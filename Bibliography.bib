@software{abadiTensorFlowLargescaleMachine2015,
  title = {{{TensorFlow}}, {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2015-11},
  doi = {10.5281/zenodo.4724125},
  url = {https://github.com/tensorflow/tensorflow},
  urldate = {2025-03-12},
  abstract = {An Open Source Machine Learning Framework for Everyone}
}

@online{al-aniOverviewMainFundamentals2010,
  title = {Overview: {{Main Fundamentals}} for {{Steganography}}},
  shorttitle = {Overview},
  author = {AL-Ani, Zaidoon Kh and Zaidan, A. A. and Zaidan, B. B. and Alanazi, Hamdan O.},
  date = {2010-03-22},
  eprint = {1003.4086},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1003.4086},
  url = {http://arxiv.org/abs/1003.4086},
  urldate = {2025-03-28},
  abstract = {The rapid development of multimedia and internet allows for wide distribution of digital media data. It becomes much easier to edit, modify and duplicate digital information .Besides that, digital documents are also easy to copy and distribute, therefore it will be faced by many threats. It is a big security and privacy issue, it become necessary to find appropriate protection because of the significance, accuracy and sensitivity of the information. Steganography considers one of the techniques which used to protect the important information. The main goals for this paper, to recognize the researchers for the main fundamentals of steganography. In this paper provides a general overview of the following subject areas: Steganography types, General Steganography system, Characterization of Steganography Systems and Classification of Steganography Techniques.},
  pubstate = {prepublished}
}

@online{alemohammadSelfConsumingGenerativeModels2023,
  title = {Self-{{Consuming Generative Models Go MAD}}},
  author = {Alemohammad, Sina and Casco-Rodriguez, Josue and Luzi, Lorenzo and Humayun, Ahmed Imtiaz and Babaei, Hossein and LeJeune, Daniel and Siahkoohi, Ali and Baraniuk, Richard G.},
  date = {2023-07-04},
  eprint = {2307.01850},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.01850},
  url = {http://arxiv.org/abs/2307.01850},
  urldate = {2025-03-19},
  abstract = {Seismic advances in generative AI algorithms for imagery, text, and other data types has led to the temptation to use synthetic data to train next-generation models. Repeating this process creates an autophagous (self-consuming) loop whose properties are poorly understood. We conduct a thorough analytical and empirical analysis using state-of-the-art generative image models of three families of autophagous loops that differ in how fixed or fresh real training data is available through the generations of training and in whether the samples from previous generation models have been biased to trade off data quality versus diversity. Our primary conclusion across all scenarios is that without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD), making analogy to mad cow disease.},
  pubstate = {prepublished}
}

@inproceedings{aliIoTSecurityReview2019,
  title = {{{IoT}} Security: {{A}} Review of Cybersecurity Architecture and Layers},
  shorttitle = {{{IoT}} Security},
  booktitle = {2nd {{Smart Cities Symposium}} ({{SCS}} 2019)},
  author = {Ali, Hamad Younis and El-Medany, Wael},
  date = {2019-03},
  pages = {1--7},
  doi = {10.1049/cp.2019.0191},
  url = {https://ieeexplore.ieee.org/document/9124947},
  urldate = {2025-03-28},
  abstract = {With the fast advancement in Technology, it started to get in every aspect of our lives. Especially that these devices are getting smaller, low power consuming and connects to the internet along with other IoT devices most or all the time thus internet of things devices are becoming a major part and can be seen everywhere in consumers houses or businesses. With these devices several risks in term of security and privacy are emerging, especially with data becoming so valuable for spying or profiting. This paper will explain privacy, its aspect and meanings to obtain a clear definition of types and ways privacy is invaded or violated. There are several laws regarding information, data privacy and protection, example of old and recent court cases with corresponding rulings. For a better understanding of how they are violated thus what should be considered or protected. There are different Layers of IoT security architecture available and described in order to protect the availability, confidentiality and integrity of IoT devices, besides a few suggested areas that need to be considered or addressed. Types of data and information that can be collected, aspects and attacks to IoT devices in terms of machine and deep learning and the data yielded from them, also the solutions approached are recommended by the author.},
  eventtitle = {2nd {{Smart Cities Symposium}} ({{SCS}} 2019)}
}

@article{aliTextbasedSteganographyUsing2021,
  title = {Text-Based {{Steganography}} Using {{Huffman Compression}} and {{AES Encryption Algorithm}}},
  author = {Ali, Rawaa Hamza and Kadhim, Jamal Mohamed},
  date = {2021-11-30},
  journaltitle = {Iraqi Journal of Science},
  pages = {4110--4120},
  issn = {2312-1637},
  doi = {10.24996/ijs.2021.62.11.31},
  url = {https://ijs.uobaghdad.edu.iq/index.php/eijs/article/view/3488},
  urldate = {2025-03-12},
  abstract = {In every system of security, to keep important data confidential, we need a high degree of protection. Steganography can be defined as a way of sending confidential texts through a secure medium of communications as well as protecting the information during the process of transmission. Steganography is a technology that is used to protect users' security and privacy. Communication is majorly achieved using a network through SMS, e-mail, and so on. The presented work suggested a technology of text hiding for protecting secret texts with Unicode characters. The similarities of glyphs\&nbsp; provided invisibility and increased the hiding capacity. In conclusion, the proposed method succeeded in securing confidential data and achieving high payload capacity by using the Huffman compression algorithm, which was implemented on an unlimited text length. In addition, this approach has the ability to hide a single bit in every digit or letter in the cover file. Also, the approach meets the cognitive transparency and does not make the modifications apparent on the original data. The method suggested in this work increases the security level through coding a secret message before embedding it within the cover text, with the use of the Advanced Encryption Standard (AES) algorithm.},
  langid = {english}
}

@inproceedings{allaEvolutionHindiText2009,
  title = {An {{Evolution}} of {{Hindi Text Steganography}}},
  booktitle = {2009 {{Sixth International Conference}} on {{Information Technology}}: {{New Generations}}},
  author = {Alla, Kalavathi and Prasad, R. Siva Rama},
  date = {2009-04},
  pages = {1577--1578},
  doi = {10.1109/ITNG.2009.41},
  url = {https://ieeexplore.ieee.org/abstract/document/5070855},
  urldate = {2025-03-24},
  abstract = {This paper presents a novel steganography scheme suitable for Hindi text. It can be classified under text steganography. Conveying information secretly and establishing a hidden relationship between the message and its counterpart has been of great interest since very long time ago. Methods of steganography are mostly applied on images, audio, video and text files. During the process characteristics of these methods are to change in the structure and features so as not to be identifiable by human eye. Text documents are the best examples for this. This paper presents a novel Hindi text steganography, which uses Hindi letters and its diacritics and numerical code. This method is not only useful to Hindi text but also to all other similar Indian languages.},
  eventtitle = {2009 {{Sixth International Conference}} on {{Information Technology}}: {{New Generations}}}
}

@article{andersonLimitsSteganography1998,
  title = {On the Limits of Steganography},
  author = {Anderson, R.J. and Petitcolas, F.A.P.},
  date = {1998-05},
  journaltitle = {IEEE Journal on Selected Areas in Communications},
  volume = {16},
  number = {4},
  pages = {474--481},
  issn = {1558-0008},
  doi = {10.1109/49.668971},
  url = {https://ieeexplore.ieee.org/abstract/document/668971},
  urldate = {2025-03-23},
  abstract = {In this paper, we clarify what steganography is and what it can do. We contrast it with the related disciplines of cryptography and traffic security, present a unified terminology agreed at the first international workshop on the subject, and outline a number of approaches-many of them developed to hide encrypted copyright marks or serial numbers in digital audio or video. We then present a number of attacks, some new, on such information hiding schemes. This leads to a discussion of the formidable obstacles that lie in the way of a general theory of information hiding systems (in the sense that Shannon gave us a general theory of secrecy systems). However, theoretical considerations lead to ideas of practical value, such as the use of parity checks to amplify covertness and provide public key steganography. Finally, we show that public key information hiding systems exist, and are not necessarily constrained to the case where the warden is passive.},
  eventtitle = {{{IEEE Journal}} on {{Selected Areas}} in {{Communications}}}
}

@software{anselPyTorch2Faster2024,
  title = {{{PyTorch}} 2: {{Faster Machine Learning Through Dynamic Python Bytecode Transformation}} and {{Graph Compilation}}},
  shorttitle = {{{PyTorch}} 2},
  author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and family=Luk, given=CK, given-i=CK and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Suo, Michael and Tillet, Phil and Wang, Eikan and Wang, Xiaodong and Wen, William and Zhang, Shunting and Zhao, Xu and Zhou, Keren and Zou, Richard and Mathews, Ajit and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
  date = {2024-04},
  origdate = {2016-08-13T05:26:41Z},
  journaltitle = {29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)},
  doi = {10.1145/3620665.3640366},
  url = {https://pytorch.org/assets/pytorch2-2.pdf},
  urldate = {2025-03-12},
  abstract = {Tensors and Dynamic neural networks in Python with strong GPU acceleration},
  organization = {ACM}
}

@article{bagnallReversingSteganographyMyth2002,
  title = {Reversing the {{Steganography Myth}} in {{Terrorist Operations}}: {{The Asymmetrical Threat}} of {{Simple Intelligence Dissemination Techniques Using Common Tools}}},
  author = {Bagnall, Robert J.},
  date = {2002},
  journaltitle = {SANS Information Security Reading Room},
  volume = {19},
  url = {http://profs.sci.univr.it/~giaco/download/Watermarking-Obfuscation/paper556.pdf},
  abstract = {The events of September 11th prompted significant discussion and speculation as to the use of Steganography by terrorists for clandestine and secured communications. Numerous prominent figures in the industry have written articles and given interviews debating whether or not terrorists are using Stego to disseminate information to sleeper cells both in America and abroad. USA Today, for example, quoted “US Officials” this way: “U.S. officials and experts say it's the latest method of communication being used by Osama bin Laden and his associates to outfox law enforcement. Bin Laden and others are hiding maps and photographs of terrorist targets and posting instructions for terrorist activities on sports chat rooms, pornographic bulletin boards and other Web sites, U.S. and foreign officials say.” (http://www.usatoday.com/life/cyber/tech/2001-0205-binladen.htm) Mostly, the commentary was not a question of if but rather how long. I contend, however, that Steganography is not required, nor significantly used, by terrorist organizations for a number of reasons. Commonly available IT software and equipment such as 802.11b wireless networks, laptop and desktop computers, highcapacity media devices, and a little creative thinking, make it possible, indeed simple, to facilitate efficient, short-duration, and completely anonymous communications between even casual hosts. In this paper, using common technology, I will demonstrate various ways and methods for simple, clandestine communications that are virtually undetectable and untraceable. In order to be most effective, clandestine data transmission between parties must be simple, stealthy, and efficient. Many would say security of the data is important, but data security in this case can also be viewed as a vector of the exposure time of the data in question to outside parties. Additionally, focus will be given to both short and long range data transmission, including transmission through methods as simple as a physical hand-off of data between parties to more complicated means across larger distances between parties which do not have physical contact, such as wireless and Internet transmissions. First we will examine three high-capacity data storage devices, their immunity to detection, and the ease with which they can be transferred between parties. Next, we will examine short burst dissemination through the use of wireless transmissions in high-density populations, such as Washington, DC or San Francisco. Lastly, we will examine the use of the web in simple, effective, and virtually undetectable intelligence dissemination.},
  langid = {english}
}

@online{bahdanauNeuralMachineTranslation2016,
  title = {Neural {{Machine Translation}} by {{Jointly Learning}} to {{Align}} and {{Translate}}},
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  date = {2016-05-19},
  eprint = {1409.0473},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1409.0473},
  url = {http://arxiv.org/abs/1409.0473},
  urldate = {2025-03-27},
  abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  pubstate = {prepublished}
}

@inproceedings{bankoScalingVeryVery2001,
  title = {Scaling to Very Very Large Corpora for Natural Language Disambiguation},
  booktitle = {Proceedings of the 39th {{Annual Meeting}} on {{Association}} for {{Computational Linguistics}}},
  author = {Banko, Michele and Brill, Eric},
  date = {2001-07-06},
  series = {{{ACL}} '01},
  pages = {26--33},
  publisher = {Association for Computational Linguistics},
  location = {USA},
  doi = {10.3115/1073012.1073017},
  url = {https://dl.acm.org/doi/10.3115/1073012.1073017},
  urldate = {2025-03-27},
  abstract = {The amount of readily available on-line text has reached hundreds of billions of words and continues to grow. Yet for most core natural language tasks, algorithms continue to be optimized, tested and compared after training on corpora consisting of only one million words or less. In this paper, we evaluate the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambiguation, when trained on orders of magnitude more labeled data than has previously been used. We are fortunate that for this particular application, correctly labeled training data is free. Since this will often not be the case, we examine methods for effectively exploiting very large corpora when labeled data comes at a cost.}
}

@online{baraniukWhyPrintersAdd2017,
  title = {Why Printers Add Secret Tracking Dots},
  author = {Baraniuk, Chris},
  date = {2017-06-07},
  url = {https://www.bbc.com/future/article/20170607-why-printers-add-secret-tracking-dots},
  urldate = {2025-01-23},
  abstract = {They’re almost invisible but contain a hidden code – and now their presence on a leaked document has sparked speculation about their usefulness to FBI investigators.},
  langid = {british}
}

@article{barnesIntelligenceOfficialsAcknowledge2025,
  entrysubtype = {newspaper},
  title = {Intelligence Officials Acknowledge the Sensitivity of the Military Strike Information.},
  author = {Barnes, Julian E.},
  date = {2025-03-25},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2025/03/25/us/politics/ratcliffe-gabbard-signal-leak.html},
  urldate = {2025-03-25},
  abstract = {Under questioning from senators, the C.I.A. chief and the director of national intelligence pointed to the defense secretary to determine what was appropriate to share.},
  journalsubtitle = {U.S.},
  langid = {american}
}

@article{bbcGhislaineMaxwellJeffreyEpstein2020,
  entrysubtype = {newspaper},
  title = {Ghislaine {{Maxwell-Jeffrey Epstein}} Emails Revealed in New Court Papers},
  author = {{BBC}},
  date = {2020-07-31},
  url = {https://www.bbc.com/news/world-us-canada-53605784},
  urldate = {2024-12-08},
  abstract = {In the papers, a key accuser also alleges the pair were equally involved in sex trafficking.},
  langid = {british}
}

@article{bbcPegasusSpywareSold2021,
  entrysubtype = {newspaper},
  title = {Pegasus: {{Spyware}} Sold to Governments 'Targets Activists'},
  shorttitle = {Pegasus},
  author = {{BBC}},
  date = {2021-07-18},
  url = {https://www.bbc.com/news/technology-57881364},
  urldate = {2024-12-08},
  abstract = {Israeli tech firm NSO denies media reports that its software has been sold to authoritarian regimes.},
  langid = {british}
}

@software{beewareBeewareToga2025,
  title = {Beeware/Toga},
  author = {{BeeWare}},
  date = {2025-03-29T08:31:59Z},
  origdate = {2014-08-01T21:44:10Z},
  url = {https://github.com/beeware/toga},
  urldate = {2025-03-29},
  abstract = {A Python native, OS native GUI toolkit.},
  organization = {BeeWare}
}

@misc{bennettLinguisticSteganographySurvey2004,
  title = {Linguistic Steganography: {{Survey}}, Analysis, and Robustness Concerns for Hiding Information in Text},
  author = {Bennett, Krista},
  date = {2004-05-12},
  abstract = {Steganography is an ancient art. With the advent of computers, we have vast accessible bodies of data in which to hide information, and increasingly sophisticated techniques with which to analyze and recover that information. While much of the recent research in steganography has been centered on hiding data in images, many of the solutions that work for images are more complicated when applied to natural language text as a cover medium. Many approaches to steganalysis attempt to detect statistical anomalies in cover data which predict the presence of hidden information. Natural language cover texts must not only pass the statistical muster of automatic analysis, but also the minds of human readers. Linguistically na},
  acknowledgement = {Victor Raskin, CERIAS},
  affiliation = {Interdepartmental Program in Linguistics and CERIAS},
  contents = {- Steganography, steganalysis and mimicking - Text steganography - Linguistic concerns with existing methods - Future directions in constructing linguistically and statistically robust cover texts},
  howpublished = {Research paper accepted in partial fulfillment of the Dept. of Linguistics preliminary examination requirement},
  langid = {english},
  organization = {Purdue University},
  subject = {Issues and future directions in linguistic steganography}
}

@article{berryLimitsComputationJoseph2023,
  title = {The {{Limits}} of {{Computation}}: {{Joseph Weizenbaum}} and the {{ELIZA Chatbot}}},
  shorttitle = {The {{Limits}} of {{Computation}}},
  author = {Berry, David M.},
  date = {2023-11-06},
  journaltitle = {Weizenbaum Journal of the Digital Society},
  volume = {3},
  number = {3},
  issn = {2748-5625},
  doi = {10.34669/WI.WJDS/3.3.2},
  url = {https://ojs.weizenbaum-institut.de/index.php/wjds/article/view/106},
  urldate = {2025-03-27},
  abstract = {Developed in the 1960s by Joseph Weizenbaum, ELIZA is arguably among the most influential computer programs ever written. ELIZA – and especially its most famous persona DOCTOR – continues to inspire programmers, wider discussions about AI, and imitations. This original ancestor of all conversational interfaces and chatbots maintains a special fascination for engineers, historians, and philosophers of artificial intelligence (AI) and computing. With its ability to produce human-like responses using a relatively small amount of computer code, ELIZA has paved the way for a multitude of similar programs. These take the form of conversation agents and other human-computer interfaces that have inspired entire new fields of study within computer science. This paper examines Weizenbaum’s contribution to AI and considers his more critical writings in the context of contemporary developments in generative AI, such as ChatGPT. Examining how ELIZA has been discussed can provide insights into current debates surrounding machine learning and AI.},
  issue = {3},
  langid = {english}
}

@online{biddleFacebookEngineersWe2022,
  title = {Facebook {{Engineers}}: {{We Have No Idea Where We Keep All Your Personal Data}}},
  shorttitle = {Facebook {{Engineers}}},
  author = {Biddle, Sam},
  date = {2022-09-07T11:00:49+00:00},
  url = {https://theintercept.com/2022/09/07/facebook-personal-data-no-accountability/},
  urldate = {2025-03-27},
  abstract = {In a discovery hearing, two veteran Facebook engineers said that Meta doesn’t know where it stores personal data.},
  langid = {american},
  organization = {The Intercept}
}

@article{brittainMetaKnewIt2025,
  entrysubtype = {newspaper},
  title = {Meta Knew It Used Pirated Books to Train {{AI}}, Authors Say},
  author = {Brittain, Blake},
  date = {2025-01-09T21:58:00Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/artificial-intelligence/meta-knew-it-used-pirated-books-train-ai-authors-say-2025-01-09/},
  urldate = {2025-03-19},
  abstract = {Meta Platforms used pirated versions of copyrighted books to train its artificial intelligence systems with approval from its CEO Mark Zuckerberg, a group of authors alleged in newly disclosed court papers.},
  journalsubtitle = {Artificial Intelligence},
  langid = {english}
}

@online{carreiraRevolutionizingMobileInteraction2023,
  title = {Revolutionizing {{Mobile Interaction}}: {{Enabling}} a 3 {{Billion Parameter GPT LLM}} on {{Mobile}}},
  shorttitle = {Revolutionizing {{Mobile Interaction}}},
  author = {Carreira, Samuel and Marques, Tomás and Ribeiro, José and Grilo, Carlos},
  date = {2023-09-29},
  eprint = {2310.01434},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2310.01434},
  url = {http://arxiv.org/abs/2310.01434},
  urldate = {2024-11-12},
  abstract = {The field of Artificial Intelligence has witnessed remarkable progress in recent years, especially with the emergence of powerful large language models (LLMs) based on the transformer architecture. Cloud-based LLMs, such as OpenAI's ChatGPT, offer impressive capabilities but come with concerns regarding latency and privacy due to network dependencies. This article presents an innovative approach to LLM inference, envisioning a future where LLMs with billions of parameters can be executed directly on mobile devices without network connectivity. The article showcases a fine-tuned GPT LLM with 3 billion parameters that can operate smoothly on devices with as low as 4GB of memory. Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features. The article provides insights into the training pipeline, implementation details, test results, and future directions of on-device LLM inference. This breakthrough technology opens up possibilities for empowering users with sophisticated AI capabilities while preserving their privacy and eliminating latency concerns.},
  pubstate = {prepublished},
  version = {1}
}

@software{chaquoChaquoChaquopy2025,
  title = {Chaquo/Chaquopy},
  author = {{Chaquo}},
  date = {2025-03-29T11:27:56Z},
  origdate = {2017-06-22T17:33:02Z},
  url = {https://github.com/chaquo/chaquopy},
  urldate = {2025-03-29},
  abstract = {Chaquopy: the Python SDK for Android},
  organization = {Chaquo}
}

@online{chenLLMMobileInitial2024,
  title = {{{LLM}} for {{Mobile}}: {{An Initial Roadmap}}},
  shorttitle = {{{LLM}} for {{Mobile}}},
  author = {Chen, Daihang and Liu, Yonghui and Zhou, Mingyi and Zhao, Yanjie and Wang, Haoyu and Wang, Shuai and Chen, Xiao and Bissyandé, Tegawendé F. and Klein, Jacques and Li, Li},
  date = {2024-07-09},
  eprint = {2407.06573},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2407.06573},
  url = {http://arxiv.org/abs/2407.06573},
  urldate = {2024-11-12},
  abstract = {When mobile meets LLMs, mobile app users deserve to have more intelligent usage experiences. For this to happen, we argue that there is a strong need to appl LLMs for the mobile ecosystem. We therefore provide a research roadmap for guiding our fellow researchers to achieve that as a whole. In this roadmap, we sum up six directions that we believe are urgently required for research to enable native intelligence in mobile devices. In each direction, we further summarize the current research progress and the gaps that still need to be filled by our fellow researchers.},
  pubstate = {prepublished},
  version = {1}
}

@online{chenOptimizationArmv9Architecture2024,
  title = {Optimization of {{Armv9}} Architecture General Large Language Model Inference Performance Based on {{Llama}}.Cpp},
  author = {Chen, Longhao and Zhao, Yina and Xie, Qiangjun and Sheng, Qinghua},
  date = {2024-06-16},
  eprint = {2406.10816},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.10816},
  url = {http://arxiv.org/abs/2406.10816},
  urldate = {2024-12-05},
  abstract = {This article optimizes the inference performance of the Qwen-1.8B model by performing Int8 quantization, vectorizing some operators in llama.cpp, and modifying the compilation script to improve the compiler optimization level. On the Yitian 710 experimental platform, the prefill performance is increased by 1.6 times, the decoding performance is increased by 24 times, the memory usage is reduced to 1/5 of the original, and the accuracy loss is almost negligible.},
  pubstate = {prepublished}
}

@online{chintalaPyTorchStrengthensIts2022,
  title = {{{PyTorch}} Strengthens Its Governance by Joining the {{Linux Foundation}}},
  author = {Chintala, Soumith},
  date = {2022-09-12},
  url = {https://pytorch.org/blog/PyTorchfoundation/},
  urldate = {2025-03-29},
  abstract = {Today, I am proud to announce that PyTorch is moving to the Linux Foundation (LF) as a top-level project under the name PyTorch Foundation. The core mission of the Linux Foundation is the collaborative development of open source software. With a governing board of leaders from AMD, Amazon Web Services (AWS), Google Cloud, Meta, Microsoft Azure and NVIDIA, this model aligns with where PyTorch stands today and what it needs to travel forward. The creation of the PyTorch Foundation will ensure business decisions are being made in a transparent and open manner by a diverse group of members for years to come. The technical decisions remain in control of individual maintainers. I’m excited that the Linux Foundation will be our new home as they have notable experience supporting large open-source projects like ours such as Kubernetes and NodeJS. At this pivotal moment, I want to take a look back at how we started, share why we are moving, and what’s ahead.},
  langid = {english},
  organization = {PyTorch}
}

@inproceedings{chowdhuryChatGPTThreatCIA2023,
  title = {{{ChatGPT}}: {{A Threat Against}} the {{CIA Triad}} of {{Cyber Security}}},
  shorttitle = {{{ChatGPT}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Electro Information Technology}} ({{eIT}})},
  author = {Chowdhury, MD Minhaz and Rifat, Nafiz and Ahsan, Mostofa and Latif, Shadman and Gomes, Rahul and Rahman, Md Saifur},
  date = {2023-05},
  pages = {1--6},
  issn = {2154-0373},
  doi = {10.1109/eIT57321.2023.10187355},
  url = {https://ieeexplore.ieee.org/abstract/document/10187355},
  urldate = {2025-03-28},
  abstract = {The AI revolution has brought significant changes to society. AI-powered systems can analyze enormous amounts of data to optimize processes, improve accuracy, and cut costs. Nevertheless, addressing potential hazards and ethical issues related to AI enabled technologies, such as bias and job displacement, is essential. This paper presented an example of an AI revolution threatening cyber security, the ChatGPT. ChatGPT, a chatbot, can generate essays or code on demand. However, ChatGPT's security system can be circumvented or deceived to generate malicious content. Moreover, these AI enabled tools to have design issues, e.g., accuracy issues. As a result, ChatGPT can be accused of violating the confidentiality of information (privacy invasion), producing inaccurate information, and potentially facilitating attack tool generation that can compromise the availability principle of the CIA triad. This paper presents ChatGPT as a threat against the CIA triad principle by focusing on violating these principles.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Electro Information Technology}} ({{eIT}})}
}

@inproceedings{christUndetectableWatermarksLanguage2024,
  title = {Undetectable {{Watermarks}} for {{Language Models}}},
  booktitle = {Proceedings of {{Thirty Seventh Conference}} on {{Learning Theory}}},
  author = {Christ, Miranda and Gunn, Sam and Zamir, Or},
  date = {2024-06-30},
  pages = {1125--1139},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v247/christ24a.html},
  urldate = {2025-03-12},
  abstract = {Recent advances in the capabilities of large language models such as GPT-4 have spurred increasing concern about our ability to detect AI-generated text.  Prior works have suggested methods of embedding watermarks in model outputs, by *noticeably* altering the output distribution. We ask: Is it possible to introduce a watermark without incurring *any detectable* change to the output distribution? To this end, we introduce a cryptographically-inspired notion of undetectable watermarks for language models.  That is, watermarks can be detected only with the knowledge of a secret key; without the secret key, it is computationally intractable to distinguish watermarked outputs from those of the original model. In particular, it is impossible for a user to observe any degradation in the quality of the text. Crucially, watermarks remain undetectable even when the user is allowed to adaptively query the model with arbitrarily chosen prompts. We construct undetectable watermarks based on the existence of one-way functions, a standard assumption in cryptography.},
  eventtitle = {The {{Thirty Seventh Annual Conference}} on {{Learning Theory}}},
  langid = {english}
}

@online{cmakeCMakeUpgradeYour,
  title = {{{CMake}} - {{Upgrade Your Software Build System}}},
  author = {{CMake}},
  url = {https://cmake.org/},
  urldate = {2025-03-29},
  abstract = {CMake is a powerful and comprehensive solution for managing the software build process. CMake is the de-facto standard for building C++ code, with over 2 million downloads a month.},
  langid = {american}
}

@online{cohenWhenTerrorHides2001,
  title = {When {{Terror Hides Online}}},
  author = {Cohen, Adam},
  date = {2001-11-12T05:00:00},
  url = {https://time.com/archive/6665170/when-terror-hides-online/},
  urldate = {2025-01-09},
  abstract = {Did you hear the one about Osama bin Laden hiding messages in porn websites? It sounds like one of those crazy Sept. 11 rumors, but it's actually a law-enforcement theory about how the al-Qaeda...},
  langid = {english},
  organization = {TIME}
}

@article{conwayCodeWarsSteganography2003,
  title = {Code {{Wars}}: {{Steganography}}, {{Signals Intelligence}}, and {{Terrorism}}},
  author = {Conway, Maura},
  date = {2003-02-16},
  url = {https://doras.dcu.ie/494/1/know_tech_pol_16_2_2003.pdf},
  abstract = {This paper describes and discusses the process of secret communication known as steganography. The argument advanced here is that terrorists are unlikely to be employing digital steganography to facilitate secret intra-group communication as has been claimed. This is because terrorist use of digital steganography is both technically and operationally implausible. The position adopted in this paper is that terrorists are likely to employ low-tech steganography such as semagrams and null ciphers instead.},
  langid = {english}
}

@online{coppTrumpOfficialsTexted2025,
  title = {Trump Officials Texted Attack Plans to a Group Chat in a Secure App That Included a Journalist},
  author = {Copp, Tara and Madhani, Aamer and Tucker, Eric},
  date = {2025-03-24T19:02:02},
  url = {https://apnews.com/article/war-plans-trump-hegseth-atlantic-230718a984911dd8663d59edbcb86f2a},
  urldate = {2025-03-25},
  abstract = {President Donald Trump is downplaying the texting of attack plans to a group chat that included a journalist as “the only glitch in two months” of his administration.},
  langid = {english},
  organization = {AP News}
}

@online{coxDataBrokerSelling2022,
  title = {Data {{Broker Is Selling Location Data}} of {{People Who Visit Abortion Clinics}}},
  author = {Cox, Joseph},
  date = {2022-05-03T16:46:42+00:00},
  url = {https://www.vice.com/en/article/location-data-abortion-clinics-safegraph-planned-parenthood/},
  urldate = {2025-03-26},
  abstract = {It costs just over \$160 to get a week's worth of data on where people who visited Planned Parenthood came from, and where they went afterwards.},
  langid = {american},
  organization = {VICE}
}

@online{coxHowNewSuspected2017,
  title = {How the {{New Suspected NSA Leaker Reality Winner Was Caught}}},
  author = {Cox, Joseph},
  date = {2017-06-06T11:33:21+00:00},
  url = {https://www.vice.com/en/article/nsa-suspected-leaker-reality-leigh-winner-caught/},
  urldate = {2025-03-26},
  abstract = {From the characteristics of physical documents, to not using work computers, there’s plenty to learn from the recent bombshell leaking charge.},
  langid = {american},
  organization = {VICE}
}

@online{danielChatControlEnd2024,
  title = {Chat {{Control}}—{{The End Of Private Messaging As We Know It}}?},
  author = {Daniel, Lars},
  date = {2024-12-19},
  url = {https://www.forbes.com/sites/larsdaniel/2024/12/19/eus-chat-control-the-end-of-private-messaging-as-we-know-it/},
  urldate = {2025-03-25},
  abstract = {The EU wants to search all private chats, messages, and emails—here's what you need to know.},
  langid = {english},
  organization = {Forbes}
}

@online{dasSteganographySteganalysisDifferent2011,
  title = {Steganography and {{Steganalysis}}: {{Different Approaches}}},
  shorttitle = {Steganography and {{Steganalysis}}},
  author = {Das, Soumyendu and Das, Subhendu and Bandyopadhyay, Bijoy and Sanyal, Sugata},
  date = {2011-11-16},
  eprint = {1111.3758},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1111.3758},
  url = {http://arxiv.org/abs/1111.3758},
  urldate = {2025-03-12},
  abstract = {Steganography is the technique of hiding confidential information within any media. Steganography is often confused with cryptography because the two are similar in the way that they both are used to protect confidential information. The difference between the two is in the appearance in the processed output; the output of steganography operation is not apparently visible but in cryptography the output is scrambled so that it can draw attention. Steganlysis is process to detect of presence of steganography. In this article we have tried to elucidate the different approaches towards implementation of steganography using 'multimedia' file (text, static image, audio and video) and Network IP datagram as cover. Also some methods of steganalysis will be discussed.},
  pubstate = {prepublished},
  version = {1}
}

@online{debusmannTrumpIntelligenceChiefs2025,
  title = {Trump and Intelligence Chiefs Play down {{Signal}} Group Chat Leak},
  author = {Debusmann, Bernd and Drenon, Brandon},
  date = {2025-03-25},
  url = {https://www.bbc.com/news/articles/cp8vgr0p8n6o},
  urldate = {2025-03-25},
  abstract = {President Trump also defended his national security team after a reporter was added to their message thread.},
  langid = {british}
}

@online{deepseek-aiDeepSeekR1IncentivizingReasoning2025,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  date = {2025-01-22},
  eprint = {2501.12948},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.12948},
  url = {http://arxiv.org/abs/2501.12948},
  urldate = {2025-03-28},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  pubstate = {prepublished}
}

@software{deepseekDeepseekaiDeepSeekR12025,
  title = {Deepseek-Ai/{{DeepSeek-R1}}},
  author = {{DeepSeek}},
  date = {2025-03-27T12:46:34Z},
  origdate = {2025-01-20T11:57:28Z},
  url = {https://github.com/deepseek-ai/DeepSeek-R1},
  urldate = {2025-03-27},
  organization = {DeepSeek}
}

@article{dembartEndUserHide2001,
  entrysubtype = {newspaper},
  title = {The {{End User}}: {{Hide Your Secrets}}},
  shorttitle = {The {{End User}}},
  author = {Dembart, Lee},
  date = {2001-05-07},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2001/05/07/business/worldbusiness/IHT-the-end-user-hide-your-secrets.html},
  urldate = {2025-03-11},
  abstract = {Everyone knows by now that the Internet is insecure — the bad guys can eavesdrop on what you send over the Web — and most people probably know that encryption is one way around the problem. If there's something that you don't want anyone but},
  journalsubtitle = {Business},
  langid = {american}
}

@software{devitoZdevitoATen2025,
  title = {Zdevito/{{ATen}}},
  author = {DeVito, Zachary},
  date = {2025-03-02T13:28:59Z},
  origdate = {2017-06-20T23:50:41Z},
  url = {https://github.com/zdevito/ATen},
  urldate = {2025-03-11},
  abstract = {ATen: A TENsor library for C++11}
}

@article{dolevSecurityPublicKey1983,
  title = {On the Security of Public Key Protocols},
  author = {Dolev, D. and Yao, A.},
  date = {1983-03},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {29},
  number = {2},
  pages = {198--208},
  issn = {1557-9654},
  doi = {10.1109/TIT.1983.1056650},
  url = {https://ieeexplore.ieee.org/document/1056650},
  urldate = {2025-03-28},
  abstract = {Recently the use of public key encryption to provide secure network communication has received considerable attention. Such public key systems are usually effective against passive eavesdroppers, who merely tap the lines and try to decipher the message. It has been pointed out, however, that an improperly designed protocol could be vulnerable to an active saboteur, one who may impersonate another user or alter the message being transmitted. Several models are formulated in which the security of protocols can be discussed precisely. Algorithms and characterizations that can be used to determine protocol security in these models are given.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}}
}

@online{donnerFinetuningLLMYour2024,
  title = {Fine-Tuning an {{LLM}} on Your Texts: Part 2 - Exploring Your Text Data},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-01-17T15:10:39+00:00},
  url = {https://edwarddonner.com/2024/01/17/fine-tune-llm-on-texts-part-2-the-data/},
  urldate = {2025-01-24},
  abstract = {In part 2 of my guide to fine-tuning an LLM on your text messages, we use our CSV downloads to read, organize and investigate our data.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerFinetuningLLMYour2024a,
  title = {Fine-Tuning an {{LLM}} on Your Texts: Part 3 - Curating the Dataset},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-01-24T23:17:43+00:00},
  url = {https://edwarddonner.com/2024/01/24/fine-tuning-an-llm-on-your-texts-part-3-curating-the-dataset/},
  urldate = {2025-01-24},
  abstract = {In part 3 of my guide to fine-tuning an LLM on your text messages, we curate the dataset, encrypt and upload to Hugging Face.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerFinetuningLLMYour2024b,
  title = {Fine-Tuning an {{LLM}} on Your Texts: Part 4 - {{QLoRA}}},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-01-31T17:42:51+00:00},
  url = {https://edwarddonner.com/2024/01/31/fine-tuning-an-llm-on-your-text-messages-using-qlora/},
  urldate = {2025-01-24},
  abstract = {In part 4 of my guide to fine-tuning an LLM on your text message history, we train using QLoRA and experiment with hyper-parameters.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerSimulationMeFinetuning2024,
  title = {A Simulation of Me: Fine-Tuning an {{LLM}} on 240k Text Messages},
  shorttitle = {A Simulation of Me},
  author = {Donner, Edward},
  date = {2024-01-02T21:26:11+00:00},
  url = {https://edwarddonner.com/2024/01/02/fine-tuning-an-llm-on-240k-text-messages/},
  urldate = {2025-01-24},
  abstract = {Armed with a download of my 240,000 text message and Whatsapp history, I was able to fine-tune an LLM to create convincing conversations.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerStepStepGuide2024,
  title = {Step by Step Guide: Fine-Tune an {{LLM}} on Your Texts (Part 1)},
  shorttitle = {Step by Step Guide},
  author = {Donner, Edward},
  date = {2024-01-11T14:22:20+00:00},
  url = {https://edwarddonner.com/2024/01/11/fine-tune-llama-for-text-messages-part-1/},
  urldate = {2025-01-24},
  abstract = {Part 1 of my step-by-step guide on how to fine-tune an LLM on your entire text message and WhatsApp history.},
  langid = {american},
  organization = {Edward Donner}
}

@software{drukAndriydrukLMPlayground2025,
  title = {Andriydruk/{{LMPlayground}}},
  author = {Druk, Andriy},
  date = {2025-03-01T12:44:43Z},
  origdate = {2024-03-16T13:51:07Z},
  url = {https://github.com/andriydruk/LMPlayground},
  urldate = {2025-03-11},
  abstract = {Language Model Playground}
}

@article{duportailAskedTinderMy2017,
  entrysubtype = {newspaper},
  title = {I Asked {{Tinder}} for My Data. {{It}} Sent Me 800 Pages of My Deepest, Darkest Secrets},
  author = {Duportail, Judith},
  date = {2017-09-26T06:10:35},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold},
  urldate = {2025-03-26},
  abstract = {The dating app knows me better than I do, but these reams of intimate information are just the tip of the iceberg. What if my data is hacked – or sold?},
  journalsubtitle = {Technology},
  langid = {british}
}

@article{edwardsFBIPaidMore2016,
  entrysubtype = {newspaper},
  title = {{{FBI}} Paid More than \$1.3 Million to Break into {{San Bernardino iPhone}}},
  author = {Edwards, Julia},
  date = {2016-04-22T17:52:08},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/article/technology/fbi-paid-more-than-13-million-to-break-into-san-bernardino-iphone-idUSKCN0XI2IB/},
  urldate = {2025-02-18},
  abstract = {Federal Bureau of Investigation Director James Comey said on Thursday the agency paid more to get into the iPhone of one of the San Bernardino shooters than he will make in the remaining seven years and four months he has in his job.},
  journalsubtitle = {Technology},
  langid = {american}
}

@online{eldanTinyStoriesHowSmall2023,
  title = {{{TinyStories}}: {{How Small Can Language Models Be}} and {{Still Speak Coherent English}}?},
  shorttitle = {{{TinyStories}}},
  author = {Eldan, Ronen and Li, Yuanzhi},
  date = {2023-05-24},
  eprint = {2305.07759},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2305.07759},
  url = {http://arxiv.org/abs/2305.07759},
  urldate = {2024-11-27},
  abstract = {Language models (LMs) are powerful tools for natural language processing, but they often struggle to produce coherent and fluent text when they are small. Models with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can rarely generate coherent and consistent English text beyond a few words even after extensive training. This raises the question of whether the emergence of the ability to produce coherent English text only occurs at larger scales (with hundreds of millions of parameters or more) and complex architectures (with many layers of global attention). In this work, we introduce TinyStories, a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We show that TinyStories can be used to train and evaluate LMs that are much smaller than the state-of-the-art models (below 10 million total parameters), or have much simpler architectures (with only one transformer block), yet still produce fluent and consistent stories with several paragraphs that are diverse and have almost perfect grammar, and demonstrate reasoning capabilities. We also introduce a new paradigm for the evaluation of language models: We suggest a framework which uses GPT-4 to grade the content generated by these models as if those were stories written by students and graded by a (human) teacher. This new paradigm overcomes the flaws of standard benchmarks which often requires the model's output to be very structures, and moreover provides a multidimensional score for the model, providing scores for different capabilities such as grammar, creativity and consistency. We hope that TinyStories can facilitate the development, analysis and research of LMs, especially for low-resource or specialized domains, and shed light on the emergence of language capabilities in LMs.},
  pubstate = {prepublished}
}

@article{evsutinDigitalSteganographyWatermarking2020,
  title = {Digital {{Steganography}} and {{Watermarking}} for {{Digital Images}}: {{A Review}} of {{Current Research Directions}}},
  shorttitle = {Digital {{Steganography}} and {{Watermarking}} for {{Digital Images}}},
  author = {Evsutin, Oleg and Melman, Anna and Meshcheryakov, Roman},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {166589--166611},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3022779},
  url = {https://ieeexplore.ieee.org/abstract/document/9187785},
  urldate = {2025-03-27},
  abstract = {The development of information technology has led to a significant increase in the share of multimedia traffic in data networks. This has necessitated to solve the following information security tasks in relation to multimedia data: protection against leakage of confidential information, as well as identifying the source of the leak; ensuring the impossibility of unauthorized changes; copyright protection for digital objects. To solve such kind of problems, methods of steganography and watermarking are designed that implement embedding in digital objects hidden information sequences for various purposes. In this paper, an overview of promising research in the specified area is provided. First of all, we provide basic information about this field of research and consider the main applications of its methods. Next, we review works demonstrating current trends in the development of methods and algorithms for data hiding in digital images. This review is not exhaustive; it focuses on contemporary works illustrating current research directions in the field of information embedding in digital images. This is the main feature of review, which distinguishes it from previously published reviews. The paper concludes with an analysis of identified problems in the field of digital steganography and digital watermarking.},
  eventtitle = {{{IEEE Access}}}
}

@online{fangGeneratingSteganographicText2017,
  title = {Generating {{Steganographic Text}} with {{LSTMs}}},
  author = {Fang, Tina and Jaggi, Martin and Argyraki, Katerina},
  date = {2017-05-30},
  eprint = {1705.10742},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1705.10742},
  url = {http://arxiv.org/abs/1705.10742},
  urldate = {2025-01-26},
  abstract = {Motivated by concerns for user privacy, we design a steganographic system ("stegosystem") that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.},
  pubstate = {prepublished}
}

@online{fbiUpdateFBIInvestigation2024,
  type = {Press Release},
  title = {Update on the {{FBI Investigation}} of the {{Attempted Assassination}} of {{Former President Donald Trump}}},
  author = {{FBI}},
  date = {2024-07-15T15:03:00Z},
  url = {https://www.fbi.gov/news/press-releases/update-on-the-fbi-investigation-of-the-attempted-assassination-of-former-president-donald-trump},
  urldate = {2024-11-26},
  abstract = {The FBI continues to investigate the shooting incident at the July 13 rally in Butler, Pennsylvania, as an assassination attempt on former President Donald Trump and as potential domestic terrorism. The investigation is still in the early stages, and the FBI is providing the following updates.},
  langid = {american},
  organization = {Federal Bureau of Investigation}
}

@online{gaureL^2M^2C^22024,
  title = {L\textasciicircum 2 * {{M}}\textasciicircum 2 = {{C}}\textasciicircum 2: {{Large Language Models}} Are {{Covert Channels}}},
  author = {Gaure, Simen and Koffas, Stefanos and Picek, Stjepan and Rønjom, Sondre},
  date = {2024-10-07},
  eprint = {2405.15652},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.15652},
  url = {http://arxiv.org/abs/2405.15652},
  urldate = {2025-03-12},
  abstract = {Large Language Models (LLMs) have gained significant popularity recently. LLMs are susceptible to various attacks but can also improve the security of diverse systems. However, besides enabling more secure systems, how well do open source LLMs behave as covertext distributions to, e.g., facilitate censorship-resistant communication? In this paper, we explore open-source LLM-based covert channels. We empirically measure the security vs. capacity of an open-source LLM model (Llama-7B) to assess its performance as a covert channel. Although our results indicate that such channels are not likely to achieve high practical bitrates, we also show that the chance for an adversary to detect covert communication is low. To ensure our results can be used with the least effort as a general reference, we employ a conceptually simple and concise scheme and only assume public models.},
  pubstate = {prepublished},
  version = {2}
}

@software{gerganovGgerganovGgml2024,
  title = {Ggerganov/Ggml},
  author = {Gerganov, Georgi},
  date = {2024-12-08T06:39:36Z},
  origdate = {2022-09-18T17:07:19Z},
  url = {https://github.com/ggerganov/ggml},
  urldate = {2024-12-08},
  abstract = {Tensor library for machine learning}
}

@software{gerganovGgerganovLlamacpp2024,
  title = {Ggerganov/Llama.Cpp},
  author = {Gerganov, Georgi},
  date = {2024-12-08T12:18:03Z},
  origdate = {2023-03-10T18:58:00Z},
  url = {https://github.com/ggerganov/llama.cpp},
  urldate = {2024-12-08},
  abstract = {LLM inference in C/C++}
}

@software{gerganovGgerganovWhispercpp2024,
  title = {Ggerganov/Whisper.Cpp},
  author = {Gerganov, Georgi},
  date = {2024-12-08T15:39:54Z},
  origdate = {2022-09-25T18:26:37Z},
  url = {https://github.com/ggerganov/whisper.cpp},
  urldate = {2024-12-08},
  abstract = {Port of OpenAI's Whisper model in C/C++}
}

@software{ghorbaniAghorbaniPocketpalai2025,
  title = {A-Ghorbani/Pocketpal-Ai},
  author = {Ghorbani, Asghar},
  date = {2025-03-11T17:43:15Z},
  origdate = {2024-08-25T08:14:11Z},
  url = {https://github.com/a-ghorbani/pocketpal-ai},
  urldate = {2025-03-11},
  abstract = {An app that brings language models directly to your phone.}
}

@online{gleaveMakingCompressionAlgorithms2017,
  title = {Making Compression Algorithms for {{Unicode}} Text},
  author = {Gleave, Adam and Steinruecken, Christian},
  date = {2017-01-15},
  eprint = {1701.04047},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1701.04047},
  url = {http://arxiv.org/abs/1701.04047},
  urldate = {2025-04-01},
  abstract = {The majority of online content is written in languages other than English, and is most commonly encoded in UTF-8, the world's dominant Unicode character encoding. Traditional compression algorithms typically operate on individual bytes. While this approach works well for the single-byte ASCII encoding, it works poorly for UTF-8, where characters often span multiple bytes. Previous research has focused on developing Unicode compressors from scratch, which often failed to outperform established algorithms such as bzip2. We develop a technique to modify byte-based compressors to operate directly on Unicode characters, and implement variants of LZW and PPM that apply this technique. We find that our method substantially improves compression effectiveness on a UTF-8 corpus, with our PPM variant outperforming the state-of-the-art PPMII compressor. On ASCII and binary files, our variants perform similarly to the original unmodified compressors.},
  pubstate = {prepublished}
}

@online{gnuprojectWhatFreeSoftware,
  title = {What Is {{Free Software}}? - {{GNU Project}} - {{Free Software Foundation}}},
  author = {{GNU Project}},
  url = {https://www.gnu.org/philosophy/free-sw.en.html},
  urldate = {2025-03-28}
}

@online{goldbergHereAreAttack2025,
  title = {Here {{Are}} the {{Attack Plans That Trump}}’s {{Advisers Shared}} on {{Signal}}},
  author = {Goldberg, Jeffrey and Harris, Shane},
  date = {2025-03-26},
  url = {https://www.theatlantic.com/politics/archive/2025/03/signal-group-chat-attack-plans-hegseth-goldberg/682176/},
  urldate = {2025-03-26},
  abstract = {The administration has downplayed the importance of the text messages inadvertently sent to The Atlantic’s editor in chief.},
  langid = {english},
  organization = {The Atlantic}
}

@online{goldbergTrumpAdministrationAccidentally2025,
  title = {The {{Trump Administration Accidentally Texted Me Its War Plans}}},
  author = {Goldberg, Jeffrey},
  date = {2025-03-24},
  url = {https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/},
  urldate = {2025-03-26},
  abstract = {U.S. national-security leaders included me in a group chat about upcoming military strikes in Yemen. I didn’t think it could be real. Then the bombs started falling.},
  langid = {english},
  organization = {The Atlantic}
}

@online{googleaiedgeteamTensorFlowLiteNow2024,
  title = {{{TensorFlow Lite}} Is Now {{LiteRT- Google Developers Blog}}},
  author = {{Google AI Edge team}},
  date = {2024-09-04},
  url = {https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/},
  urldate = {2025-03-18},
  abstract = {TensorFlow Lite, now named LiteRT, is still the same high-performance runtime for on-device AI, but with an expanded vision to support models authored in PyTorch, JAX, and Keras.},
  langid = {english}
}

@software{googleGoogleaiedgeLiteRT2025,
  title = {Google-Ai-Edge/{{LiteRT}}},
  author = {{Google}},
  date = {2025-03-18T20:52:11Z},
  origdate = {2024-09-04T03:33:35Z},
  url = {https://github.com/google-ai-edge/LiteRT},
  urldate = {2025-03-18},
  abstract = {LiteRT is the new name for TensorFlow Lite (TFLite). While the name is new, it's still the same trusted, high-performance runtime for on-device AI, now with an expanded vision.},
  organization = {google-ai-edge}
}

@software{googleGoogleKsp2025,
  title = {Google/Ksp},
  author = {{Google}},
  date = {2025-03-28T08:53:54Z},
  origdate = {2020-09-22T18:59:42Z},
  url = {https://github.com/google/ksp},
  urldate = {2025-03-29},
  abstract = {Kotlin Symbol Processing API},
  organization = {Google}
}

@software{googleGoogleSentencepiece2024,
  title = {Google/Sentencepiece},
  author = {{Google}},
  date = {2024-12-28T19:47:17Z},
  origdate = {2017-03-07T10:03:48Z},
  url = {https://github.com/google/sentencepiece},
  urldate = {2024-12-28},
  abstract = {Unsupervised text tokenizer for Neural Network-based text generation.},
  organization = {Google}
}

@online{gradleGradleBuildTool2025,
  title = {Gradle {{Build Tool}}},
  author = {{Gradle}},
  date = {2025-03-20},
  url = {https://gradle.org/},
  urldate = {2025-03-29},
  abstract = {Accelerate developer productivity. Gradle helps teams build, automate and deliver better software, faster.},
  langid = {american},
  organization = {Gradle}
}

@article{greenwaldBoundlessInformantNSAs2013,
  entrysubtype = {newspaper},
  title = {Boundless {{Informant}}: The {{NSA}}'s Secret Tool to Track Global Surveillance Data},
  shorttitle = {Boundless {{Informant}}},
  author = {Greenwald, Glenn and MacAskill, Ewen},
  date = {2013-06-11T13:00:00},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jun/08/nsa-boundless-informant-global-datamining},
  urldate = {2025-03-26},
  abstract = {Revealed: The NSA's powerful tool for cataloguing global surveillance data – including figures on US collection • Boundless Informant: mission outlined in four slides• Read the NSA's frequently asked questions document},
  journalsubtitle = {US news},
  langid = {british}
}

@article{greenwaldEdwardSnowdenWhistleblower2013,
  entrysubtype = {newspaper},
  title = {Edward {{Snowden}}: The Whistleblower behind the {{NSA}} Surveillance Revelations},
  shorttitle = {Edward {{Snowden}}},
  author = {Greenwald, Glenn and MacAskill, Ewen and Poitras, Laura},
  date = {2013-06-11T13:00:00},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jun/09/edward-snowden-nsa-whistleblower-surveillance},
  urldate = {2025-03-26},
  abstract = {The 29-year-old source behind the biggest intelligence leak in the NSA’s history explains his motives, his uncertain future and why he never intended on hiding in the shadows},
  journalsubtitle = {US news},
  langid = {british}
}

@article{greenwaldNSAPrismProgram2013,
  entrysubtype = {newspaper},
  title = {{{NSA Prism}} Program Taps in to User Data of {{Apple}}, {{Google}} and Others},
  author = {Greenwald, Glenn and MacAskill, Ewen},
  date = {2013-06-07T19:23:00},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jun/06/us-tech-giants-nsa-data},
  urldate = {2025-03-26},
  abstract = {• Top-secret Prism program claims direct access to servers of firms including Google, Apple and Facebook• Companies deny any knowledge of program in operation since 2007},
  journalsubtitle = {US news},
  langid = {british}
}

@article{greenwaldXKeyscoreNSATool2013,
  entrysubtype = {newspaper},
  title = {{{XKeyscore}}: {{NSA}} Tool Collects 'Nearly Everything a User Does on the Internet'},
  shorttitle = {{{XKeyscore}}},
  author = {Greenwald, Glenn},
  date = {2013-07-31T12:56:51},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jul/31/nsa-top-secret-program-online-data},
  urldate = {2025-03-26},
  abstract = {• XKeyscore gives 'widest-reaching' collection of online data• NSA analysts require no prior authorization for searches• Sweeps up emails, social media activity and browsing history},
  journalsubtitle = {US news},
  langid = {british}
}

@article{guptaChatGPTThreatGPTImpact2023,
  title = {From {{ChatGPT}} to {{ThreatGPT}}: {{Impact}} of {{Generative AI}} in {{Cybersecurity}} and {{Privacy}}},
  shorttitle = {From {{ChatGPT}} to {{ThreatGPT}}},
  author = {Gupta, Maanak and Akiri, Charankumar and Aryal, Kshitiz and Parker, Eli and Praharaj, Lopamudra},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {80218--80245},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3300381},
  url = {https://ieeexplore.ieee.org/abstract/document/10198233},
  urldate = {2025-03-27},
  abstract = {Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.},
  eventtitle = {{{IEEE Access}}}
}

@article{hamzahLinguisticSteganographyFramework2021,
  title = {A Linguistic Steganography Framework Using {{Arabic}} Calligraphy},
  author = {family=Hamzah, given=Ali. A., given-i={{Ali}}A and Khattab, Sherif and Bayomi, Hanaa},
  date = {2021-09-01},
  journaltitle = {Journal of King Saud University - Computer and Information Sciences},
  shortjournal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {33},
  number = {7},
  pages = {865--877},
  issn = {1319-1578},
  doi = {10.1016/j.jksuci.2019.04.015},
  url = {https://www.sciencedirect.com/science/article/pii/S1319157819301818},
  urldate = {2025-03-13},
  abstract = {In linguistic steganography, languages’ features are employed to hide information. The Arabic language has a rich set of features which have not been utilized until now in this area. In particular, Arabic calligraphy contains multiple fonts and multiple shapes of Arabic alphabet letters. In this paper, a framework that uses Arabic calligraphy to hide information is proposed. The phases of the framework are preparation phase, embedding phase and extraction phase. The embedding phase uses string matching to generate stego text and accompanying letter shapes according to a secret message. The framework also includes corpus creation and a modification of the Aho-Corasick string-matching algorithm. The Arabic font Naskh was used as a case study. A set of Arabic poetry and proverbs were used as a dataset. The framework was evaluated on capacity and security. Because the visual difference between the cover and the stego-cover must be unnoticeable to the human in any stego-system, the security in this framework is satisfying due there is no cover used. The cover represents the secret message itself and it provides high capacity to hide data also. The evaluation showed the potential of using the multiple shapes of Arabic letters to satisfy steganography requirements.}
}

@article{hanFolkloreSourceCoding2005,
  title = {Folklore in Source Coding: Information-Spectrum Approach},
  shorttitle = {Folklore in Source Coding},
  author = {Han, Te Sun},
  date = {2005-02},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {51},
  number = {2},
  pages = {747--753},
  issn = {1557-9654},
  doi = {10.1109/TIT.2004.840860},
  url = {https://ieeexplore.ieee.org/document/1386546},
  urldate = {2025-03-13},
  abstract = {Information theory has several traditional folklore problems about data compression or channel coding with reference to random number generation problems. Here, we focus on and reasonably formulate one of them from the viewpoint of information spectra. Specifically, we verify the validity of the folklore that the output from any source encoder working at the optimal coding rate with asymptotically vanishing probability of error looks like almost completely random.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}}
}

@article{haoReversibleNaturalLanguage2018,
  title = {Reversible Natural Language Watermarking Using Synonym Substitution and Arithmetic Coding},
  author = {Hao, Wei and Xiang, Lingyun and Li, Yan and Yang, Peng and Shen, Xiaobo},
  date = {2018},
  issn = {1546-2218},
  doi = {10.3970/cmc.2018.03510},
  url = {https://dr.ntu.edu.sg/handle/10356/106752},
  urldate = {2025-03-24},
  abstract = {For protecting the copyright of a text and recovering its original content harmlessly, this paper proposes a novel reversible natural language watermarking method that combines arithmetic coding and synonym substitution operations. By analyzing relative frequencies of synonymous words, synonyms employed for carrying payload are quantized into an unbalanced and redundant binary sequence. The quantized binary sequence is compressed by adaptive binary arithmetic coding losslessly to provide a spare for accommodating additional data. Then, the compressed data appended with the watermark are embedded into the cover text via synonym substitutions in an invertible manner. On the receiver side, the watermark and compressed data can be extracted by decoding the values of synonyms in the watermarked text, as a result of which the original context can be perfectly recovered by decompressing the extracted compressed data and substituting the replaced synonyms with their original synonyms. Experimental results demonstrate that the proposed method can extract the watermark successfully and achieve a lossless recovery of the original text. Additionally, it achieves a high embedding capacity.},
  langid = {english},
  annotation = {Accepted: 2019-06-26T05:16:58Z}
}

@article{hernNewAIFake2019,
  entrysubtype = {newspaper},
  title = {New {{AI}} Fake Text Generator May Be Too Dangerous to Release, Say Creators},
  author = {Hern, Alex},
  date = {2019-02-14T17:00:54},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction},
  urldate = {2025-03-27},
  abstract = {The Elon Musk-backed nonprofit company OpenAI declines to release research publicly for fear of misuse},
  journalsubtitle = {Technology},
  langid = {british}
}

@online{hoodIntroducingLlamafileMozilla2023,
  title = {Introducing Llamafile – {{Mozilla Hacks}} - the {{Web}} Developer Blog},
  author = {Hood, Stephen},
  date = {2023-11-29},
  url = {https://hacks.mozilla.org/2023/11/introducing-llamafile},
  urldate = {2025-03-29},
  abstract = {We're thrilled to announce the first release of llamafile, inviting the open source community to join this groundbreaking project.},
  langid = {american},
  organization = {Mozilla Hacks – the Web developer blog}
}

@online{hossainLLMProSAnalyzingLarge2025,
  title = {{{LLM-ProS}}: {{Analyzing Large Language Models}}' {{Performance}} in {{Competitive Problem Solving}}},
  shorttitle = {{{LLM-ProS}}},
  author = {Hossain, Md Sifat and Tabassum, Anika and Arefin, Md Fahim and Zaman, Tarannum Shaila},
  date = {2025-02-04},
  eprint = {2502.04355},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.04355},
  url = {http://arxiv.org/abs/2502.04355},
  urldate = {2025-03-24},
  abstract = {The rapid advancement of large language models has opened new avenues for automating complex problem-solving tasks such as algorithmic coding and competitive programming. This paper introduces a novel evaluation technique, LLM-ProS, to assess the performance of state-of-the-art LLMs on International Collegiate Programming Contest (ICPC) problems. Using a curated dataset of 166 World Finals problems from 2011 to 2024, we benchmark the models' reasoning, accuracy, and efficiency. We evaluate the five models-GPT-4o, Mistral Large, Llama-3.1-405B, and the o1 family, consisting of o1-mini and o1-preview, across critical metrics like correctness, resource utilization, and response calibration. Our results reveal significant differences in the models' abilities to generalize, adapt, and solve novel problems. We also investigated the impact of training methodologies, dataset contamination, and chain-of-thought reasoning on model performance. The findings provide new insights into optimizing LLMs for algorithmic tasks, highlighting both strengths and limitations of current models.},
  pubstate = {prepublished}
}

@article{huffmanMethodConstructionMinimumRedundancy1952,
  title = {A {{Method}} for the {{Construction}} of {{Minimum-Redundancy Codes}}},
  author = {Huffman, David A.},
  date = {1952-09},
  journaltitle = {Proceedings of the IRE},
  volume = {40},
  number = {9},
  pages = {1098--1101},
  issn = {2162-6634},
  doi = {10.1109/JRPROC.1952.273898},
  url = {https://ieeexplore.ieee.org/document/4051119},
  urldate = {2025-03-19},
  abstract = {An optimum method of coding an ensemble of messages consisting of a finite number of members is developed. A minimum-redundancy code is one constructed in such a way that the average number of coding digits per message is minimized.},
  eventtitle = {Proceedings of the {{IRE}}}
}

@online{huggingfaceGGUF,
  title = {{{GGUF}}},
  author = {{HuggingFace}},
  url = {https://huggingface.co/docs/hub/gguf},
  urldate = {2025-03-29},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingfaceModelCards,
  title = {Model {{Cards}}},
  author = {{HuggingFace}},
  url = {https://huggingface.co/docs/hub/model-cards},
  urldate = {2025-03-29},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingfaceModelsHuggingFace2025,
  title = {Models - {{Hugging Face}}},
  author = {{HuggingFace}},
  date = {2025-03-16},
  url = {https://huggingface.co/models},
  urldate = {2025-03-17},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingfacesmolmodelsresearchHuggingFaceTBSmolLM217BInstructGGUFHugging2024,
  title = {{{HuggingFaceTB}}/{{SmolLM2-1}}.{{7B-Instruct-GGUF}} · {{Hugging Face}}},
  author = {{Hugging Face Smol Models Research}},
  date = {2024-10-31},
  url = {https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingquantsHuggingquantsLlama321BInstructQ4_K_MGGUFHugging2024,
  title = {Hugging-Quants/{{Llama-3}}.2-{{1B-Instruct-Q4}}\_{{K}}\_{{M-GGUF}} · {{Hugging Face}}},
  author = {{Hugging Quants}},
  date = {2024-09-26},
  url = {https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q4_K_M-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  date = {2021-10-16},
  eprint = {2106.09685},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.09685},
  url = {http://arxiv.org/abs/2106.09685},
  urldate = {2025-03-27},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  pubstate = {prepublished}
}

@inproceedings{ishizakiTransformingJavaPrograms2014,
  title = {Transforming {{Java}} Programs for Concurrency Using {{Double-Checked Locking}} Pattern},
  booktitle = {2014 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  author = {Ishizaki, Kazuaki and Daijavad, Shahrokh and Nakatani, Toshio},
  date = {2014-03},
  pages = {128--129},
  doi = {10.1109/ISPASS.2014.6844469},
  url = {https://ieeexplore.ieee.org/abstract/document/6844469},
  urldate = {2025-03-31},
  abstract = {Java provides a synchronized construct for multi-core programming with many workloads. However, naïve use of the synchronized construct causes performance scalability problems due to lock contention. One of the sources of lock contentions is a synchronized collection class. There are known concurrency code patterns to alleviate lock contentions such as a Concurrent Collection (CC), Read-Write Lock (RWL), and Double-Checked Locking (DCL). To date, there is no algorithm to transform a program using DCL. This paper describes steps on how to rewrite synchronized blocks using DCL.},
  eventtitle = {2014 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})}
}

@software{jaxJaxmlJax2025,
  title = {Jax-Ml/Jax},
  author = {{Jax}},
  date = {2025-03-17T10:56:50Z},
  origdate = {2018-10-25T21:25:02Z},
  url = {https://github.com/jax-ml/jax},
  urldate = {2025-03-17},
  abstract = {Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more},
  organization = {jax-ml}
}

@online{jiangChatBugCommonVulnerability2025,
  title = {{{ChatBug}}: {{A Common Vulnerability}} of {{Aligned LLMs Induced}} by {{Chat Templates}}},
  shorttitle = {{{ChatBug}}},
  author = {Jiang, Fengqing and Xu, Zhangchen and Niu, Luyao and Lin, Bill Yuchen and Poovendran, Radha},
  date = {2025-01-07},
  eprint = {2406.12935},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.12935},
  url = {http://arxiv.org/abs/2406.12935},
  urldate = {2025-04-03},
  abstract = {Large language models (LLMs) are expected to follow instructions from users and engage in conversations. Techniques to enhance LLMs' instruction-following capabilities typically fine-tune them using data structured according to a predefined chat template. Although chat templates are shown to be effective in optimizing LLM performance, their impact on safety alignment of LLMs has been less understood, which is crucial for deploying LLMs safely at scale. In this paper, we investigate how chat templates affect safety alignment of LLMs. We identify a common vulnerability, named ChatBug, that is introduced by chat templates. Our key insight to identify ChatBug is that the chat templates provide a rigid format that need to be followed by LLMs, but not by users. Hence, a malicious user may not necessarily follow the chat template when prompting LLMs. Instead, malicious users could leverage their knowledge of the chat template and accordingly craft their prompts to bypass safety alignments of LLMs. We develop two attacks to exploit the ChatBug vulnerability. We demonstrate that a malicious user can exploit the ChatBug vulnerability of eight state-of-the-art (SOTA) LLMs and effectively elicit unintended responses from these models. Moreover, we show that ChatBug can be exploited by existing jailbreak attacks to enhance their attack success rates. We investigate potential countermeasures to ChatBug. Our results show that while adversarial training effectively mitigates the ChatBug vulnerability, the victim model incurs significant performance degradation. These results highlight the trade-off between safety alignment and helpfulness. Developing new methods for instruction tuning to balance this trade-off is an open and critical direction for future research},
  pubstate = {prepublished}
}

@article{kasterPrivatizedEspionageNSO2023,
  title = {Privatized Espionage: {{NSO Group Technologies}} and Its {{Pegasus}} Spyware},
  shorttitle = {Privatized Espionage},
  author = {Kaster, Sean D. and Ensign, Prescott C.},
  date = {2023},
  journaltitle = {Thunderbird International Business Review},
  volume = {65},
  number = {3},
  pages = {355--364},
  issn = {1520-6874},
  doi = {10.1002/tie.22321},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/tie.22321},
  urldate = {2025-03-12},
  abstract = {Advanced cyber technology like NSO Group Technologies' (NSO) controversial Pegasus spyware blurs distinctions between “good” and “bad.” This case follows the Israeli-based international leader in cyber espionage and developer NSO and one of its co-founders, Shalev Hulio from its creation in 2010 to the present. It includes NSO's acquisition by US-based private equity fund Francisco Partners in 2014. NSO's re-acquisition in 2019 by co-founders Hulio and Omri Lavie with funding support from London-based private equity fund Novalpina Capital. During this time, Pegasus had helped capture Mexican drug baron El Chapo, prevented terrorist attacks and broken up pedophilia, sex, and drug-trafficking rings. But Pegasus also contributed to the murder of Washington Post reporter Jamal Khashoggi as well as other illegal incidents against dissidents, journalist, and governments. As the case suggests, controlling access to such powerful technology that involves accountability, responsibility, and enforceability within a firm and within nations appears illusive.},
  langid = {english}
}

@article{kilgarriffIntroductionSpecialIssue2003,
  title = {Introduction to the {{Special Issue}} on the {{Web}} as {{Corpus}}},
  author = {Kilgarriff, Adam and Grefenstette, Gregory},
  date = {2003-09-01},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {29},
  number = {3},
  pages = {333--347},
  issn = {0891-2017},
  doi = {10.1162/089120103322711569},
  url = {https://doi.org/10.1162/089120103322711569},
  urldate = {2025-03-27},
  abstract = {The Web, teeming as it is with language data, of all manner of varieties and languages, in vast quantity and freely available, is a fabulous linguists' playground. This special issue of Computational Linguistics explores ways in which this dream is being explored.}
}

@software{kivyKivyKivy2025,
  title = {Kivy/Kivy},
  author = {{Kivy}},
  date = {2025-03-29T00:27:04Z},
  origdate = {2010-11-03T20:27:32Z},
  url = {https://github.com/kivy/kivy},
  urldate = {2025-03-29},
  abstract = {Open source UI framework written in Python, running on Windows, Linux, macOS, Android and iOS},
  organization = {Kivy}
}

@online{kleinmanApplePullsData2025,
  title = {Apple Pulls Data Protection Tool after {{UK}} Government Security Row},
  author = {Kleinman, Zoe},
  date = {2025-02-22},
  url = {https://www.bbc.com/news/articles/cgj54eq4vejo},
  urldate = {2025-02-25},
  abstract = {Customers' photos and documents stored online will no longer be protected by end-to-end encryption.},
  langid = {british}
}

@online{kleinmanUKGovernmentDemands2025,
  title = {{{UK}} Government Demands Access to {{Apple}} Users' Encrypted Data},
  author = {Kleinman, Zoe},
  date = {2025-02-07},
  url = {https://www.bbc.com/news/articles/c20g288yldko},
  urldate = {2025-02-25},
  abstract = {The Home Office served the notice to the tech giant under the Investigatory Powers Act.},
  langid = {british}
}

@inproceedings{knochelTextSteganographyMethods2024,
  title = {Text {{Steganography Methods}} and Their {{Influence}} in {{Malware}}: {{A Comprehensive Overview}} and {{Evaluation}}},
  shorttitle = {Text {{Steganography Methods}} and Their {{Influence}} in {{Malware}}},
  booktitle = {Proceedings of the 2024 {{ACM Workshop}} on {{Information Hiding}} and {{Multimedia Security}}},
  author = {Knöchel, Mandy and Karius, Sebastian},
  date = {2024-06-24},
  series = {{{IH}}\&amp;{{MMSec}} '24},
  pages = {113--124},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3658664.3659637},
  url = {https://dl.acm.org/doi/10.1145/3658664.3659637},
  urldate = {2025-03-12},
  abstract = {Steganography describes techniques and algorithms for hiding secret information in a cover medium such as images, audio or text files. Malware that makes use of steganographic techniques, known as stegomalware, is becoming increasingly common. This paper provides a comprehensive analysis of various text steganography methods and their application in the context of stegomalware. We give an extensive overview of occurrences of text stegomalware in the real world and the steganographic methods used in these attacks. The cover text includes any files or data containing natural language text or machine-readable digital texts and source code such as HTML, CSS, JavaScript, etc. A categorical overview of known text steganography methods is presented, whereas text steganography techniques are classified into the categories insertion, substitution, permutation and generation. For each category, selected representatives have been practically implemented and tested with different cover text files and messages of varying lengths. The authors also look at real-world applications and instances of stegomalware that utilize these methods. The paper reveals that while there is a vast array of text steganography methods, only a few are used in practice. To assess the strengths and weaknesses of each method, the evaluation is based on the metrics capacity, imperceptibility and robustness, which are commonly used to evaluate steganographic methods, and additionally complexity. The evaluation results show the performance of each method based on the defined metrics. We further discuss possible countermeasures and their effect on each steganography method. The analysis also shows that with the rise of machine learning and large language models, text steganography methods might become more common in the future.},
  isbn = {979-8-4007-0637-0}
}

@article{kolataVeiledMessagesTerror2001,
  entrysubtype = {newspaper},
  title = {Veiled {{Messages}} of {{Terror May Lurk}} in {{Cyberspace}}},
  author = {Kolata, Gina},
  date = {2001-10-30},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2001/10/30/science/veiled-messages-of-terror-may-lurk-in-cyberspace.html},
  urldate = {2025-03-11},
  abstract = {Probe into terrorist attacks on United States is drawing new attention to steganography, stealthy way of sending messages through Internet by hiding them in digital photographs or music files; method allegedly was used by recently seized terrorists who were planning to blow up United States's Paris embassy; takes advantage of fact that digital files can be slightly altered and still look or sound same; computer programs that look for statistical deviations are reportedly detecting widespread use of steganography on Internet; diagram; photos (M)},
  journalsubtitle = {Science},
  langid = {american}
}

@article{kollnigAreIPhonesReally2022,
  title = {Are {{iPhones Really Better}} for {{Privacy}}? {{Comparative Study}} of {{iOS}} and {{Android Apps}}},
  shorttitle = {Are {{iPhones Really Better}} for {{Privacy}}?},
  author = {Kollnig, Konrad and Shuba, Anastasia and Binns, Reuben and Kleek, Max Van and Shadbolt, Nigel},
  date = {2022-04-01},
  journaltitle = {Proceedings on Privacy Enhancing Technologies},
  volume = {2022},
  number = {2},
  eprint = {2109.13722},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {6--24},
  issn = {2299-0984},
  doi = {10.2478/popets-2022-0033},
  url = {http://arxiv.org/abs/2109.13722},
  urldate = {2024-12-13},
  abstract = {While many studies have looked at privacy properties of the Android and Google Play app ecosystem, comparatively much less is known about iOS and the Apple App Store, the most widely used ecosystem in the US. At the same time, there is increasing competition around privacy between these smartphone operating system providers. In this paper, we present a study of 24k Android and iOS apps from 2020 along several dimensions relating to user privacy. We find that third-party tracking and the sharing of unique user identifiers was widespread in apps from both ecosystems, even in apps aimed at children. In the children's category, iOS apps tended to use fewer advertising-related tracking than their Android counterparts, but could more often access children's location. Across all studied apps, our study highlights widespread potential violations of US, EU and UK privacy law, including 1) the use of third-party tracking without user consent, 2) the lack of parental consent before sharing personally identifiable information (PII) with third-parties in children's apps, 3) the non-data-minimising configuration of tracking libraries, 4) the sending of personal data to countries without an adequate level of data protection, and 5) the continued absence of transparency around tracking, partly due to design decisions by Apple and Google. Overall, we find that neither platform is clearly better than the other for privacy across the dimensions we studied.}
}

@software{kotlinKotlinKotlinxserialization2025,
  title = {Kotlin/Kotlinx.Serialization},
  author = {{Kotlin}},
  date = {2025-03-28T21:35:41Z},
  origdate = {2017-07-20T11:25:23Z},
  url = {https://github.com/Kotlin/kotlinx.serialization},
  urldate = {2025-03-29},
  abstract = {Kotlin multiplatform / multi-format serialization},
  organization = {Kotlin}
}

@online{kotlinKotlinProgrammingLanguage,
  title = {Kotlin {{Programming Language}}},
  author = {{Kotlin}},
  url = {https://kotlinlang.org/},
  urldate = {2025-03-29},
  abstract = {Kotlin is a concise and multiplatform programming language by JetBrains. Enjoy coding and build server-side, mobile, web, and desktop applications efficiently.},
  langid = {english},
  organization = {Kotlin}
}

@inproceedings{leeGitHubRecentBugs2024,
  title = {The {{GitHub Recent Bugs Dataset}} for {{Evaluating LLM-Based Debugging Applications}}},
  booktitle = {2024 {{IEEE Conference}} on {{Software Testing}}, {{Verification}} and {{Validation}} ({{ICST}})},
  author = {Lee, Jae Yong and Kang, Sungmin and Yoon, Juyeon and Yoo, Shin},
  date = {2024-05},
  pages = {442--444},
  issn = {2159-4848},
  doi = {10.1109/ICST60714.2024.00049},
  url = {https://ieeexplore.ieee.org/abstract/document/10638568},
  urldate = {2025-03-24},
  abstract = {While Large Language Models (LLMs) have demon-strated strong natural language and code processing capabilities, concern has been raised as to whether existing bug benchmarks are included in their training data. We examine the training data of the open-source LLM StarCoder, and find it likely that data from the widely used Defects4J benchmark was included, raising the possibility of its inclusion in the training data of the GPT model as well. This makes it difficult to tell how well LLM-based results on Defects4J would generalize, as for any results it would be unclear whether a technique's performance is due to LLM generalization or memorization. To remedy this issue and facilitate continued research on LLM-based SE, we present the GitHub Recent Bugs (GHRB) framework, which continuously gathers real-world Java bugs for use in evaluation of LLM-based techniques. To date, we have gathered 89 bugs reported after the GPT-3.5 training data cutoff point of September 2021.},
  eventtitle = {2024 {{IEEE Conference}} on {{Software Testing}}, {{Verification}} and {{Validation}} ({{ICST}})}
}

@online{leeUnifiedDebuggingApproach2024,
  title = {A {{Unified Debugging Approach}} via {{LLM-Based Multi-Agent Synergy}}},
  author = {Lee, Cheryl and Xia, Chunqiu Steven and Yang, Longji and Huang, Jen-tse and Zhu, Zhouruixin and Zhang, Lingming and Lyu, Michael R.},
  date = {2024-10-23},
  eprint = {2404.17153},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.17153},
  url = {http://arxiv.org/abs/2404.17153},
  urldate = {2025-03-24},
  abstract = {Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25\$\textbackslash times\$ to 2.56\$\textbackslash times\$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on https://github.com/AcceptePapier/UniDebugger.},
  pubstate = {prepublished}
}

@inproceedings{liesenfeldOpeningChatGPTTracking2023,
  title = {Opening up {{ChatGPT}}: {{Tracking}} Openness, Transparency, and Accountability in Instruction-Tuned Text Generators},
  shorttitle = {Opening up {{ChatGPT}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Conversational User Interfaces}}},
  author = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
  date = {2023-07-19},
  series = {{{CUI}} '23},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3571884.3604316},
  url = {https://dl.acm.org/doi/10.1145/3571884.3604316},
  urldate = {2025-03-28},
  abstract = {Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.},
  isbn = {979-8-4007-0014-9}
}

@inproceedings{liImperceptibleTextSteganography2024,
  title = {Imperceptible {{Text Steganography}} Based on {{Group Chat}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})},
  author = {Li, Fanxiao and Wei, Ping and Fu, Tingchao and Lin, Yu and Zhou, Wei},
  date = {2024-07},
  pages = {1--6},
  issn = {1945-788X},
  doi = {10.1109/ICME57554.2024.10687958},
  url = {https://ieeexplore.ieee.org/abstract/document/10687958},
  urldate = {2024-12-07},
  abstract = {Text steganography is a technique for hiding secret messages within texts. Previous approaches neglect the contextual relevance of generated stego texts (texts containing secrets) and consistently transmitted secret messages unidirectionally. This behavior is considered anomalous and thus arouses the suspicion of potential attackers. In this paper, we first propose a text steganography framework grounded in the group chat scenario named GCStego, aimed at enhancing the behavior imperceptibility. Additionally, we employ a large language model (LLM) to generate stego texts according to the chatting history and thus boosts the contextual relevance. The proposed scheme is well-suited for secret transmission in group chatting, where multiple agents can pass secret messages through stego texts like regular conversations. Furthermore, we propose token index-based encoding, position filtering and sentence split strategies to deliver the performance. Experimental results demonstrate the superiority of our proposed framework in terms of text semantic controllability, behavioral imperceptibility, and anti-steganalysis ability.},
  eventtitle = {2024 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})}
}

@online{liTransformerLiteHighefficiencyDeployment2024,
  title = {Transformer-{{Lite}}: {{High-efficiency Deployment}} of {{Large Language Models}} on {{Mobile Phone GPUs}}},
  shorttitle = {Transformer-{{Lite}}},
  author = {Li, Luchang and Qian, Sheng and Lu, Jie and Yuan, Lunxi and Wang, Rui and Xie, Qin},
  date = {2024-07-05},
  eprint = {2403.20041},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.20041},
  url = {http://arxiv.org/abs/2403.20041},
  urldate = {2025-03-12},
  abstract = {The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text summarization, translation, and multi-modality on mobile phones. However, the current methods for on-device LLM deployment maintain slow inference speed, which causes poor user experience. To facilitate high-efficiency LLM deployment on device GPUs, we propose four optimization techniques: (a) a symbolic expression-based approach to support dynamic shape model inference; (b) operator optimizations and execution priority setting to enhance inference speed and reduce phone lagging; (c) an FP4 quantization method termed M0E4 to reduce dequantization overhead; (d) a sub-tensor-based technique to eliminate the need for copying KV cache after LLM inference. Furthermore, we implement these methods in our mobile inference engine, Transformer-Lite, which is compatible with both Qualcomm and MTK processors. We evaluated Transformer-Lite's performance using LLMs with varied architectures and parameters ranging from 2B to 14B. Specifically, we achieved prefill and decoding speeds of 121 token/s and 14 token/s for ChatGLM2 6B, and 330 token/s and 30 token/s for smaller Gemma 2B, respectively. Compared with CPU-based FastLLM and GPU-based MLC-LLM, our engine attains over 10x speedup for the prefill speed and 2\textasciitilde 3x speedup for the decoding speed.},
  pubstate = {prepublished},
  version = {3}
}

@online{lmstudiocommunityLmstudiocommunityDeepSeekR1DistillQwen15BGGUFHugging2025,
  title = {Lmstudio-Community/{{DeepSeek-R1-Distill-Qwen-1}}.{{5B-GGUF}} · {{Hugging Face}}},
  author = {{LM Studio Community}},
  date = {2025-01-20},
  url = {https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-1.5B-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{lmstudiocommunityLmstudiocommunityGemma31bItGGUF2025,
  title = {Lmstudio-Community/Gemma-3-1b-It-{{GGUF}} · {{Hugging Face}}},
  author = {{LM Studio Community}},
  date = {2025-03-12},
  url = {https://huggingface.co/lmstudio-community/gemma-3-1b-it-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{lovonEvaluatingLLMAbilities2025,
  title = {Evaluating {{LLM Abilities}} to {{Understand Tabular Electronic Health Records}}: {{A Comprehensive Study}} of {{Patient Data Extraction}} and {{Retrieval}}},
  shorttitle = {Evaluating {{LLM Abilities}} to {{Understand Tabular Electronic Health Records}}},
  author = {Lovon, Jesus and Mouysset, Martin and Oleiwan, Jo and Moreno, Jose G. and Damase-Michel, Christine and Tamine, Lynda},
  date = {2025-01-16},
  eprint = {2501.09384},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.09384},
  url = {http://arxiv.org/abs/2501.09384},
  urldate = {2025-03-27},
  abstract = {Electronic Health Record (EHR) tables pose unique challenges among which is the presence of hidden contextual dependencies between medical features with a high level of data dimensionality and sparsity. This study presents the first investigation into the abilities of LLMs to comprehend EHRs for patient data extraction and retrieval. We conduct extensive experiments using the MIMICSQL dataset to explore the impact of the prompt structure, instruction, context, and demonstration, of two backbone LLMs, Llama2 and Meditron, based on task performance. Through quantitative and qualitative analyses, our findings show that optimal feature selection and serialization methods can enhance task performance by up to 26.79\% compared to naive approaches. Similarly, in-context learning setups with relevant example selection improve data extraction performance by 5.95\%. Based on our study findings, we propose guidelines that we believe would help the design of LLM-based models to support health search.},
  pubstate = {prepublished}
}

@inproceedings{lowDocumentMarkingIdentification1995,
  title = {Document Marking and Identification Using Both Line and Word Shifting},
  booktitle = {Proceedings of {{INFOCOM}}'95},
  author = {Low, S.H. and Maxemchuk, N.F. and Brassil, J.T. and O'Gorman, L.},
  date = {1995-04},
  volume = {2},
  pages = {853-860 vol.2},
  issn = {0743-166X},
  doi = {10.1109/INFCOM.1995.515956},
  url = {https://ieeexplore.ieee.org/abstract/document/515956},
  urldate = {2025-03-23},
  abstract = {Continues a study of document marking to deter illicit dissemination. An experiment performed reveals that the distortion on the photocopy of a document is very different in the vertical and horizontal directions. This leads to the strategy that marks a text line both vertically using line shifting and horizontally using word shifting. A line that is marked is always accompanied by two unmarked control lines one above and one below. They are used to measure distortions in the vertical and horizontal directions in order to decide whether line or word shift should be detected. Line shifts are detected using a centroid method that bases its decision on the relative distance of line centroids. Word shifts are detected using a correlation method that treats a profile as a waveform and decides whether it originated from a waveform whose middle block has been shifted left or right. The maximum likelihood detectors for both methods are given.},
  eventtitle = {Proceedings of {{INFOCOM}}'95}
}

@inproceedings{luoTextSteganographyHigh2017,
  title = {Text {{Steganography}} with {{High Embedding Rate}}: {{Using Recurrent Neural Networks}} to {{Generate Chinese Classic Poetry}}},
  shorttitle = {Text {{Steganography}} with {{High Embedding Rate}}},
  booktitle = {Proceedings of the 5th {{ACM Workshop}} on {{Information Hiding}} and {{Multimedia Security}}},
  author = {Luo, Yubo and Huang, Yongfeng},
  date = {2017-06-20},
  series = {{{IH}}\&amp;{{MMSec}} '17},
  pages = {99--104},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3082031.3083240},
  url = {https://dl.acm.org/doi/10.1145/3082031.3083240},
  urldate = {2025-03-12},
  abstract = {We propose a novel text steganography method using RNN Encoder-Decoder structure to generate quatrains, one genre of Chinese poetry. Compared to other text-generation based steganography methods which have either very low embedding rate or flaws in the naturalness of generated texts, our method has higher embedding rate and better text quality. In this paper, we use the LSTM Encoder-Decoder model to generate the first line of a quatrain with a keyword and then generate the following lines one by one. RNN has proved effective in generating poetry, but when applied to steganograpy, poetry quality decreases sharply, because of the redundancy we create to hide information. To overcome this problem, we propose a template-constrained generation method and develop a word-choosing approach using inner-word mutual information. Through a series of experiments, it is proven that our approach outperforms other poetry steganography methods in both embedding rate and poetry quality.},
  isbn = {978-1-4503-5061-7}
}

@online{luSmallLanguageModels2024,
  title = {Small {{Language Models}}: {{Survey}}, {{Measurements}}, and {{Insights}}},
  shorttitle = {Small {{Language Models}}},
  author = {Lu, Zhenyan and Li, Xiang and Cai, Dongqi and Yi, Rongjie and Liu, Fangming and Zhang, Xiwen and Lane, Nicholas D. and Xu, Mengwei},
  date = {2024-09-24},
  eprint = {2409.15790},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.15790},
  url = {http://arxiv.org/abs/2409.15790},
  urldate = {2025-03-11},
  abstract = {Small language models (SLMs), despite their widespread adoption in modern smart devices, have received significantly less academic attention compared to their large language model (LLM) counterparts, which are predominantly deployed in data centers and cloud environments. While researchers continue to improve the capabilities of LLMs in the pursuit of artificial general intelligence, SLM research aims to make machine intelligence more accessible, affordable, and efficient for everyday tasks. Focusing on transformer-based, decoder-only language models with 100M-5B parameters, we survey 59 state-of-the-art open-source SLMs, analyzing their technical innovations across three axes: architectures, training datasets, and training algorithms. In addition, we evaluate their capabilities in various domains, including commonsense reasoning, in-context learning, mathematics, and coding. To gain further insight into their on-device runtime costs, we benchmark their inference latency and memory footprints. Through in-depth analysis of our benchmarking data, we offer valuable insights to advance research in this field.},
  pubstate = {prepublished},
  version = {1}
}

@article{macaskillGCHQTapsFibreoptic2013,
  entrysubtype = {newspaper},
  title = {{{GCHQ}} Taps Fibre-Optic Cables for Secret Access to World's Communications},
  author = {MacAskill, Ewen and Borger, Julian and Hopkins, Nick and Davies, Nick and Ball, James},
  date = {2013-06-21T16:23:17},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa},
  urldate = {2025-03-26},
  abstract = {Exclusive: British spy agency collects and stores vast quantities of global email messages, Facebook posts, internet histories and calls, and shares them with NSA, latest documents from Edward Snowden reveal},
  journalsubtitle = {UK news},
  langid = {british}
}

@article{malikHighCapacityText2017,
  title = {A High Capacity Text Steganography Scheme Based on Huffman Compression and Color Coding},
  author = {Malik, Aruna and Sikka, Geeta and Verma, Harsh K.},
  date = {2017-07-04},
  journaltitle = {Journal of Information and Optimization Sciences},
  volume = {38},
  number = {5},
  pages = {647--664},
  publisher = {Taylor \& Francis},
  issn = {0252-2667},
  doi = {10.1080/02522667.2016.1197572},
  url = {https://doi.org/10.1080/02522667.2016.1197572},
  urldate = {2025-03-12},
  abstract = {In this paper, we propose a high capacity text steganography scheme by using a combination of Move to Front (MTF) encoding, huffman compression, and color coding. The forward email platform is used to hide the secret data. In this scheme, we first encode the secret data using MTF encoding to increase the similarity among the element of the secret data and then apply huffman compression technique on the resultant secret data to obtain huffman codes for condensing the size of the secret data. Part of the compressed secret data is embedded into the email addresses, and residual part of the secret data stream is hide in the text message using a user defined color coding table. To make optimal utilization of number of characters in email ids, the characters added to the email id to indicate the secret data bits are taken from the processed secret data. The new characters are appended just before the ‘@’ symbol of email ids. Hence, the hiding capacity is further increased. Experimental results show that our method performs much better than the existing methods in terms of hiding capacity.}
}

@online{mallisTechniquesKVCache2024,
  title = {Techniques for {{KV Cache Optimization}} in {{Large Language Models}}},
  author = {Mallis, Omri},
  date = {2024-02-25},
  url = {https://www.omrimallis.com/posts/techniques-for-kv-cache-optimization/},
  urldate = {2025-01-08},
  abstract = {This post explores techniques for optimizing the Key-Value (KV) cache in large language models, from Grouped-query attention to PagedAttention and distributed cache management.},
  langid = {english}
}

@online{mallisUnderstandingHowLLM2023,
  title = {Understanding How {{LLM}} Inference Works with Llama.Cpp},
  author = {Mallis, Omri},
  date = {2023-11-11},
  url = {https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/},
  urldate = {2024-12-03},
  abstract = {In this post we will understand how large language models (LLMs) answer user prompts by exploring the source code of llama.cpp, a C++ implementation of LLaMA, covering subjects such as tokenization, embedding, self-attention and sampling.},
  langid = {english}
}

@online{martinezCombiningGenerativeArtificial2023,
  title = {Combining {{Generative Artificial Intelligence}} ({{AI}}) and the {{Internet}}: {{Heading}} towards {{Evolution}} or {{Degradation}}?},
  shorttitle = {Combining {{Generative Artificial Intelligence}} ({{AI}}) and the {{Internet}}},
  author = {Martínez, Gonzalo and Watson, Lauren and Reviriego, Pedro and Hernández, José Alberto and Juarez, Marc and Sarkar, Rik},
  date = {2023-02-17},
  eprint = {2303.01255},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.01255},
  url = {http://arxiv.org/abs/2303.01255},
  urldate = {2025-03-19},
  abstract = {In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve with the new data sets or degenerate? Will evolution introduce biases in subsequent generations of generative AI tools? In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool. These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate. Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet.},
  pubstate = {prepublished}
}

@online{martinezUnderstandingInterplayGenerative2023,
  title = {Towards {{Understanding}} the {{Interplay}} of {{Generative Artificial Intelligence}} and the {{Internet}}},
  author = {Martínez, Gonzalo and Watson, Lauren and Reviriego, Pedro and Hernández, José Alberto and Juarez, Marc and Sarkar, Rik},
  date = {2023-06-08},
  eprint = {2306.06130},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.06130},
  url = {http://arxiv.org/abs/2306.06130},
  urldate = {2025-03-19},
  abstract = {The rapid adoption of generative Artificial Intelligence (AI) tools that can generate realistic images or text, such as DALL-E, MidJourney, or ChatGPT, have put the societal impacts of these technologies at the center of public debate. These tools are possible due to the massive amount of data (text and images) that is publicly available through the Internet. At the same time, these generative AI tools become content creators that are already contributing to the data that is available to train future models. Therefore, future versions of generative AI tools will be trained with a mix of human-created and AI-generated content, causing a potential feedback loop between generative AI and public data repositories. This interaction raises many questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve and improve with the new data sets or on the contrary will they degrade? Will evolution introduce biases or reduce diversity in subsequent generations of generative AI tools? What are the societal implications of the possible degradation of these models? Can we mitigate the effects of this feedback loop? In this document, we explore the effect of this interaction and report some initial results using simple diffusion models trained with various image datasets. Our results show that the quality and diversity of the generated images can degrade over time suggesting that incorporating AI-created data can have undesired effects on future versions of generative models.},
  pubstate = {prepublished}
}

@online{mathewHiddenPlainText2024,
  title = {Hidden in {{Plain Text}}: {{Emergence}} \& {{Mitigation}} of {{Steganographic Collusion}} in {{LLMs}}},
  shorttitle = {Hidden in {{Plain Text}}},
  author = {Mathew, Yohan and Matthews, Ollie and McCarthy, Robert and Velja, Joan and family=Witt, given=Christian Schroeder, prefix=de, useprefix=false and Cope, Dylan and Schoots, Nandi},
  date = {2024-10-02},
  eprint = {2410.03768},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.03768},
  url = {http://arxiv.org/abs/2410.03768},
  urldate = {2025-03-12},
  abstract = {The rapid proliferation of frontier model agents promises significant societal advances but also raises concerns about systemic risks arising from unsafe interactions. Collusion to the disadvantage of others has been identified as a central form of undesirable agent cooperation. The use of information hiding (steganography) in agent communications could render collusion practically undetectable. This underscores the need for evaluation frameworks to monitor and mitigate steganographic collusion capabilities. We address a crucial gap in the literature by demonstrating, for the first time, that robust steganographic collusion in LLMs can arise indirectly from optimization pressure. To investigate this problem we design two approaches -- a gradient-based reinforcement learning (GBRL) method and an in-context reinforcement learning (ICRL) method -- for reliably eliciting sophisticated LLM-generated linguistic text steganography. Importantly, we find that emergent steganographic collusion can be robust to both passive steganalytic oversight of model outputs and active mitigation through communication paraphrasing. We contribute a novel model evaluation framework and discuss limitations and future work. Our findings imply that effective risk mitigation from steganographic collusion post-deployment requires innovation in passive and active oversight techniques.},
  pubstate = {prepublished},
  version = {1}
}

@article{mccallumMetaFacebookOwner2023,
  entrysubtype = {newspaper},
  title = {Meta: {{Facebook}} Owner Fined €1.2bn for Mishandling Data},
  shorttitle = {Meta},
  author = {McCallum, Shiona},
  date = {2023-05-22},
  url = {https://www.bbc.com/news/technology-65669839},
  urldate = {2025-03-27},
  abstract = {The dispute is over Facebook's transfer of European data to US servers.},
  langid = {british}
}

@article{mccullaghBinLadenSteganography2001,
  entrysubtype = {magazine},
  title = {Bin {{Laden}}: {{Steganography Master}}?},
  shorttitle = {Bin {{Laden}}},
  author = {McCullagh, Declan},
  date = {2001-02-07},
  journaltitle = {Wired},
  issn = {1059-1028},
  url = {https://www.wired.com/2001/02/bin-laden-steganography-master/},
  urldate = {2025-01-09},
  abstract = {Are the FBI and CIA using reports that Osama bin Laden and others are using messaging scrambling techniques to justify further restrictions of encryption and steganography programs? Declan McCullagh reports from Washington.},
  langid = {american}
}

@article{megiasDataHidingIts2021,
  title = {Data {{Hiding}} and {{Its Applications}}: {{Digital Watermarking}} and {{Steganography}}},
  shorttitle = {Data {{Hiding}} and {{Its Applications}}},
  author = {Megías, David and Mazurczyk, Wojciech and Kuribayashi, Minoru},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {22},
  pages = {10928},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app112210928},
  url = {https://www.mdpi.com/2076-3417/11/22/10928},
  urldate = {2025-03-27},
  abstract = {Data hiding techniques [...]},
  issue = {22},
  langid = {english}
}

@software{metaMetallamaLlamamodels2025,
  title = {Meta-Llama/Llama-Models},
  author = {{Meta}},
  date = {2025-03-14T12:52:56Z},
  origdate = {2024-06-27T22:14:09Z},
  url = {https://github.com/meta-llama/llama-models},
  urldate = {2025-03-14},
  abstract = {Utilities intended for use with Llama models.},
  organization = {Meta Llama}
}

@article{michaelsonJournalistsMore11002025,
  entrysubtype = {newspaper},
  title = {Journalists among More than 1,100 Arrested in {{Turkey}} Crackdown},
  author = {Michaelson, Ruth},
  date = {2025-03-24T17:04:13},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2025/mar/24/journalists-among-more-than-1100-arrested-in-turkey-crackdown-istanbul},
  urldate = {2025-03-24},
  abstract = {Authorities ask X to block accounts as tens of thousands take to streets in largest anti-government protests in years},
  journalsubtitle = {World news},
  langid = {british}
}

@article{mienyeChatGPTEducationReview2025,
  title = {{{ChatGPT}} in {{Education}}: {{A Review}} of {{Ethical Challenges}} and {{Approaches}} to {{Enhancing Transparency}} and {{Privacy}}},
  shorttitle = {{{ChatGPT}} in {{Education}}},
  author = {Mienye, Ibomoiye Domor and Swart, Theo G.},
  date = {2025-01-01},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  series = {International {{Conference}} on {{Digital Sovereignty}} ({{ICDS}})},
  volume = {254},
  pages = {181--190},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2025.02.077},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050925004272},
  urldate = {2025-03-27},
  abstract = {The integration of ChatGPT and large language models (LLMs) into education has created new possibilities for personalized learning, tutoring, and automation of administrative tasks. However, these advancements also present ethical challenges. This paper critically examines the ethical implications of deploying ChatGPT in educational settings, with a focus on data privacy, the opaque nature of AI decision-making, and the risks of biased outputs. To address these issues, we outline actionable approaches, including Explainable AI (XAI) techniques and privacy-preserving strategies, aimed at enabling transparency and protecting student data. We also outline frameworks that support human oversight and governance to maintain trust and accountability in Al-driven educational tools.}
}

@inproceedings{mitchellModelCardsModel2019,
  title = {Model {{Cards}} for {{Model Reporting}}},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  date = {2019-01-29},
  eprint = {1810.03993},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {220--229},
  doi = {10.1145/3287560.3287596},
  url = {http://arxiv.org/abs/1810.03993},
  urldate = {2025-03-30},
  abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related AI technology, increasing transparency into how well AI technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.}
}

@software{mozillaMozillaOchoLlamafile2025,
  title = {Mozilla-{{Ocho}}/Llamafile},
  author = {{Mozilla}},
  date = {2025-03-11T19:50:12Z},
  origdate = {2023-09-10T21:12:32Z},
  url = {https://github.com/Mozilla-Ocho/llamafile},
  urldate = {2025-03-11},
  abstract = {Distribute and run LLMs with a single file.},
  organization = {Mozilla Ocho}
}

@inproceedings{mukherjeeChatGPTBasedImage2023,
  title = {{{ChatGPT Based Image Steganography}} ({{CGIS}}): {{A Novel Intelligent Information Hiding Approach}} to {{Achieve Secure Covert Communication}}},
  shorttitle = {{{ChatGPT Based Image Steganography}} ({{CGIS}})},
  booktitle = {2023 {{First International Conference}} on {{Advances}} in {{Electrical}}, {{Electronics}} and {{Computational Intelligence}} ({{ICAEECI}})},
  author = {Mukherjee, Subhadip and Mukhopadhyay, Somnath and Sarkar, Sunita},
  date = {2023-10},
  pages = {1--5},
  doi = {10.1109/ICAEECI58247.2023.10370937},
  url = {https://ieeexplore.ieee.org/abstract/document/10370937},
  urldate = {2025-03-12},
  abstract = {Covert communication refers to the practice of exchanging information or messages in a discreet or secretive manner, with the intent of keeping the communication hidden from unintended or unauthorized recipients. Steganography is a widely used, strategy for establishing covert communication, for maintaining the privacy and security of sensitive information. Steganography ensures that the message remains concealed from surveillance or eavesdropping. Artificial Intelligence (AI) plays a crucial role in enhancing security across various domains of covert communication. ChatGPT is an AI model, specifically a natural language processing (NLP) model. It belongs to the broader category of AI models which can comprehend and produce language for humans. In this paper, a new image steganographic model named CGIS is developed for covert communication using ChatGPT. Proposed steganographic method has achieved 3.0 bpp of hiding capacity. In situations where confidentiality is critical, such as in military operations, intelligence agencies, or corporate strategies, proposed method ensures that the message cannot be detected and or extracted by any surveillance or eavesdropper.},
  eventtitle = {2023 {{First International Conference}} on {{Advances}} in {{Electrical}}, {{Electronics}} and {{Computational Intelligence}} ({{ICAEECI}})}
}

@online{obrienNebraskaTeenMother2022,
  title = {Nebraska Teen and Mother Facing Charges in Abortion-Related Case That Involved Obtaining Their {{Facebook}} Messages | {{CNN Business}}},
  author = {O'Brien, Sara and Duffy, Clare},
  date = {2022-08-10T15:00:43Z},
  url = {https://www.cnn.com/2022/08/10/tech/teen-charged-abortion-facebook-messages/index.html},
  urldate = {2024-11-26},
  abstract = {A Nebraska mother and her 18-year-old daughter are facing multiple charges in a case that involved police obtaining Facebook messages between the two that authorities allege show evidence of an illegal self-managed medication abortion, as well as a plan to hide the remains.},
  langid = {english},
  organization = {CNN}
}

@software{onnxruntimedevelopersONNXRuntime2018,
  title = {{{ONNX Runtime}}},
  author = {{ONNX Runtime developers}},
  date = {2018-11},
  origdate = {2018-11-10T02:22:53Z},
  url = {https://github.com/microsoft/onnxruntime},
  urldate = {2025-03-11},
  abstract = {ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator}
}

@online{onnxruntimeONNXRuntimeHome,
  title = {{{ONNX Runtime}} | {{Home}}},
  author = {{ONNX Runtime}},
  url = {https://onnxruntime.ai/},
  urldate = {2025-03-11},
  abstract = {Cross-platform accelerated machine learning. Built-in optimizations speed up training and inferencing with your existing technology stack.},
  langid = {english}
}

@software{openaiOpenaiTiktoken2025,
  title = {Openai/Tiktoken},
  author = {{OpenAI}},
  date = {2025-03-14T18:27:50Z},
  origdate = {2022-12-01T23:22:11Z},
  url = {https://github.com/openai/tiktoken},
  urldate = {2025-03-14},
  abstract = {tiktoken is a fast BPE tokeniser for use with OpenAI's models.},
  organization = {OpenAI}
}

@online{osiOpenSourceAI,
  title = {The {{Open Source AI Definition}} – 1.0},
  author = {{OSI}},
  url = {https://opensource.org/ai/open-source-ai-definition},
  urldate = {2025-03-27},
  abstract = {version 1.0 Preamble Why we need Open Source Artificial Intelligence (AI) Open Source has demonstrated that massive benefits accrue to everyone after removing the barriers to learning, using, sharing and…},
  langid = {american},
  organization = {Open Source Initiative}
}

@online{oversecOVERSECPrivacyAll2016,
  title = {{{OVERSEC}} - {{Privacy}} for All {{Android Apps}}},
  author = {{Oversec}},
  date = {2016},
  url = {https://www.oversec.io/},
  urldate = {2025-03-11}
}

@software{panchalShubham0204SmolChatAndroid2025,
  title = {Shubham0204/{{SmolChat-Android}}},
  author = {Panchal, Shubham},
  date = {2025-03-11T02:44:46Z},
  origdate = {2024-11-10T08:26:09Z},
  url = {https://github.com/shubham0204/SmolChat-Android},
  urldate = {2025-03-11},
  abstract = {Running any GGUF SLMs/LLMs locally, on-device in Android}
}

@article{panQuantumManybodyPhysics2025,
  title = {Quantum Many-Body Physics Calculations with Large Language Models},
  author = {Pan, Haining and Mudur, Nayantara and Taranto, William and Tikhanovskaya, Maria and Venugopalan, Subhashini and Bahri, Yasaman and Brenner, Michael P. and Kim, Eun-Ah},
  date = {2025-01-31},
  journaltitle = {Communications Physics},
  shortjournal = {Commun Phys},
  volume = {8},
  number = {1},
  pages = {1--8},
  publisher = {Nature Publishing Group},
  issn = {2399-3650},
  doi = {10.1038/s42005-025-01956-y},
  url = {https://www.nature.com/articles/s42005-025-01956-y},
  urldate = {2025-03-24},
  abstract = {Large language models (LLMs) have demonstrated abilities to perform complex tasks in multiple domains, including mathematical and scientific reasoning. We demonstrate that with carefully designed prompts, LLMs can accurately carry out key calculations in research papers in theoretical physics. We focus on a broadly-used approximation method in quantum physics: the Hartree-Fock method, requiring an analytic multi-step calculation deriving approximate Hamiltonian and corresponding self-consistency equations. To carry out the calculations using LLMs, we design multi-step prompt templates that break down the analytic calculation into standardized steps with placeholders for problem-specific information. We evaluate GPT-4’s performance in executing the calculation for 15 papers from the past decade, demonstrating that, with the correction of intermediate steps, it can correctly derive the final Hartree-Fock Hamiltonian in 13 cases. Aggregating across all research papers, we find an average score of 87.5 (out of 100) on the execution of individual calculation steps. We further use LLMs to mitigate the two primary bottlenecks in this evaluation process: (i) extracting information from papers to fill in templates and (ii) automatic scoring of the calculation steps, demonstrating good results in both cases.},
  langid = {english}
}

@article{pearsonSignalHeadDefends2025,
  entrysubtype = {newspaper},
  title = {Signal Head Defends Messaging App's Security after {{US}} War Plan Leak},
  author = {Pearson, James},
  date = {2025-03-25T22:33:08Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/world/us/signal-head-defends-messaging-apps-security-after-us-war-plan-leak-2025-03-25/},
  urldate = {2025-03-25},
  abstract = {The president of Signal defended the messaging app's security on Wednesday after top Trump administration officials mistakenly included a journalist in an encrypted chatroom they used to discuss looming U.S. military action against Yemen's Houthis.},
  journalsubtitle = {United States},
  langid = {english}
}

@article{perez-moronElevenYearsCyberattacks2021,
  title = {Eleven Years of Cyberattacks on {{Chinese}} Supply Chains in an Era of Cyber Warfare, a Review and Future Research Agenda},
  author = {Pérez-Morón, James},
  date = {2021-11-03T00:00:00Z},
  journaltitle = {Journal of Asia Business Studies},
  volume = {16},
  number = {2},
  pages = {371--395},
  publisher = {Emerald Publishing Limited},
  issn = {1558-7894},
  doi = {10.1108/JABS-11-2020-0444},
  url = {https://www.emerald.com/insight/content/doi/10.1108/jabs-11-2020-0444/full/html},
  urldate = {2025-03-26},
  abstract = {The contribution of this study aims to twofold: First, it provides an overview of the current state of research on cyberattacks on Chinese supply chains (SCs). Second, it offers a look at the Chinese Government’s approach to fighting cyberattacks on Chinese SCs and its calls for global governance.,A comprehensive literature review was conducted on Clarivate Analytics’ Web of Science, in Social Sciences Citation Index journals, Scopus and Google Scholar, published between 2010–2021. A systematic review of practitioner literature was also conducted.,Chinese SCs have become a matter of national security, especially in the era of cyber warfare. The risks to SC have been outlined. Cybersecurity regulations are increasing as China aims to build a robust environment for cyberspace development. Using the Technology-organization-environment (TOE) framework, the results show that the top five factors influencing the adoption process in firms are as follows: relative advantage and technological readiness (Technology context); top management support and firm size (Organization context) and government policy and regulations (Environment context).,This review focuses on cyberattacks on Chinese SCs and great care was taken when selecting search terms. However, the author acknowledges that the choice of databases/terms may have excluded a few articles on cyberattacks from this review.,This review provides managerial insights for SC practitioners into how cyberattacks have the potential to disrupt the global SC network.,Past researchers proposed a taxonomic approach to evaluate progress with SC integration into Industry 4.0; in contrast, this study is one of the first steps toward an enhanced understanding of cyberattacks on Chinese SCs and their contribution to the global SC network using the TOE framework.},
  langid = {english}
}

@online{perezAppleOpposesJudges2016,
  title = {Apple Opposes Judge’s Order to Hack {{San Bernardino}} Shooter’s {{iPhone}}},
  author = {Perez, Evan and Hume, Tim},
  date = {2016-02-17T02:33:06Z},
  url = {https://www.cnn.com/2016/02/16/us/san-bernardino-shooter-phone-apple/index.html},
  urldate = {2025-03-18},
  abstract = {Apple is opposing a judge’s order to help the FBI break into the iPhone of one of the San Bernardino, California, shooters.},
  langid = {english},
  organization = {CNN}
}

@online{perrigoExclusive$2Hour2023,
  title = {Exclusive: {{The}} \$2 {{Per Hour Workers Who Made ChatGPT Safer}}},
  shorttitle = {Exclusive},
  author = {Perrigo, Billy},
  date = {2023-01-18T12:00:58},
  url = {https://time.com/6247678/openai-chatgpt-kenya-workers/},
  urldate = {2025-03-27},
  abstract = {A TIME investigation reveals the difficult conditions faced by the workers who made ChatGPT possible},
  langid = {english},
  organization = {TIME}
}

@online{petitcolasInformationHidingHomepage,
  title = {The Information Hiding Homepage},
  author = {Petitcolas, Fabien A. P.},
  url = {http://www.petitcolas.net/steganography/},
  urldate = {2025-03-13},
  abstract = {The information hiding homepage},
  organization = {The information hiding homepage}
}

@article{petitcolasInformationHidingSurvey1999,
  title = {Information {{Hiding}} - {{A Survey}}},
  author = {Petitcolas, F.A.P. and Anderson, R.J. and Kuhn, M.G.},
  date = {1999-07},
  journaltitle = {Proceedings of the IEEE},
  volume = {87},
  number = {7},
  pages = {1062--1078},
  issn = {1558-2256},
  doi = {10.1109/5.771065},
  url = {https://ieeexplore.ieee.org/abstract/document/771065},
  urldate = {2025-03-23},
  abstract = {Information-hiding techniques have recently become important in a number of application areas. Digital audio, video, and pictures are increasingly furnished with distinguishing but imperceptible marks, which may contain a hidden copyright notice or serial number or even help to prevent unauthorized copying directly. Military communications systems make increasing use of traffic security techniques which, rather than merely concealing the content of a message using encryption, seek to conceal its sender, its receiver, or its very existence. Similar techniques are used in some mobile phone systems and schemes proposed for digital elections. Criminals try to use whatever traffic security properties are provided intentionally or otherwise in the available communications systems, and police forces try to restrict their use. However, many of the techniques proposed in this young and rapidly evolving field can trace their history back to antiquity, and many of them are surprisingly easy to circumvent. In this article, we try to give an overview of the field, of what we know, what works, what does not, and what are the interesting topics for research.},
  eventtitle = {Proceedings of the {{IEEE}}}
}

@online{petroniLanguageModelsKnowledge2019,
  title = {Language {{Models}} as {{Knowledge Bases}}?},
  author = {Petroni, Fabio and Rocktäschel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H. and Riedel, Sebastian},
  date = {2019-09-04},
  eprint = {1909.01066},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1909.01066},
  url = {http://arxiv.org/abs/1909.01066},
  urldate = {2025-03-19},
  abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as "fill-in-the-blank" cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.},
  pubstate = {prepublished}
}

@online{pytorchPyTorch,
  title = {{{PyTorch}}},
  author = {{PyTorch}},
  url = {https://pytorch.org/},
  urldate = {2025-03-17},
  langid = {english},
  organization = {PyTorch}
}

@software{pytorchPytorchAndroiddemoapp2025,
  title = {Pytorch/Android-Demo-App},
  author = {{PyTorch}},
  date = {2025-03-16T08:10:20Z},
  origdate = {2019-09-27T03:11:18Z},
  url = {https://github.com/pytorch/android-demo-app},
  urldate = {2025-03-17},
  abstract = {PyTorch android examples of usage in applications},
  organization = {pytorch}
}

@online{pytorchPyTorchAPIPyTorch,
  title = {{{PyTorch C}}++ {{API}} — {{PyTorch}} Main Documentation},
  author = {{PyTorch}},
  url = {https://pytorch.org/cppdocs/},
  urldate = {2025-03-29}
}

@software{pytorchPytorchExecutorch2025,
  title = {Pytorch/Executorch},
  author = {{PyTorch}},
  date = {2025-03-12T08:13:36Z},
  origdate = {2022-02-25T17:58:31Z},
  url = {https://github.com/pytorch/executorch},
  urldate = {2025-03-12},
  abstract = {On-device AI across mobile, embedded and edge for PyTorch},
  organization = {pytorch}
}

@online{pytorchStartLocally,
  title = {Start {{Locally}}},
  author = {{PyTorch}},
  url = {https://pytorch.org/get-started/locally/},
  urldate = {2025-03-29},
  abstract = {Start Locally},
  langid = {english},
  organization = {PyTorch}
}

@inproceedings{qadirReviewPaperCryptography2019,
  title = {A {{Review Paper}} on {{Cryptography}}},
  booktitle = {2019 7th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})},
  author = {Qadir, Abdalbasit Mohammed and Varol, Nurhayat},
  date = {2019-06},
  pages = {1--6},
  doi = {10.1109/ISDFS.2019.8757514},
  url = {https://ieeexplore.ieee.org/abstract/document/8757514},
  urldate = {2025-03-28},
  abstract = {With the internet having reached a level that merges with our lives, growing explosively during the last several decades, data security has become a main concern for anyone connected to the web. Data security ensures that our data is only accessible by the intended receiver and prevents any modification or alteration of data. In order to achieve this level of security, various algorithms and methods have been developed. Cryptography can be defined as techniques that cipher data, depending on specific algorithms that make the data unreadable to the human eye unless decrypted by algorithms that are predefined by the sender.},
  eventtitle = {2019 7th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})}
}

@online{qwenQwenQwen215BInstructGGUFHugging2024,
  title = {Qwen/{{Qwen2-1}}.{{5B-Instruct-GGUF}} · {{Hugging Face}}},
  author = {{Qwen}},
  date = {2024-06-14},
  url = {https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@article{raiaanReviewLargeLanguage2024,
  title = {A {{Review}} on {{Large Language Models}}: {{Architectures}}, {{Applications}}, {{Taxonomies}}, {{Open Issues}} and {{Challenges}}},
  shorttitle = {A {{Review}} on {{Large Language Models}}},
  author = {Raiaan, Mohaimenul Azam Khan and Mukta, Md. Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {26839--26874},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3365742},
  url = {https://ieeexplore.ieee.org/abstract/document/10433480},
  urldate = {2025-03-27},
  abstract = {Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.},
  eventtitle = {{{IEEE Access}}}
}

@article{rayBenchmarkingEthicalAlignment2023,
  title = {Benchmarking, Ethical Alignment, and Evaluation Framework for Conversational {{AI}}: {{Advancing}} Responsible Development of {{ChatGPT}}},
  shorttitle = {Benchmarking, Ethical Alignment, and Evaluation Framework for Conversational {{AI}}},
  author = {Ray, Partha Pratim},
  date = {2023-09-01},
  journaltitle = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
  shortjournal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
  volume = {3},
  number = {3},
  pages = {100136},
  issn = {2772-4859},
  doi = {10.1016/j.tbench.2023.100136},
  url = {https://www.sciencedirect.com/science/article/pii/S2772485923000534},
  urldate = {2025-03-27},
  abstract = {Conversational AI systems like ChatGPT have seen remarkable advancements in recent years, revolutionizing human–computer interactions. However, evaluating the performance and ethical implications of these systems remains a challenge. This paper delves into the creation of rigorous benchmarks, adaptable standards, and an intelligent evaluation methodology tailored specifically for ChatGPT. We meticulously analyze several prominent benchmarks, including GLUE, SuperGLUE, SQuAD, CoQA, Persona-Chat, DSTC, BIG-Bench, HELM and MMLU illuminating their strengths and limitations. This paper also scrutinizes the existing standards set by OpenAI, IEEE’s Ethically Aligned Design, the Montreal Declaration, and Partnership on AI’s Tenets, investigating their relevance to ChatGPT. Further, we propose adaptive standards that encapsulate ethical considerations, context adaptability, and community involvement. In terms of evaluation, we explore traditional methods like BLEU, ROUGE, METEOR, precision–recall, F1 score, perplexity, and user feedback, while also proposing a novel evaluation approach that harnesses the power of reinforcement learning. Our proposed evaluation framework is multidimensional, incorporating task-specific, real-world application, and multi-turn dialogue benchmarks. We perform feasibility analysis, SWOT analysis and adaptability analysis of the proposed framework. The framework highlights the significance of user feedback, integrating it as a core component of evaluation alongside subjective assessments and interactive evaluation sessions. By amalgamating these elements, this paper contributes to the development of a comprehensive evaluation framework that fosters responsible and impactful advancement in the field of conversational AI.}
}

@inproceedings{reegardConceptCybersecurityCulture2019,
  title = {The {{Concept}} of {{Cybersecurity Culture}}},
  author = {Reegård, Kine and Blackett, Claire and Katta, Vikash},
  date = {2019-09-27},
  doi = {10.3850/978-981-11-2724-3_0761-cd},
  abstract = {Due to a growing understanding that cybersecurity needs to be addressed also through organizational measures and not by technical measures alone, cybersecurity culture is attracting increasing attention. In this paper, we present findings from a narrative literature review of 69 papers with the purpose to identify the dimensions of cybersecurity culture and how these may be targeted by the organization. The results show that cybersecurity culture is understood as a sub-component of organizational culture comprised of layers that are increasingly more observable. Further, key practices for developing cybersecurity culture resemble those highlighted in the literature on safety culture: management support; policy; awareness and training; involvement and communication; and learning from experience. We conclude with a brief discussion of whether cybersecurity culture and safety culture are two distinct sub-components of organizational culture or can be understood to be overlapping.}
}

@article{resnikWebParallelCorpus2003,
  title = {The {{Web}} as a {{Parallel Corpus}}},
  author = {Resnik, Philip and Smith, Noah A.},
  date = {2003-09-01},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {29},
  number = {3},
  pages = {349--380},
  issn = {0891-2017},
  doi = {10.1162/089120103322711578},
  url = {https://doi.org/10.1162/089120103322711578},
  urldate = {2025-03-27},
  abstract = {Parallel corpora have become an essential resource for work in multilingual natural language processing. In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web, first reviewing the original algorithm and results and then presenting a set of significant enhancements. These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale. Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.}
}

@article{rissanenArithmeticCoding1979,
  title = {Arithmetic {{Coding}}},
  author = {Rissanen, J. and Langdon, G. G.},
  date = {1979-03},
  journaltitle = {IBM Journal of Research and Development},
  volume = {23},
  number = {2},
  pages = {149--162},
  issn = {0018-8646},
  doi = {10.1147/rd.232.0149},
  url = {https://ieeexplore.ieee.org/abstract/document/5390830},
  urldate = {2024-12-15},
  abstract = {The earlier introduced arithmetic coding idea has been generalized to a very broad and flexible coding technique which includes virtually all known variable rate noiseless coding techniques as special cases. An outstanding feature of this technique is that alphabet extensions are not required. A complete decodability analysis is given. The relationship of arithmetic coding to other known nonblock codes is illuminated.},
  eventtitle = {{{IBM Journal}} of {{Research}} and {{Development}}}
}

@online{robertsonDocumentsRevealQaedas2012,
  title = {Documents Reveal al {{Qaeda}}’s Plans for Seizing Cruise Ships, Carnage in {{Europe}}},
  author = {Robertson, Nic and Cruickshank, Paul and Lister, Tim},
  date = {2012-04-30T19:08:07Z},
  url = {https://www.cnn.com/2012/04/30/world/al-qaeda-documents-future/index.html},
  urldate = {2025-02-18},
  abstract = {CNN has obtained access to details of al Qaeda documents which shed light on future plans including seizing cruise ships and causing carnage in Europe.},
  langid = {english},
  organization = {CNN}
}

@article{rubinArithmeticStreamCoding1979,
  title = {Arithmetic Stream Coding Using Fixed Precision Registers},
  author = {Rubin, F.},
  date = {1979-11},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {25},
  number = {6},
  pages = {672--675},
  issn = {1557-9654},
  doi = {10.1109/TIT.1979.1056107},
  url = {https://ieeexplore.ieee.org/abstract/document/1056107},
  urldate = {2025-03-14},
  abstract = {Algorithms are presented for encoding and decoding strings of characters as real binary fractions, using registers of fixed precision. The encoding is left to right and does not require blocking. The algorithms have storage requirementsO(N)and computation timeO(n łog\_2N)for string lengthnand alphabet sizeN.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}}
}

@article{ruggiaDarkSideNative2025,
  title = {The {{Dark Side}} of {{Native Code}} on {{Android}}},
  author = {Ruggia, Antonio and Possemato, Andrea and Dambra, Savino and Merlo, Alessio and Aonzo, Simone and Balzarotti, Davide},
  date = {2025-02-22},
  journaltitle = {ACM Trans. Priv. Secur.},
  volume = {28},
  number = {2},
  pages = {13:1--13:33},
  issn = {2471-2566},
  doi = {10.1145/3712308},
  url = {https://dl.acm.org/doi/10.1145/3712308},
  urldate = {2025-03-29},
  abstract = {From a little research experiment to an essential component of military arsenals, malicious software has constantly been growing and evolving for more than three decades. On the other hand, from a negligible market share, the Android operating system is nowadays the most widely used mobile operating system, becoming a desirable target for large-scale malware distribution. While scientific literature has followed this trend, one aspect has been understudied: the role of native code in malicious Android apps. Android apps are written in high-level languages, but thanks to the Java Native Interface (JNI), Android also supports calling native (C/C++) library functions. While allowing native code in Android apps has a strong positive impact from a performance perspective, it dramatically complicates its analysis because bytecode and native code need different abstractions and analysis algorithms, and they thus pose different challenges and limitations. Consequently, these difficulties are often (ab)used to hide malicious payloads.In this work, we propose a novel methodology to reverse engineering Android apps focusing on suspicious patterns related to native components, i.e., surreptitious code that requires further inspection. We implemented a static analysis tool based on such methodology, which can bridge the “Java” and the native worlds and perform an in-depth analysis of tag code blocks responsible for suspicious behavior. These tags benefit the human facing the reverse engineering task: they clearly indicate which part of the code to focus on to find malicious code.Then, we performed a longitudinal analysis of Android malware over the past 10 years and compared the recent malicious samples with actual top apps on the Google Play Store. Our work depicts typical behaviors of modern malware, its evolution, and how it abuses the native layer to complicate the analysis, especially with dynamic code loading and novel anti-analysis techniques. Finally, we show a use case for our suspicious tags: we trained and tested a machine learning algorithm for a binary classification task. Even if suspicious does not imply malicious, our classifier obtained a remarkable F1-score of 0.97, showing that our methodology can be helpful to both humans and machines.}
}

@inproceedings{salleeModelBasedSteganography2004,
  title = {Model-{{Based Steganography}}},
  booktitle = {Digital {{Watermarking}}},
  author = {Sallee, Phil},
  editor = {Kalker, Ton and Cox, Ingemar and Ro, Yong Man},
  date = {2004},
  pages = {154--167},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-24624-4_12},
  abstract = {This paper presents an information-theoretic method for performing steganography and steganalysis using a statistical model of the cover medium. The methodology is general, and can be applied to virtually any type of media. It provides answers for some fundamental questions which have not been fully addressed by previous steganographic methods, such as how large a message can be hidden without risking detection by certain statistical methods, and how to achieve this maximum capacity. Current steganographic methods have been shown to be insecure against fairly simple statistical attacks. Using the model-based methodology, an example steganography method is proposed for JPEG images which achieves a higher embedding efficiency and message capacity than previous methods while remaining secure against first order statistical attacks.},
  isbn = {978-3-540-24624-4},
  langid = {english}
}

@article{satterSignalAppChoice2025,
  entrysubtype = {newspaper},
  title = {Signal Is App of Choice for {{Trump}} Allies and Opponents Alike},
  author = {Satter, Raphael},
  date = {2025-03-25T17:36:54Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/signal-is-app-choice-trump-allies-opponents-alike-2025-03-25/},
  urldate = {2025-03-25},
  abstract = {Elon Musk's team working to dismantle the federal bureaucracy and the protesters hoping to stop him have something in common.},
  journalsubtitle = {Technology},
  langid = {english}
}

@online{schmidgallAgentLaboratoryUsing2025,
  title = {Agent {{Laboratory}}: {{Using LLM Agents}} as {{Research Assistants}}},
  shorttitle = {Agent {{Laboratory}}},
  author = {Schmidgall, Samuel and Su, Yusheng and Wang, Ze and Sun, Ximeng and Wu, Jialian and Yu, Xiaodong and Liu, Jiang and Liu, Zicheng and Barsoum, Emad},
  date = {2025-01-08},
  eprint = {2501.04227},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.04227},
  url = {http://arxiv.org/abs/2501.04227},
  urldate = {2025-03-24},
  abstract = {Historically, scientific discovery has been a lengthy and costly process, demanding substantial time and resources from initial conception to final results. To accelerate scientific discovery, reduce research costs, and improve research quality, we introduce Agent Laboratory, an autonomous LLM-based framework capable of completing the entire research process. This framework accepts a human-provided research idea and progresses through three stages--literature review, experimentation, and report writing to produce comprehensive research outputs, including a code repository and a research report, while enabling users to provide feedback and guidance at each stage. We deploy Agent Laboratory with various state-of-the-art LLMs and invite multiple researchers to assess its quality by participating in a survey, providing human feedback to guide the research process, and then evaluate the final paper. We found that: (1) Agent Laboratory driven by o1-preview generates the best research outcomes; (2) The generated machine learning code is able to achieve state-of-the-art performance compared to existing methods; (3) Human involvement, providing feedback at each stage, significantly improves the overall quality of research; (4) Agent Laboratory significantly reduces research expenses, achieving an 84\% decrease compared to previous autonomous research methods. We hope Agent Laboratory enables researchers to allocate more effort toward creative ideation rather than low-level coding and writing, ultimately accelerating scientific discovery.},
  pubstate = {prepublished}
}

@online{schneierTerroristsScienceHiding2001,
  title = {Terrorists and the Science of Hiding Messages},
  author = {Schneier, Bruce},
  date = {2001-09-25},
  url = {https://www.zdnet.com/article/terrorists-and-the-science-of-hiding-messages/},
  urldate = {2025-01-09},
  abstract = {Security expert Bruce Schneier writes that terrorist groups may be using steganography to communicate, allowing communication without any group knowing the identity of the other.},
  langid = {english}
}

@online{schneierTerroristsSteganography2001,
  title = {Terrorists and Steganography},
  author = {Schneier, Bruce},
  date = {2001-09-23},
  url = {https://www.zdnet.com/article/terrorists-and-steganography/},
  urldate = {2025-02-18},
  abstract = {Security expert Bruce Schneier writes that terrorist groups may be using steganography to communicate, allowing communication without any group knowing the identity of the other.},
  langid = {english},
  organization = {ZDNET}
}

@online{sennrichNeuralMachineTranslation2016,
  title = {Neural {{Machine Translation}} of {{Rare Words}} with {{Subword Units}}},
  author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  date = {2016-06-10},
  eprint = {1508.07909},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1508.07909},
  url = {http://arxiv.org/abs/1508.07909},
  urldate = {2025-03-12},
  abstract = {Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.},
  pubstate = {prepublished}
}

@article{serpanosCyberwarfareUkraine2022,
  title = {The {{Cyberwarfare}} in {{Ukraine}}},
  author = {Serpanos, Dimitrios and Komninos, Theodoros},
  date = {2022-07},
  journaltitle = {Computer},
  volume = {55},
  number = {7},
  pages = {88--91},
  issn = {1558-0814},
  doi = {10.1109/MC.2022.3170644},
  url = {https://ieeexplore.ieee.org/abstract/document/9810126},
  urldate = {2025-03-26},
  abstract = {The hybrid war in Ukraine is shaping cybersecurity for critical infrastructures and services worldwide. The events will be changing cybersecurity processes worldwide for a long time beyond the resolution of the conflict.},
  eventtitle = {Computer}
}

@article{shannonCommunicationTheorySecrecy1949,
  title = {Communication Theory of Secrecy Systems},
  author = {Shannon, C. E.},
  date = {1949-10},
  journaltitle = {The Bell System Technical Journal},
  volume = {28},
  number = {4},
  pages = {656--715},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1949.tb00928.x},
  url = {https://ieeexplore.ieee.org/document/6769090},
  urldate = {2025-03-13},
  abstract = {THE problems of cryptography and secrecy systems furnish an interesting application of communication theory.1 In this paper a theory of secrecy systems is developed. The approach is on a theoretical level and is intended to complement the treatment found in standard works on cryptography.2 There, a detailed study is made of the many standard types of codes and ciphers, and of the ways of breaking them. We will be more concerned with the general mathematical structure and properties of secrecy systems.},
  eventtitle = {The {{Bell System Technical Journal}}}
}

@online{shiCodeCorrectnessClosing2024,
  title = {From {{Code}} to {{Correctness}}: {{Closing}} the {{Last Mile}} of {{Code Generation}} with {{Hierarchical Debugging}}},
  shorttitle = {From {{Code}} to {{Correctness}}},
  author = {Shi, Yuling and Wang, Songsong and Wan, Chengcheng and Gu, Xiaodong},
  date = {2024-10-05},
  eprint = {2410.01215},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.01215},
  url = {http://arxiv.org/abs/2410.01215},
  urldate = {2025-03-24},
  abstract = {While large language models have made significant strides in code generation, the pass rate of the generated code is bottlenecked on subtle errors, often requiring human intervention to pass tests, especially for complex problems. Existing LLM-based debugging systems treat generated programs as monolithic units, failing to address bugs at multiple levels of granularity, from low-level syntax errors to high-level algorithmic flaws. In this paper, we introduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger by isolating, identifying, and resolving bugs at various levels of granularity. MGDebugger decomposes problematic code into a hierarchical tree structure of subfunctions, with each level representing a particular granularity of error. During debugging, it analyzes each subfunction and iteratively resolves bugs in a bottom-up manner. To effectively test each subfunction, we propose an LLM-simulated Python executor, which traces code execution and tracks important variable states to pinpoint errors accurately. Extensive experiments demonstrate that MGDebugger outperforms existing debugging systems, achieving an 18.9\% improvement in accuracy over seed generations in HumanEval and a 97.6\% repair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes bugs across different categories and difficulty levels, demonstrating its robustness and effectiveness.},
  pubstate = {prepublished}
}

@inproceedings{shirali-shahrezaNewApproachPersian2006,
  title = {A {{New Approach}} to {{Persian}}/{{Arabic Text Steganography}}},
  booktitle = {5th {{IEEE}}/{{ACIS International Conference}} on {{Computer}} and {{Information Science}} and 1st {{IEEE}}/{{ACIS International Workshop}} on {{Component-Based Software Engineering}},{{Software Architecture}} and {{Reuse}} ({{ICIS-COMSAR}}'06)},
  author = {Shirali-Shahreza, M.H. and Shirali-Shahreza, M.},
  date = {2006-07},
  pages = {310--315},
  doi = {10.1109/ICIS-COMSAR.2006.10},
  url = {https://ieeexplore.ieee.org/abstract/document/1652009},
  urldate = {2025-03-23},
  abstract = {Conveying information secretly and establishing hidden relationship has been of interest since long past. Text documents have been widely used since very long time ago. Therefore, we have witnessed different method of hiding information in texts (text steganography) since past to the present. In this paper we introduce a new approach for steganography in Persian and Arabic texts. Considering the existence of too many points in Persian and Arabic phrases, in this approach, by vertical displacement of the points, we hide information in the texts. This approach can be categorized under feature coding methods. This method can be used for Persian/Arabic watermarking. Our method has been implemented by Java programming language},
  eventtitle = {5th {{IEEE}}/{{ACIS International Conference}} on {{Computer}} and {{Information Science}} and 1st {{IEEE}}/{{ACIS International Workshop}} on {{Component-Based Software Engineering}},{{Software Architecture}} and {{Reuse}} ({{ICIS-COMSAR}}'06)}
}

@inproceedings{shirali-shahrezaTextSteganographySMS2007,
  title = {Text {{Steganography}} in {{SMS}}},
  booktitle = {2007 {{International Conference}} on {{Convergence Information Technology}} ({{ICCIT}} 2007)},
  author = {Shirali-Shahreza, Mohammad and Shirali-Shahreza, M. Hassan},
  date = {2007-11},
  pages = {2260--2265},
  doi = {10.1109/ICCIT.2007.100},
  url = {https://ieeexplore.ieee.org/abstract/document/4420590},
  urldate = {2025-03-08},
  abstract = {One of the services used in mobile phone is the short message service (SMS) which is widely used by the public in all parts of the world especially in Asia and Europe. This service enables people to write and exchange short messages via mobile phone. Due to the limited size of SMS, lack of a proper keyboard on the mobile phone and to improve the speed of typing, new abbreviations have been invented for different words and phrases which has lead to the invention of a new language called SMS-texting. One of the main issues in communication is information security and privacy. There are many methods for secret communication and many researchers are working on steganography. In steganography the data is hidden in a cover media such as picture or text. The present paper offers a new method for secret exchange of information through SMS by using and developing abbreviation text steganography with the use of the invented language of SMS-texting. This project has been implemented by J2ME (Java 2 Micro Edition) programming language and tested on a Nokia N71 mobile phone.},
  eventtitle = {2007 {{International Conference}} on {{Convergence Information Technology}} ({{ICCIT}} 2007)}
}

@online{shragerELIZAReinterpretedWorlds2024,
  title = {{{ELIZA Reinterpreted}}: {{The}} World's First Chatbot Was Not Intended as a Chatbot at All},
  shorttitle = {{{ELIZA Reinterpreted}}},
  author = {Shrager, Jeff},
  date = {2024-09-19},
  eprint = {2406.17650},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.17650},
  url = {http://arxiv.org/abs/2406.17650},
  urldate = {2025-03-27},
  abstract = {ELIZA, often considered the world's first chatbot, was written by Joseph Weizenbaum in the early 1960s. Weizenbaum did not intend to invent the chatbot, but rather to build a platform for research into human-machine conversation and the important cognitive processes of interpretation and misinterpretation. His purpose was obscured by ELIZA's fame, resulting in large part from the fortuitous timing of it's creation, and it's escape into the wild. In this paper I provide a rich historical context for ELIZA's creation, demonstrating that ELIZA arose from the intersection of some of the central threads in the technical history of AI. I also briefly discuss how ELIZA escaped into the world, and how its accidental escape, along with several coincidental turns of the programming language screws, led both to the misapprehension that ELIZA was intended as a chatbot, and to the loss of the original ELIZA to history for over 50 years.},
  pubstate = {prepublished}
}

@online{shumailovCurseRecursionTraining2024,
  title = {The {{Curse}} of {{Recursion}}: {{Training}} on {{Generated Data Makes Models Forget}}},
  shorttitle = {The {{Curse}} of {{Recursion}}},
  author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  date = {2024-04-14},
  eprint = {2305.17493},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.17493},
  url = {http://arxiv.org/abs/2305.17493},
  urldate = {2025-03-19},
  abstract = {Stable Diffusion revolutionised image creation from descriptive text. GPT-2, GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of language tasks. ChatGPT introduced such language models to the general public. It is now clear that large language models (LLMs) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to GPT-\{n\} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of content generated by LLMs in data crawled from the Internet.},
  pubstate = {prepublished}
}

@online{smithEffectiveSecurityObscurity2022,
  title = {Effective {{Security}} by {{Obscurity}}},
  author = {Smith, J. Christian},
  date = {2022-04-30},
  eprint = {2205.01547},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.01547},
  url = {http://arxiv.org/abs/2205.01547},
  urldate = {2025-03-28},
  abstract = {"Security by obscurity" is a bromide which is frequently applied to undermine the perceived value of a certain class of techniques in security. This usage initially stemmed from applications and experience in the areas of cryptographic theory, and the open vs. closed source debate. Through the perceived absence of true security, the field of security by obscurity has not coalesced into a viable or recognizable approach for security practitioners. The ramifications of this has resulted in these techniques going underused and underappreciated by defenders, while they continue to provide value to attackers, which creates an unfortunate information asymmetry. Exploring effective methods for employing security by obscurity, it can be seen that examples are already embedded unrecognized in other viable security disciplines, such as information hiding, obfuscation, diversity, and moving target defense. In showing that obscurity measures are an achievable and desirable supplement to other security measures, it is apparent that the in-depth defense of an organization's assets can be enhanced by intentional and effective use of security by obscurity.},
  pubstate = {prepublished}
}

@article{soltanipanahPropertiesNonMediaDigital2016,
  title = {On the {{Properties}} of {{Non-Media Digital Watermarking}}: {{A Review}} of {{State}} of the {{Art Techniques}}},
  shorttitle = {On the {{Properties}} of {{Non-Media Digital Watermarking}}},
  author = {Soltani Panah, Arezou and Van Schyndel, Ron and Sellis, Timos and Bertino, Elisa},
  date = {2016},
  journaltitle = {IEEE Access},
  volume = {4},
  pages = {2670--2704},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2016.2570812},
  url = {https://ieeexplore.ieee.org/document/7473843},
  urldate = {2025-03-27},
  abstract = {Over the last 25 years, there has been much work on multimedia digital watermarking. In this domain, the primary limitation to watermark strength has been in its visibility. For multimedia watermarks, invisibility is defined in human terms (that is, in terms of human sensory limitations). In this paper, we review recent developments in the non-media applications of data watermarking, which have emerged over the last decade as an exciting new sub-domain. Since by definition, the intended receiver should be able to detect the watermark, we have to redefine invisibility in an acceptable way that is often application-specific and thus cannot be easily generalized. In particular, this is true when the data is not intended to be directly consumed by humans. For example, a loose definition of robustness might be in terms of the resilience of a watermark against normal host data operations, and of invisibility as resilience of the data interpretation against change introduced by the watermark. In this paper, we classify the data in terms of data mining rules on complex types of data such as time-series, symbolic sequences, data streams, and so forth. We emphasize the challenges involved in non-media watermarking in terms of common watermarking properties, including invisibility, capacity, robustness, and security. With the aid of a few examples of watermarking applications, we demonstrate these distinctions and we look at the latest research in this regard to make our argument clear and more meaningful. As the last aim, we look at the new challenges of digital watermarking that have arisen with the evolution of big data.},
  eventtitle = {{{IEEE Access}}}
}

@online{songLLMFeynmanLeveragingLarge2025,
  title = {{{LLM-Feynman}}: {{Leveraging Large Language Models}} for {{Universal Scientific Formula}} and {{Theory Discovery}}},
  shorttitle = {{{LLM-Feynman}}},
  author = {Song, Zhilong and Ju, Minggang and Ren, Chunjin and Li, Qiang and Li, Chongyi and Zhou, Qionghua and Wang, Jinlan},
  date = {2025-03-09},
  eprint = {2503.06512},
  eprinttype = {arXiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2503.06512},
  url = {http://arxiv.org/abs/2503.06512},
  urldate = {2025-03-24},
  abstract = {Distilling the underlying principles from data has long propelled scientific breakthroughs. However, conventional data-driven machine learning -- lacking deep, contextual domain knowledge -- tend to yield opaque or over-complex models that are challenging to interpret and generalize. Here, we present LLM-Feynman, a framework that leverages the embedded expertise of large language models (LLMs) with systematic optimization to distill concise, interpretable formula from data and domain knowledge. Our framework seamlessly integrates automated feature engineering, LLM-based symbolic regression augmented by self-evaluation and iterative refinement, and formula interpretation via Monte Carlo tree search. Ablation studies show that incorporating domain knowledge and self-evaluation yields more accurate formula at equivalent formula complexity than conventional symbolic regression. Validation on datasets from Feynman physics lectures confirms that LLM-Feynman can rediscover over 90\% real physical formulas. Moreover, when applied to four key materials science tasks -- from classifying the synthesizability of 2D and perovskite structures to predicting ionic conductivity in lithium solid-state electrolytes and GW bandgaps in 2D materials -- LLM-Feynman consistently yields interpretable formula with accuracy exceeding 90\% and R2 values above 0.8. By transcending mere data fitting through the integration of deep domain knowledge, LLM-Feynman establishes a new paradigm for the automated discovery of generalizable scientific formula and theory across disciplines.},
  pubstate = {prepublished}
}

@article{soniOpenAIOutlinesNew2025,
  entrysubtype = {newspaper},
  title = {{{OpenAI}} Outlines New For-Profit Structure in Bid to Stay Ahead in Costly {{AI}} Race},
  author = {Soni, Aditya and Bajwa, Arsheeya and Hu, Krystal},
  date = {2025-01-02T20:17:57Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/artificial-intelligence/openai-lays-out-plan-shift-new-for-profit-structure-2024-12-27/},
  urldate = {2025-03-27},
  abstract = {OpenAI on Friday outlined plans to revamp its structure, saying it would create a public benefit corporation to make it easier to "raise more capital than we'd imagined," and remove the restrictions imposed on the startup by its current nonprofit parent.},
  journalsubtitle = {Artificial Intelligence},
  langid = {english}
}

@online{spammimicSpammimic2000,
  title = {Spammimic},
  author = {{Spammimic}},
  date = {2000},
  url = {https://www.spammimic.com/},
  urldate = {2025-03-11},
  abstract = {and you thought spam was useless},
  langid = {english}
}

@software{srivastavaBhrigu123Huffmancoding2025,
  title = {Bhrigu123/Huffman-Coding},
  author = {Srivastava, Bhrigu},
  date = {2025-03-09T06:50:15Z},
  origdate = {2017-01-18T13:17:33Z},
  url = {https://github.com/bhrigu123/huffman-coding},
  urldate = {2025-03-20},
  abstract = {Python Implementaion of Huffman Coding - compression and decompression}
}

@inproceedings{steinebachNaturalLanguageSteganography2024,
  title = {Natural {{Language Steganography}} by {{ChatGPT}}},
  booktitle = {Proceedings of the 19th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Steinebach, Martin},
  date = {2024-07-30},
  series = {{{ARES}} '24},
  pages = {1--9},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3664476.3670930},
  url = {https://dl.acm.org/doi/10.1145/3664476.3670930},
  urldate = {2024-11-12},
  abstract = {Natural language steganography as well as natural language watermarking have been challenging because of the complexity and lack of noise in natural language. But with the advent of LLMs like ChatGPT, controlled synthesis of written language has become available. In this work, we show how ChatGPT can be utilized to generate synthetic texts of a given topic that act as stego covers for hidden messages.},
  isbn = {979-8-4007-1718-5}
}

@article{sufiSocialMediaAnalytics2023,
  title = {Social {{Media Analytics}} on {{Russia}}–{{Ukraine Cyber War}} with {{Natural Language Processing}}: {{Perspectives}} and {{Challenges}}},
  shorttitle = {Social {{Media Analytics}} on {{Russia}}–{{Ukraine Cyber War}} with {{Natural Language Processing}}},
  author = {Sufi, Fahim},
  date = {2023-09},
  journaltitle = {Information},
  volume = {14},
  number = {9},
  pages = {485},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info14090485},
  url = {https://www.mdpi.com/2078-2489/14/9/485},
  urldate = {2025-03-26},
  abstract = {Utilizing social media data is imperative in comprehending critical insights on the Russia–Ukraine cyber conflict due to their unparalleled capacity to provide real-time information dissemination, thereby enabling the timely tracking and analysis of cyber incidents. The vast array of user-generated content on these platforms, ranging from eyewitness accounts to multimedia evidence, serves as invaluable resources for corroborating and contextualizing cyber attacks, facilitating the attribution of malicious actors. Furthermore, social media data afford unique access to public sentiment, the propagation of propaganda, and emerging narratives, offering profound insights into the effectiveness of information operations and shaping counter-messaging strategies. However, there have been hardly any studies reported on the Russia–Ukraine cyber war harnessing social media analytics. This paper presents a comprehensive analysis of the crucial role of social-media-based cyber intelligence in understanding Russia’s cyber threats during the ongoing Russo–Ukrainian conflict. This paper introduces an innovative multidimensional cyber intelligence framework and utilizes Twitter data to generate cyber intelligence reports. By leveraging advanced monitoring tools and NLP algorithms, like language detection, translation, sentiment analysis, term frequency–inverse document frequency (TF-IDF), latent Dirichlet allocation (LDA), Porter stemming, n-grams, and others, this study automatically generated cyber intelligence for Russia and Ukraine. Using 37,386 tweets originating from 30,706 users in 54 languages from 13 October 2022 to 6 April 2023, this paper reported the first detailed multilingual analysis on the Russia–Ukraine cyber crisis in four cyber dimensions (geopolitical and socioeconomic; targeted victim; psychological and societal; and national priority and concerns). It also highlights challenges faced in harnessing reliable social-media-based cyber intelligence.},
  issue = {9},
  langid = {english}
}

@online{tarkowskiDataGovernanceOpen2025,
  title = {Data {{Governance}} in {{Open Source AI}}},
  author = {Tarkowski, Alek},
  date = {2025-02-03},
  url = {https://opensource.org/data-governance-open-source-ai},
  urldate = {2025-03-27},
  abstract = {Data Governance in Open Source AI},
  langid = {american},
  organization = {Open Source Initiative}
}

@video{tedGlennGreenwaldWhy2014,
  entrysubtype = {video},
  title = {Glenn {{Greenwald}}: {{Why}} Privacy Matters},
  shorttitle = {Glenn {{Greenwald}}},
  editor = {{TED}},
  editortype = {director},
  date = {2014-10-10},
  url = {https://www.youtube.com/watch?v=pcSlowAhvUk},
  urldate = {2025-03-11}
}

@online{tensorflowAPIDocumentationTensorFlow,
  title = {{{API Documentation}} | {{TensorFlow}} v2.16.1},
  author = {{TensorFlow}},
  url = {https://www.tensorflow.org/api_docs},
  urldate = {2025-03-29},
  abstract = {An open source machine learning library for research and production.},
  langid = {english},
  organization = {TensorFlow}
}

@online{tensorflowTensorFlow,
  title = {{{TensorFlow}}},
  author = {{TensorFlow}},
  url = {https://www.tensorflow.org/},
  urldate = {2025-03-29},
  abstract = {An end-to-end open source machine learning platform for everyone. Discover TensorFlow's flexible ecosystem of tools, libraries and community resources.},
  langid = {english},
  organization = {TensorFlow}
}

@article{thabitComparativeAnalysisArabic2021,
  title = {A {{Comparative Analysis}} of {{Arabic Text Steganography}}},
  author = {Thabit, Reema and Udzir, Nur Izura and Yasin, Sharifah Md and Asmawi, Aziah and Roslan, Nuur Alifah and Din, Roshidi},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {15},
  pages = {6851},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app11156851},
  url = {https://www.mdpi.com/2076-3417/11/15/6851},
  urldate = {2025-03-12},
  abstract = {Protecting sensitive information transmitted via public channels is a significant issue faced by governments, militaries, organizations, and individuals. Steganography protects the secret information by concealing it in a transferred object such as video, audio, image, text, network, or DNA. As text uses low bandwidth, it is commonly used by Internet users in their daily activities, resulting a vast amount of text messages sent daily as social media posts and documents. Accordingly, text is the ideal object to be used in steganography, since hiding a secret message in a text makes it difficult for the attacker to detect the hidden message among the massive text content on the Internet. Language’s characteristics are utilized in text steganography. Despite the richness of the Arabic language in linguistic characteristics, only a few studies have been conducted in Arabic text steganography. To draw further attention to Arabic text steganography prospects, this paper reviews the classifications of these methods from its inception. For analysis, this paper presents a comprehensive study based on the key evaluation criteria (i.e., capacity, invisibility, robustness, and security). It opens new areas for further research based on the trends in this field.},
  issue = {15},
  langid = {english}
}

@inproceedings{thakkarDeepfakesDigitalTruths2024,
  title = {From {{Deepfakes}} to {{Digital Truths}}: {{The Role}} of {{Watermarking}} in {{AI-Generated Image Verification}}},
  shorttitle = {From {{Deepfakes}} to {{Digital Truths}}},
  booktitle = {2024 47th {{International Conference}} on {{Telecommunications}} and {{Signal Processing}} ({{TSP}})},
  author = {Thakkar, Jinal Jagdishkumar and Kaur, Arashdeep},
  date = {2024-07},
  pages = {216--222},
  issn = {2768-3311},
  doi = {10.1109/TSP63128.2024.10605975},
  url = {https://ieeexplore.ieee.org/abstract/document/10605975},
  urldate = {2025-03-31},
  abstract = {The evolution of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) has introduced deepfake technology. Deepfake technology is a form of digital manipulation that alters video, image, and audio content with the help of Generative AI. Those deepfakes have increased concerns in various fields, including education, art, and they also raise ethical and security concerns due to their potential for deceptive content. Reviewing the increasing challenge of identifying high-quality deepfakes, there's a pressing need for robust measures to counter them. This review explores various watermarking techniques and their use to protect content authenticity and origin. Watermarking embeds a subtle watermark and provides a strong defense against deepfake technologies and similar AI-driven tools. The paper discusses current watermarking methods, their strengths and weaknesses, and potential improvements to verify AI-generated content.},
  eventtitle = {2024 47th {{International Conference}} on {{Telecommunications}} and {{Signal Processing}} ({{TSP}})}
}

@online{tianDebugBenchEvaluatingDebugging2024,
  title = {{{DebugBench}}: {{Evaluating Debugging Capability}} of {{Large Language Models}}},
  shorttitle = {{{DebugBench}}},
  author = {Tian, Runchu and Ye, Yining and Qin, Yujia and Cong, Xin and Lin, Yankai and Pan, Yinxu and Wu, Yesai and Hui, Haotian and Liu, Weichuan and Liu, Zhiyuan and Sun, Maosong},
  date = {2024-06-06},
  eprint = {2401.04621},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.04621},
  url = {http://arxiv.org/abs/2401.04621},
  urldate = {2025-03-24},
  abstract = {Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs' debugging ability are significantly limited by the risk of data leakage, the scale of the dataset, and the variety of tested bugs. To overcome these deficiencies, we introduce `DebugBench', an LLM debugging benchmark consisting of 4,253 instances. It covers four major bug categories and 18 minor types in C++, Java, and Python. To construct DebugBench, we collect code snippets from the LeetCode community, implant bugs into source data with GPT-4, and assure rigorous quality checks. We evaluate two commercial and four open-source models in a zero-shot scenario. We find that (1) while closed-source models exhibit inferior debugging performance compared to humans, open-source models relatively lower pass rate scores; (2) the complexity of debugging notably fluctuates depending on the bug category; (3) incorporating runtime feedback has a clear impact on debugging performance which is not always helpful. As an extension, we also compare LLM debugging and code generation, revealing a strong correlation between them for closed-source models. These findings will benefit the development of LLMs in debugging.},
  pubstate = {prepublished}
}

@article{titcombMillionsPeoplesDNA2025,
  entrysubtype = {newspaper},
  title = {Millions of People’s {{DNA}} up for Sale as {{23andMe}} Goes Bankrupt},
  author = {Titcomb, James},
  date = {2025-03-24},
  journaltitle = {The Telegraph},
  issn = {0307-1235},
  url = {https://www.telegraph.co.uk/business/2025/03/24/millions-of-peoples-dna-up-for-sale-as-23andme-goes-bankrup/},
  urldate = {2025-03-26},
  abstract = {Customers urged to consider deleting their data after genetic testing company collapses},
  langid = {british}
}

@online{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  date = {2023-02-27},
  eprint = {2302.13971},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.13971},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2025-03-28},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
  pubstate = {prepublished}
}

@article{traynorMerkelComparedNSA2013,
  entrysubtype = {newspaper},
  title = {Merkel Compared {{NSA}} to {{Stasi}} in Heated Encounter with {{Obama}}},
  author = {Traynor, Ian and Lewis, Paul},
  date = {2013-12-17T18:23:22},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/dec/17/merkel-compares-nsa-stasi-obama},
  urldate = {2025-03-26},
  abstract = {German chancellor furious after revelations US intelligence agency listened in on her personal mobile phone},
  journalsubtitle = {World news},
  langid = {british}
}

@online{turnerIntroductionTransformers2024,
  title = {An {{Introduction}} to {{Transformers}}},
  author = {Turner, Richard E.},
  date = {2024-02-08},
  eprint = {2304.10557},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.10557},
  url = {http://arxiv.org/abs/2304.10557},
  urldate = {2025-03-12},
  abstract = {The transformer is a neural network component that can be used to learn useful representations of sequences or sets of data-points. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture. We will not discuss training as this is rather standard. We assume that the reader is familiar with fundamental topics in machine learning including multi-layer perceptrons, linear transformations, softmax functions and basic probability.},
  pubstate = {prepublished},
  version = {5}
}

@online{united4iranNahoft2021,
  title = {Nahoft},
  author = {{United 4 Iran}},
  date = {2021},
  url = {https://nahoftapp.com/index-en.html},
  urldate = {2025-03-11}
}

@software{united4iranU4iadminNahoft2025,
  title = {U4i-Admin/{{Nahoft}}},
  author = {{United 4 Iran}},
  date = {2025-01-09T21:35:47Z},
  origdate = {2021-07-22T16:06:15Z},
  url = {https://github.com/u4i-admin/Nahoft},
  urldate = {2025-03-24},
  organization = {U4I}
}

@software{vali-98Vali98ChatterUI2025,
  title = {Vali-98/{{ChatterUI}}},
  author = {{Vali-98}},
  date = {2025-03-11T17:42:50Z},
  origdate = {2023-10-18T11:28:06Z},
  url = {https://github.com/Vali-98/ChatterUI},
  urldate = {2025-03-11},
  abstract = {Simple frontend for LLMs built in react-native.}
}

@online{vandersarMetaTorrented812025,
  title = {'{{Meta Torrented}} over 81 {{TB}} of {{Data Through Anna}}'s {{Archive}}, {{Despite Few Seeders}}' * {{TorrentFreak}}},
  author = {Van der Sar, Ernesto},
  date = {2025-02-06},
  url = {https://torrentfreak.com/meta-torrented-over-81-tb-of-data-through-annas-archive-despite-few-seeders-250206/},
  urldate = {2025-03-19}
}

@online{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2023-08-02},
  eprint = {1706.03762},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2024-12-28},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {prepublished}
}

@online{vendrowLargeLanguageModel2025,
  title = {Do {{Large Language Model Benchmarks Test Reliability}}?},
  author = {Vendrow, Joshua and Vendrow, Edward and Beery, Sara and Madry, Aleksander},
  date = {2025-02-05},
  eprint = {2502.03461},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.03461},
  url = {http://arxiv.org/abs/2502.03461},
  urldate = {2025-03-24},
  abstract = {When deploying large language models (LLMs), it is important to ensure that these models are not only capable, but also reliable. Many benchmarks have been created to track LLMs' growing capabilities, however there has been no similar focus on measuring their reliability. To understand the potential ramifications of this gap, we investigate how well current benchmarks quantify model reliability. We find that pervasive label errors can compromise these evaluations, obscuring lingering model failures and hiding unreliable behavior. Motivated by this gap in the evaluation of reliability, we then propose the concept of so-called platinum benchmarks, i.e., benchmarks carefully curated to minimize label errors and ambiguity. As a first attempt at constructing such benchmarks, we revise examples from fifteen existing popular benchmarks. We evaluate a wide range of models on these platinum benchmarks and find that, indeed, frontier LLMs still exhibit failures on simple tasks such as elementary-level math word problems. Analyzing these failures further reveals previously unidentified patterns of problems on which frontier models consistently struggle. We provide code at https://github.com/MadryLab/platinum-benchmarks},
  pubstate = {prepublished}
}

@article{wangELIZAChatGPTBrief2024,
  title = {From {{ELIZA}} to {{ChatGPT}}: {{A}} Brief History of Chatbots and Their Evolution},
  shorttitle = {From {{ELIZA}} to {{ChatGPT}}},
  author = {Wang, Kaicheng},
  date = {2024-02-21},
  journaltitle = {Applied and Computational Engineering},
  volume = {39},
  pages = {57--62},
  issn = {2755-273X},
  doi = {10.54254/2755-2721/39/20230579},
  url = {https://www.ewadirect.com/proceedings/ace/article/view/10185},
  urldate = {2025-03-27},
  abstract = {Over the years, chatbots have grown to be used in a variety of industries. From their humble beginnings to their current prominence, chatbots have come a long way. From the earliest chatbot ELIZA in the 1960s to today’s popular Chatgpt, chatbot language models, codes, and databases have improved greatly with the advancement of artificial intelligence technology.This paper introduces the development of chatbots through literature review and theoretical analysis. It also analyzes and summarizes the advantages and challenges of chatbots according to the current status of chatbot applications and social needs. Personalized interaction will be an important development direction for chatbots, because providing personalized responses through user data analysis can provide users with a personalized experience, thus increasing user engagement and satisfaction.},
  langid = {english}
}

@online{wangHistoryDevelopmentPrinciples2024,
  title = {History, {{Development}}, and {{Principles}} of {{Large Language Models-An Introductory Survey}}},
  author = {Wang, Zichong and Chu, Zhibo and Doan, Thang Viet and Ni, Shiwen and Yang, Min and Zhang, Wenbin},
  date = {2024-09-23},
  eprint = {2402.06853},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.06853},
  url = {http://arxiv.org/abs/2402.06853},
  urldate = {2025-03-19},
  abstract = {Language models serve as a cornerstone in natural language processing (NLP), utilizing mathematical methods to generalize language laws and knowledge for prediction and generation. Over extensive research spanning decades, language modeling has progressed from initial statistical language models (SLMs) to the contemporary landscape of large language models (LLMs). Notably, the swift evolution of LLMs has reached the ability to process, understand, and generate human-level text. Nevertheless, despite the significant advantages that LLMs offer in improving both work and personal lives, the limited understanding among general practitioners about the background and principles of these models hampers their full potential. Notably, most LLM reviews focus on specific aspects and utilize specialized language, posing a challenge for practitioners lacking relevant background knowledge. In light of this, this survey aims to present a comprehensible overview of LLMs to assist a broader audience. It strives to facilitate a comprehensive understanding by exploring the historical background of language models and tracing their evolution over time. The survey further investigates the factors influencing the development of LLMs, emphasizing key contributions. Additionally, it concentrates on elucidating the underlying principles of LLMs, equipping audiences with essential theoretical knowledge. The survey also highlights the limitations of existing work and points out promising future directions.},
  pubstate = {prepublished}
}

@article{watkinsSteganographyMessagesHidden2001,
  title = {Steganography – {{Messages Hidden}} in {{Bits}}},
  author = {Watkins, Jonathan},
  date = {2001},
  journaltitle = {Multimedia Systems Coursework, Dept of Electronics and CS, University of Southampton, SO17 1BJ, UK},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=8c4c24eac97067ee16d8ecdc999cacb7f62c068c},
  abstract = {Steganography is the process of hiding one medium of communication (text, sound or image) within another. This paper will discuss the tools used to both hide and unhide (know as Steganalysis) information. A look at the history starting with Herodotus in ancient Greece describing secret messages written in wax on stone tablets, to world war two’s secret double meaning Nazi messages and British Intelligences invisible ink. Most recently the techniques have been accredited with Osama Bin Laden's Al-Qa’eda terrorist network. Not all of Steganography involves some kind of subterfuge, I will also cover the area of digital watermarking, a method to try to protect the copyright of image.},
  langid = {english}
}

@article{waynerMimicFunctions1992,
  title = {Mimic {{Functions}}},
  author = {Wayner, Peter},
  date = {1992-07-01},
  journaltitle = {Cryptologia},
  volume = {16},
  number = {3},
  pages = {193--214},
  publisher = {Taylor \& Francis},
  issn = {0161-1194},
  doi = {10.1080/0161-119291866883},
  url = {https://doi.org/10.1080/0161-119291866883},
  urldate = {2025-03-16},
  abstract = {A mimic function changes a file A so it assumes the statistical properties of another file B. That is, if p(t, A) is the probability of some substring t occurring in A, then a mimic function f, recodes A so that p(t, f(A)) approximates p(t, B) for all strings t of length less than some n. This paper describes the algorithm for computing mimic functions and compares the algorithm with its functional inverse, Huffman coding. The paper also provides a description of more robust and more general mimic functions which can be defined using context-free grammars and van Wijngaarden grammars.}
}

@online{weiHiddenPlainSight2024,
  title = {Hidden in {{Plain Sight}}: {{Exploring Chat History Tampering}} in {{Interactive Language Models}}},
  shorttitle = {Hidden in {{Plain Sight}}},
  author = {Wei, Cheng'an and Zhao, Yue and Gong, Yujia and Chen, Kai and Xiang, Lu and Zhu, Shenchen},
  date = {2024-09-06},
  eprint = {2405.20234},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.20234},
  url = {http://arxiv.org/abs/2405.20234},
  urldate = {2025-04-03},
  abstract = {Large Language Models (LLMs) such as ChatGPT and Llama have become prevalent in real-world applications, exhibiting impressive text generation performance. LLMs are fundamentally developed from a scenario where the input data remains static and unstructured. To behave interactively, LLM-based chat systems must integrate prior chat history as context into their inputs, following a pre-defined structure. However, LLMs cannot separate user inputs from context, enabling chat history tampering. This paper introduces a systematic methodology to inject user-supplied history into LLM conversations without any prior knowledge of the target model. The key is to utilize prompt templates that can well organize the messages to be injected, leading the target LLM to interpret them as genuine chat history. To automatically search for effective templates in a WebUI black-box setting, we propose the LLM-Guided Genetic Algorithm (LLMGA) that leverages an LLM to generate and iteratively optimize the templates. We apply the proposed method to popular real-world LLMs including ChatGPT and Llama-2/3. The results show that chat history tampering can enhance the malleability of the model's behavior over time and greatly influence the model output. For example, it can improve the success rate of disallowed response elicitation up to 97\% on ChatGPT. Our findings provide insights into the challenges associated with the real-world deployment of interactive LLMs.},
  pubstate = {prepublished}
}

@article{weiJailbrokenHowDoes2023,
  title = {Jailbroken: {{How Does LLM Safety Training Fail}}?},
  shorttitle = {Jailbroken},
  author = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {80079--80110},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/fd6613131889a4b656206c50a8bd7790-Abstract-Conference.html},
  urldate = {2025-03-12},
  langid = {english}
}

@article{weizenbaumELIZAComputerProgram1966,
  title = {{{ELIZA}}—a Computer Program for the Study of Natural Language Communication between Man and Machine},
  author = {Weizenbaum, Joseph},
  date = {1966-01-01},
  journaltitle = {Commun. ACM},
  volume = {9},
  number = {1},
  pages = {36--45},
  issn = {0001-0782},
  doi = {10.1145/365153.365168},
  url = {https://dl.acm.org/doi/10.1145/365153.365168},
  urldate = {2025-03-27}
}

@online{whiteModelOpennessFramework2024,
  title = {The {{Model Openness Framework}}: {{Promoting Completeness}} and {{Openness}} for {{Reproducibility}}, {{Transparency}}, and {{Usability}} in {{Artificial Intelligence}}},
  shorttitle = {The {{Model Openness Framework}}},
  author = {White, Matt and Haddad, Ibrahim and Osborne, Cailean and Liu, Xiao-Yang Yanglet and Abdelmonsef, Ahmed and Varghese, Sachin and Hors, Arnaud Le},
  date = {2024-10-18},
  eprint = {2403.13784},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.13784},
  url = {http://arxiv.org/abs/2403.13784},
  urldate = {2025-03-28},
  abstract = {Generative artificial intelligence (AI) offers numerous opportunities for research and innovation, but its commercialization has raised concerns about the transparency and safety of frontier AI models. Most models lack the necessary components for full understanding, auditing, and reproducibility, and some model producers use restrictive licenses whilst claiming that their models are "open source". To address these concerns, we introduce the Model Openness Framework (MOF), a three-tiered ranked classification system that rates machine learning models based on their completeness and openness, following open science principles. For each MOF class, we specify code, data, and documentation components of the model development lifecycle that must be released and under which open licenses. In addition, the Model Openness Tool (MOT) provides a user-friendly reference implementation to evaluate the openness and completeness of models against the MOF classification system. Together, the MOF and MOT provide timely practical guidance for (i) model producers to enhance the openness and completeness of their publicly-released models, and (ii) model consumers to identify open models and their constituent components that can be permissively used, studied, modified, and redistributed. Through the MOF, we seek to establish completeness and openness as core tenets of responsible AI research and development, and to promote best practices in the burgeoning open AI ecosystem.},
  pubstate = {prepublished}
}

@article{wilsonFundamentalCybersecurityConcepts2014,
  title = {Some {{Fundamental Cybersecurity Concepts}}},
  author = {Wilson, Kelce S. and Kiy, Müge Ayse},
  date = {2014},
  journaltitle = {IEEE Access},
  volume = {2},
  pages = {116--124},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2014.2305658},
  url = {https://ieeexplore.ieee.org/abstract/document/6737236},
  urldate = {2025-03-28},
  abstract = {The results of successful hacking attacks against commercially available cybersecurity protection tools that had been touted as secure are distilled into a set of concepts that are applicable to many protection planning scenarios. The concepts, which explain why trust in those systems was misplaced, provides a framework for both analyzing known exploits and also evaluating proposed protection systems for predicting likely potential vulnerabilities. The concepts are: 1) differentiating security threats into distinct classes; 2) a five layer model of computing systems; 3) a payload versus protection paradigm; and 4) the nine Ds of cybersecurity, which present practical defensive tactics in an easily remembered scheme. An eavesdropping risk, inherent in many smartphones and notebook computers, is described to motivate improved practices and demonstrate real-world application of the concepts to predicting new vulnerabilities. Additionally, the use of the nine Ds is demonstrated as analysis tool that permits ranking of the expected effectiveness of some potential countermeasures.},
  eventtitle = {{{IEEE Access}}}
}

@software{wolfTransformersStateoftheArtNatural2020,
  title = {Transformers: {{State-of-the-Art Natural Language Processing}}},
  shorttitle = {Transformers},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Perric and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  date = {2020-10},
  origdate = {2018-10-29T13:56:00Z},
  pages = {38--45},
  url = {https://www.aclweb.org/anthology/2020.emnlp-demos.6},
  urldate = {2025-03-29},
  abstract = {🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.},
  organization = {Association for Computational Linguistics}
}

@article{wongSocialMediaMay2016,
  entrysubtype = {newspaper},
  title = {Social Media May Have Been Blocked during {{Turkey}} Coup Attempt},
  author = {Wong, Julia Carrie},
  date = {2016-07-15T23:25:09},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2016/jul/15/turkey-blocking-social-facebook-twitter-youtube},
  urldate = {2025-03-24},
  abstract = {Reports emerge during attempted military coup of people struggling to access social media in a country described as a ‘bastion of internet censorship’},
  journalsubtitle = {World news},
  langid = {british}
}

@inproceedings{wuGenerativeTextSteganography2024,
  title = {Generative {{Text Steganography}} with {{Large Language Model}}},
  booktitle = {Proceedings of the 32nd {{ACM International Conference}} on {{Multimedia}}},
  author = {Wu, Jiaxuan and Wu, Zhengxian and Xue, Yiming and Wen, Juan and Peng, Wanli},
  date = {2024-10-28},
  eprint = {2404.10229},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {10345--10353},
  doi = {10.1145/3664647.3680562},
  url = {http://arxiv.org/abs/2404.10229},
  urldate = {2025-03-12},
  abstract = {Recent advances in large language models (LLMs) have blurred the boundary of high-quality text generation between humans and machines, which is favorable for generative text steganography. While, current advanced steganographic mapping is not suitable for LLMs since most users are restricted to accessing only the black-box API or user interface of the LLMs, thereby lacking access to the training vocabulary and its sampling probabilities. In this paper, we explore a black-box generative text steganographic method based on the user interfaces of large language models, which is called LLM-Stega. The main goal of LLM-Stega is that the secure covert communication between Alice (sender) and Bob (receiver) is conducted by using the user interfaces of LLMs. Specifically, We first construct a keyword set and design a new encrypted steganographic mapping to embed secret messages. Furthermore, to guarantee accurate extraction of secret messages and rich semantics of generated stego texts, an optimization mechanism based on reject sampling is proposed. Comprehensive experiments demonstrate that the proposed LLM-Stega outperforms current state-of-the-art methods.}
}

@article{wuPromptingSteganographyNew2024,
  title = {Prompting {{Steganography}}: {{A New Paradigm}}},
  shorttitle = {Prompting {{Steganography}}},
  author = {Wu, Hanzhou},
  date = {2024-01-21},
  journaltitle = {Electronic Imaging},
  volume = {36},
  pages = {1--11},
  publisher = {{Society for Imaging Science and Technology}},
  issn = {2470-1173},
  doi = {10.2352/EI.2024.36.4.MWSF-338},
  url = {https://library.imaging.org/ei/articles/36/4/MWSF-338},
  urldate = {2025-03-12},
  abstract = {Abstract Recent studies show that scaling pre-trained language models can lead to a significantly improved model capacity on downstream tasks, resulting in a new research direction called large language models (LLMs). A remarkable application of LLMs is ChatGPT, which is a powerful large language model capable of generating human-like text based on context and past conversations. It is demonstrated that LLMs have impressive skills in reasoning, especially when using prompting strategies. In this paper, we explore the possibility of applying LLMs to the field of steganography, which is referred to as the art of hiding secret data into an innocent cover for covert communication. Our purpose is not to combine an LLM into an already designed steganographic system to boost the performance, which follows the conventional framework of steganography. Instead, we expect that, through prompting, an LLM can realize steganography by itself, which is defined as prompting steganography and may be a new paradigm of steganography. We show that, by reasoning, an LLM can embed secret data into a cover, and extract secret data from a stego, with an error rate. This error rate, however, can be reduced by optimizing the prompt, which may shed light on further research.},
  langid = {english}
}

@article{wuUnveilingSecurityPrivacy2024,
  title = {Unveiling Security, Privacy, and Ethical Concerns of {{ChatGPT}}},
  author = {Wu, Xiaodong and Duan, Ran and Ni, Jianbing},
  date = {2024-03-01},
  journaltitle = {Journal of Information and Intelligence},
  shortjournal = {Journal of Information and Intelligence},
  volume = {2},
  number = {2},
  pages = {102--115},
  issn = {2949-7159},
  doi = {10.1016/j.jiixd.2023.10.007},
  url = {https://www.sciencedirect.com/science/article/pii/S2949715923000707},
  urldate = {2025-03-27},
  abstract = {This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.}
}

@article{xiangGenerativeLinguisticSteganography2022,
  title = {Generative {{Linguistic Steganography}}: {{A Comprehensive Review}}},
  shorttitle = {Generative {{Linguistic Steganography}}},
  author = {Xiang, Lingyun and Wang, Rong and Yang, Zhongliang and Liu, Yuling},
  date = {2022},
  journaltitle = {KSII Transactions on Internet and Information Systems (TIIS)},
  volume = {16},
  number = {3},
  pages = {986--1005},
  publisher = {Korean Society for Internet Information},
  issn = {1976-7277},
  doi = {10.3837/tiis.2022.03.013},
  url = {https://koreascience.kr/article/JAKO202211563864037.page},
  urldate = {2025-03-13},
  abstract = {Text steganography is one of the most imminent and promising research interests in the information security field. With the unprecedented success of the neural network and natural language processing (NLP), the last years have seen a surge of research on generative linguistic steganography (GLS). This paper provides a thorough and comprehensive review to summarize the existing key contributions, and creates a novel taxonomy for GLS according to NLP techniques and steganographic encoding algorithm, then summarizes the characteristics of generative linguistic steganographic methods properly to analyze the relationship and difference between each type of them. Meanwhile, this paper also comprehensively introduces and analyzes several evaluation metrics to evaluate the performance of GLS from diverse perspective. Finally, this paper concludes the future research work, which is more conducive to the follow-up research and innovation of researchers.},
  langid = {english}
}

@inproceedings{xingAssessingEfficacyInvisible2024,
  title = {Assessing the {{Efficacy}} of {{Invisible Watermarks}} in {{AI-Generated Medical Images}}},
  booktitle = {2024 {{IEEE International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  author = {Xing, Xiaodan and Zhou, Huiyu and Fang, Yingying and Yang, Guang},
  date = {2024-05},
  pages = {1--5},
  issn = {1945-8452},
  doi = {10.1109/ISBI56570.2024.10635746},
  url = {https://ieeexplore.ieee.org/abstract/document/10635746},
  urldate = {2025-03-31},
  abstract = {AI-generated medical images are gaining growing popularity due to their potential to address the data scarcity challenge in the real world. However, the issue of accurate identification of these synthetic images, particularly when they exhibit remarkable realism with their real copies, remains a concern. To mitigate this challenge, image generators such as DALLE and Imagen, have integrated digital watermarks aimed at facilitating the discernment of synthetic images’ authenticity. These watermarks are embedded within the image pixels and are invisible to the human eye while remains their detectability. Nevertheless, a comprehensive investigation into the potential impact of these invisible watermarks on the utility of synthetic medical images has been lacking. In this study, we propose the incorporation of invisible watermarks into synthetic medical images and seek to evaluate their efficacy in the context of downstream classification tasks. Our goal is to pave the way for discussions on the viability of such watermarks in boosting the detectability of synthetic medical images, fortifying ethical standards, and safeguarding against data pollution and potential scams.},
  eventtitle = {2024 {{IEEE International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})}
}

@online{xuInvisMarkInvisibleRobust2024,
  title = {{{InvisMark}}: {{Invisible}} and {{Robust Watermarking}} for {{AI-generated Image Provenance}}},
  shorttitle = {{{InvisMark}}},
  author = {Xu, Rui and Hu, Mengya and Lei, Deren and Li, Yaxi and Lowe, David and Gorevski, Alex and Wang, Mingyu and Ching, Emily and Deng, Alex},
  date = {2024-11-19},
  eprint = {2411.07795},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.07795},
  url = {http://arxiv.org/abs/2411.07795},
  urldate = {2025-03-31},
  abstract = {The proliferation of AI-generated images has intensified the need for robust content authentication methods. We present InvisMark, a novel watermarking technique designed for high-resolution AI-generated images. Our approach leverages advanced neural network architectures and training strategies to embed imperceptible yet highly robust watermarks. InvisMark achieves state-of-the-art performance in imperceptibility (PSNR\$\textbackslash sim\$51, SSIM \$\textbackslash sim\$ 0.998) while maintaining over 97\textbackslash\% bit accuracy across various image manipulations. Notably, we demonstrate the successful encoding of 256-bit watermarks, significantly expanding payload capacity while preserving image quality. This enables the embedding of UUIDs with error correction codes, achieving near-perfect decoding success rates even under challenging image distortions. We also address potential vulnerabilities against advanced attacks and propose mitigation strategies. By combining high imperceptibility, extended payload capacity, and resilience to manipulations, InvisMark provides a robust foundation for ensuring media provenance in an era of increasingly sophisticated AI-generated content. Source code of this paper is available at: https://github.com/microsoft/InvisMark.},
  pubstate = {prepublished}
}

@article{yangLinguisticSteganalysisSocial2023,
  title = {Linguistic {{Steganalysis Toward Social Network}}},
  author = {Yang, Jinshuai and Yang, Zhongliang and Zou, Jiajun and Tu, Haoqin and Huang, Yongfeng},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {859--871},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3226909},
  url = {https://ieeexplore.ieee.org/abstract/document/9970400},
  urldate = {2025-03-13},
  abstract = {With the rapid development of the internet and social media, linguistic steganography can be easily abused in social networks to make considerable damage to varied aspects like personal privacy, network virus and national defense. Currently, considerable linguistic steganalysis methods are proposed to detect harmful steganographic carriers. However, almost all the existing methods fail in real social networks, since they are only devoted to the linguistic features that are extreme insufficient owing to the extreme sparsity and extreme fragmentation challenges of real social networks. In this paper, we attempt to fill the long-standing gap that the datasets and effective methods are absent for hunting steganographic texts in social network scenarios. Concretely, we construct a dataset called Stego-Sandbox to simulate the real social network scenarios, which contains texts and their relation. And we propose an effective linguistic steganalysis framework integrating linguistic features contained in texts and context features represented by these connections. Extensive experimental results demonstrate owing to the captured context features, our proposed framework can effectively compensate for shortcomings of these existing methods and tremendously improve their detection ability in real social network scenarios.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}}
}

@article{yangRNNStegaLinguisticSteganography2019,
  title = {{{RNN-Stega}}: {{Linguistic Steganography Based}} on {{Recurrent Neural Networks}}},
  shorttitle = {{{RNN-Stega}}},
  author = {Yang, Zhong-Liang and Guo, Xiao-Qing and Chen, Zi-Ming and Huang, Yong-Feng and Zhang, Yu-Jin},
  date = {2019-05},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {14},
  number = {5},
  pages = {1280--1295},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2018.2871746},
  url = {https://ieeexplore.ieee.org/document/8470163},
  urldate = {2025-01-26},
  abstract = {Linguistic steganography based on text carrier auto-generation technology is a current topic with great promise and challenges. Limited by the text automatic generation technology or the corresponding text coding methods, the quality of the steganographic text generated by previous methods is inferior, which makes its imperceptibility unsatisfactory. In this paper, we propose a linguistic steganography based on recurrent neural networks, which can automatically generate high-quality text covers on the basis of a secret bitstream that needs to be hidden. We trained our model with a large number of artificially generated samples and obtained a good estimate of the statistical language model. In the text generation process, we propose fixed-length coding and variable-length coding to encode words based on their conditional probability distribution. We designed several experiments to test the proposed model from the perspectives of information hiding efficiency, information imperceptibility, and information hidden capacity. The experimental results show that the proposed model outperforms all the previous related methods and achieves the state-of-the-art performance.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}}
}

@article{yangSeSyLinguisticSteganalysis2022,
  title = {{{SeSy}}: {{Linguistic Steganalysis Framework Integrating Semantic}} and {{Syntactic Features}}},
  shorttitle = {{{SeSy}}},
  author = {Yang, Jinshuai and Yang, Zhongliang and Zhang, Siyu and Tu, Haoqin and Huang, Yongfeng},
  date = {2022},
  journaltitle = {IEEE Signal Processing Letters},
  volume = {29},
  pages = {31--35},
  issn = {1558-2361},
  doi = {10.1109/LSP.2021.3122901},
  url = {https://ieeexplore.ieee.org/abstract/document/9591452},
  urldate = {2025-03-13},
  abstract = {With the rapid development of natural language processing technology and linguistic steganography, linguistic steganalysis gains considerable interest in recent years. Current advanced methods dominantly focus on statistical features in semantic view yet ignore syntax structure of text, which leads to limited performance to some newly statistically indistinguishable steganography algorithms. To fill this gap, in this paper, we propose a novel linguistic steganalysis framework named SeSy to integrate both semantic and syntactic features. Specifically, we propose to employ transformer-architecture language model as semantics extractor and leverage a graph attention network to retain syntactic features. Extensive experimental results show that owing to additional syntactic information, the SeSy framework effectively brings about remarkable improvement to current advanced linguistic steganalysis methods.},
  eventtitle = {{{IEEE Signal Processing Letters}}}
}

@inproceedings{yiExploitingLanguageModel2022,
  title = {Exploiting {{Language Model For Efficient Linguistic Steganalysis}}},
  booktitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Yi, Biao and Wu, Hanzhou and Feng, Guorui and Zhang, Xinpeng},
  date = {2022-05},
  pages = {3074--3078},
  issn = {2379-190X},
  doi = {10.1109/ICASSP43922.2022.9746219},
  url = {https://ieeexplore.ieee.org/abstract/document/9746219},
  urldate = {2025-03-13},
  abstract = {Recent advances in linguistic steganalysis have successively applied CNN, RNN, GNN and other efficient deep models for detecting secret information in generative texts. These methods tend to seek stronger feature extractors to achieve higher steganalysis effects. However, we have found through experiments that there actually exists significant difference between automatically generated stego texts and carrier texts in terms of the conditional probability distribution of individual words. Such kind of difference can be naturally captured by the language model used for generating stego texts. Through further experiments, we conclude that this ability can be transplanted to a text classifier by pre-training and fine-tuning to improve the detection performance. Motivated by this insight, we propose two methods for efficient linguistic steganalysis. One is to pre-train a language model based on RNN, and the other is to pre-train a sequence autoencoder. The results indicate that the two methods have different degrees of performance gain compared to the randomly initialized RNN, and the convergence speed is significantly accelerated. Moreover, our methods achieved the best performance compared to related works, while providing a solution for real-world scenario where there are more cover texts than stego texts.},
  eventtitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})}
}

@inproceedings{zamfirescu-pereiraWhyJohnnyCant2023,
  title = {Why {{Johnny Can}}’t {{Prompt}}: {{How Non-AI Experts Try}} (and {{Fail}}) to {{Design LLM Prompts}}},
  shorttitle = {Why {{Johnny Can}}’t {{Prompt}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
  date = {2023-04-19},
  series = {{{CHI}} '23},
  pages = {1--21},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3544548.3581388},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581388},
  urldate = {2025-04-03},
  abstract = {Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
  isbn = {978-1-4503-9421-5}
}

@online{zamirExcuseMeSir2024,
  title = {Excuse Me, Sir? {{Your}} Language Model Is Leaking (Information)},
  shorttitle = {Excuse Me, Sir?},
  author = {Zamir, Or},
  date = {2024-01-18},
  eprint = {2401.10360},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.10360},
  url = {http://arxiv.org/abs/2401.10360},
  urldate = {2025-03-12},
  abstract = {We introduce a cryptographic method to hide an arbitrary secret payload in the response of a Large Language Model (LLM). A secret key is required to extract the payload from the model's response, and without the key it is provably impossible to distinguish between the responses of the original LLM and the LLM that hides a payload. In particular, the quality of generated text is not affected by the payload. Our approach extends a recent result of Christ, Gunn and Zamir (2023) who introduced an undetectable watermarking scheme for LLMs.},
  pubstate = {prepublished},
  version = {1}
}

@online{zhangExtractingPromptsInverting2024,
  title = {Extracting {{Prompts}} by {{Inverting LLM Outputs}}},
  author = {Zhang, Collin and Morris, John X. and Shmatikov, Vitaly},
  date = {2024-10-08},
  eprint = {2405.15012},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.15012},
  url = {http://arxiv.org/abs/2405.15012},
  urldate = {2025-04-03},
  abstract = {We consider the problem of language model inversion: given outputs of a language model, we seek to extract the prompt that generated these outputs. We develop a new black-box method, output2prompt, that learns to extract prompts without access to the model's logits and without adversarial or jailbreaking queries. In contrast to previous work, output2prompt only needs outputs of normal user queries. To improve memory efficiency, output2prompt employs a new sparse encoding techique. We measure the efficacy of output2prompt on a variety of user and system prompts and demonstrate zero-shot transferability across different LLMs.},
  pubstate = {prepublished}
}

@article{zhaoInvisibleImageWatermarks2024,
  title = {Invisible {{Image Watermarks Are Provably Removable Using Generative AI}}},
  author = {Zhao, Xuandong and Zhang, Kexun and Su, Zihao and Vasan, Saastha and Grishchenko, Ilya and Kruegel, Christopher and Vigna, Giovanni and Wang, Yu-Xiang and Li, Lei},
  date = {2024-12-16},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {37},
  pages = {8643--8672},
  url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/10272bfd0371ef960ec557ed6c866058-Abstract-Conference.html},
  urldate = {2025-03-31},
  langid = {english}
}

@online{zhaoLinguaLinkedDistributedLarge2023,
  title = {{{LinguaLinked}}: {{A Distributed Large Language Model Inference System}} for {{Mobile Devices}}},
  shorttitle = {{{LinguaLinked}}},
  author = {Zhao, Junchen and Song, Yurun and Liu, Simeng and Harris, Ian G. and Jyothi, Sangeetha Abdu},
  date = {2023-12-01},
  eprint = {2312.00388},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2312.00388},
  url = {http://arxiv.org/abs/2312.00388},
  urldate = {2024-11-12},
  abstract = {Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of \$1.11\textbackslash times\$ to \$1.61\textbackslash times\$ in single-threaded settings, \$1.73\textbackslash times\$ to \$2.65\textbackslash times\$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of \$1.29\textbackslash times\$ to \$1.32\textbackslash times\$.},
  pubstate = {prepublished}
}

@online{zhaoSoKWatermarkingAIGenerated2024,
  title = {{{SoK}}: {{Watermarking}} for {{AI-Generated Content}}},
  shorttitle = {{{SoK}}},
  author = {Zhao, Xuandong and Gunn, Sam and Christ, Miranda and Fairoze, Jaiden and Fabrega, Andres and Carlini, Nicholas and Garg, Sanjam and Hong, Sanghyun and Nasr, Milad and Tramer, Florian and Jha, Somesh and Li, Lei and Wang, Yu-Xiang and Song, Dawn},
  date = {2024-12-19},
  eprint = {2411.18479},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.18479},
  url = {http://arxiv.org/abs/2411.18479},
  urldate = {2025-03-31},
  abstract = {As the outputs of generative AI (GenAI) techniques improve in quality, it becomes increasingly challenging to distinguish them from human-created content. Watermarking schemes are a promising approach to address the problem of distinguishing between AI and human-generated content. These schemes embed hidden signals within AI-generated content to enable reliable detection. While watermarking is not a silver bullet for addressing all risks associated with GenAI, it can play a crucial role in enhancing AI safety and trustworthiness by combating misinformation and deception. This paper presents a comprehensive overview of watermarking techniques for GenAI, beginning with the need for watermarking from historical and regulatory perspectives. We formalize the definitions and desired properties of watermarking schemes and examine the key objectives and threat models for existing approaches. Practical evaluation strategies are also explored, providing insights into the development of robust watermarking techniques capable of resisting various attacks. Additionally, we review recent representative works, highlight open challenges, and discuss potential directions for this emerging field. By offering a thorough understanding of watermarking in GenAI, this work aims to guide researchers in advancing watermarking methods and applications, and support policymakers in addressing the broader implications of GenAI.},
  pubstate = {prepublished}
}

@software{zieglerHarvardnlpNeuralSteganography2025,
  title = {Harvardnlp/{{NeuralSteganography}}},
  author = {Ziegler, Zachary M.},
  date = {2025-01-17T12:54:40Z},
  origdate = {2019-08-30T05:38:12Z},
  url = {https://github.com/harvardnlp/NeuralSteganography},
  urldate = {2025-03-11},
  abstract = {STEGASURAS: STEGanography via Arithmetic coding and Strong neURAl modelS},
  organization = {HNLP}
}

@online{zieglerNeuralLinguisticSteganography2019,
  title = {Neural {{Linguistic Steganography}}},
  author = {Ziegler, Zachary M. and Deng, Yuntian and Rush, Alexander M.},
  date = {2019-09-03},
  eprint = {1909.01496},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1909.01496},
  url = {http://arxiv.org/abs/1909.01496},
  urldate = {2024-10-30},
  abstract = {Whereas traditional cryptography encrypts a secret message into an unintelligible form, steganography conceals that communication is taking place by encoding a secret message into a cover signal. Language is a particularly pragmatic cover signal due to its benign occurrence and independence from any one medium. Traditionally, linguistic steganography systems encode secret messages in existing text via synonym substitution or word order rearrangements. Advances in neural language models enable previously impractical generation-based techniques. We propose a steganography technique based on arithmetic coding with large-scale neural language models. We find that our approach can generate realistic looking cover sentences as evaluated by humans, while at the same time preserving security by matching the cover message distribution with the language model distribution.},
  pubstate = {prepublished},
  version = {1}
}

@online{zieglerStegasuras2025,
  title = {Stegasuras},
  author = {Ziegler, Zachary M. and Deng, Yuntian and Rush, Alexander M.},
  date = {2025-03-11},
  url = {https://steganography.live/},
  urldate = {2025-03-11},
  abstract = {STEGanography via Arithmetic coding and Strong neURAl modelS},
  organization = {Stegasuras}
}
