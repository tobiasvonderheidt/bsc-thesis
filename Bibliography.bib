@software{abadiTensorFlowLargescaleMachine2015,
  title = {{{TensorFlow}}, {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2015-11},
  doi = {10.5281/zenodo.4724125},
  url = {https://github.com/tensorflow/tensorflow},
  urldate = {2025-03-12},
  abstract = {An Open Source Machine Learning Framework for Everyone}
}

@article{ahadConvenienceNuisanceWhatsApp2014,
  title = {Convenience or {{Nuisance}}?: {{The}} ‘{{WhatsApp}}’ {{Dilemma}}},
  shorttitle = {Convenience or {{Nuisance}}?},
  author = {Ahad, Annie Dayani and Lim, Syamimi Md Ariff},
  date = {2014-11-06},
  journaltitle = {Procedia - Social and Behavioral Sciences},
  shortjournal = {Procedia - Social and Behavioral Sciences},
  series = {The {{International Conference}} on {{Communication}} and {{Media}} 2014 (i-{{COME}}’14) - {{Communication}}, {{Empowerment}} and {{Governance}}: {{The}} 21st {{Century Enigma}}},
  volume = {155},
  pages = {189--196},
  issn = {1877-0428},
  doi = {10.1016/j.sbspro.2014.10.278},
  url = {https://www.sciencedirect.com/science/article/pii/S1877042814057449},
  urldate = {2025-04-10},
  abstract = {WhatsApp sends real-time messages and is one of the world's most popular communication applications in the 21st century. While this study extends the current knowledge on the use of WhatsApp, it also highlights the challenges of WhatsApp use by young people. The purpose of this study is to examine the domestication of WhatsApp among young people, specifically the undergraduates at Universiti Brunei Darussalam. Results showed how young people perceive WhatsApp as a ‘convenient’ communication application in their everyday lives. Some of the critical issues arising from the use of WhatsApp included distractions and exposure to unregulated messages or information.}
}

@online{al-aniOverviewMainFundamentals2010,
  title = {Overview: {{Main Fundamentals}} for {{Steganography}}},
  shorttitle = {Overview},
  author = {AL-Ani, Zaidoon Kh and Zaidan, A. A. and Zaidan, B. B. and Alanazi, Hamdan O.},
  date = {2010-03-22},
  eprint = {1003.4086},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1003.4086},
  url = {http://arxiv.org/abs/1003.4086},
  urldate = {2025-03-28},
  abstract = {The rapid development of multimedia and internet allows for wide distribution of digital media data. It becomes much easier to edit, modify and duplicate digital information .Besides that, digital documents are also easy to copy and distribute, therefore it will be faced by many threats. It is a big security and privacy issue, it become necessary to find appropriate protection because of the significance, accuracy and sensitivity of the information. Steganography considers one of the techniques which used to protect the important information. The main goals for this paper, to recognize the researchers for the main fundamentals of steganography. In this paper provides a general overview of the following subject areas: Steganography types, General Steganography system, Characterization of Steganography Systems and Classification of Steganography Techniques.},
  pubstate = {prepublished}
}

@article{alazzawieLinguisticSituationalFeatures2022,
  title = {The {{Linguistic}} and {{Situational Features}} of {{WhatsApp Messages Among High School}} and {{University Canadian Students}}},
  author = {Alazzawie, Abdulkhaliq},
  date = {2022-01-01},
  journaltitle = {SAGE Open},
  volume = {12},
  number = {1},
  pages = {21582440221082124},
  publisher = {SAGE Publications},
  issn = {2158-2440},
  doi = {10.1177/21582440221082124},
  url = {https://doi.org/10.1177/21582440221082124},
  urldate = {2025-04-10},
  abstract = {WhatsApp messages can be such a rich source for creative and spontaneous language geared toward more individual expression. WhatsApping provides us with a unique view into language and is an interesting prototype for thinking about language use, the various functions of this variety and how it is used to render different kinds of meanings. This study aims to explore the linguistic features of text messaging’s communicative intent, content and context. Selected samples of messages were drawn from a high school student population in Canada who provided a corpus of 100 different texts already sent and/or received for personal, educational and professional purposes. The collected data were analyzed using Biber and Conrad’s qualitative approach to register, genre, and style analysis. The result is that people use clipped sentences in a free flow of casual speech and slang. While certain abbreviations have come into such common use, to the point of becoming standard, a wide array of individualistic variance in terms of style and language usage has emerged. It is concluded that avid texters, while appearing to greatly deviate from more traditional, standard written English, are a rich source for studying creative and spontaneous language adaptation of register, genre and text according to context and text users.},
  langid = {english}
}

@online{alemohammadSelfConsumingGenerativeModels2023,
  title = {Self-{{Consuming Generative Models Go MAD}}},
  author = {Alemohammad, Sina and Casco-Rodriguez, Josue and Luzi, Lorenzo and Humayun, Ahmed Imtiaz and Babaei, Hossein and LeJeune, Daniel and Siahkoohi, Ali and Baraniuk, Richard G.},
  date = {2023-07-04},
  eprint = {2307.01850},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.01850},
  url = {http://arxiv.org/abs/2307.01850},
  urldate = {2025-03-19},
  abstract = {Seismic advances in generative AI algorithms for imagery, text, and other data types has led to the temptation to use synthetic data to train next-generation models. Repeating this process creates an autophagous (self-consuming) loop whose properties are poorly understood. We conduct a thorough analytical and empirical analysis using state-of-the-art generative image models of three families of autophagous loops that differ in how fixed or fresh real training data is available through the generations of training and in whether the samples from previous generation models have been biased to trade off data quality versus diversity. Our primary conclusion across all scenarios is that without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD), making analogy to mad cow disease.},
  pubstate = {prepublished}
}

@inproceedings{aliIoTSecurityReview2019,
  title = {{{IoT}} Security: {{A}} Review of Cybersecurity Architecture and Layers},
  shorttitle = {{{IoT}} Security},
  booktitle = {2nd {{Smart Cities Symposium}} ({{SCS}} 2019)},
  author = {Ali, Hamad Younis and El-Medany, Wael},
  date = {2019-03},
  pages = {1--7},
  doi = {10.1049/cp.2019.0191},
  url = {https://ieeexplore.ieee.org/document/9124947},
  urldate = {2025-03-28},
  abstract = {With the fast advancement in Technology, it started to get in every aspect of our lives. Especially that these devices are getting smaller, low power consuming and connects to the internet along with other IoT devices most or all the time thus internet of things devices are becoming a major part and can be seen everywhere in consumers houses or businesses. With these devices several risks in term of security and privacy are emerging, especially with data becoming so valuable for spying or profiting. This paper will explain privacy, its aspect and meanings to obtain a clear definition of types and ways privacy is invaded or violated. There are several laws regarding information, data privacy and protection, example of old and recent court cases with corresponding rulings. For a better understanding of how they are violated thus what should be considered or protected. There are different Layers of IoT security architecture available and described in order to protect the availability, confidentiality and integrity of IoT devices, besides a few suggested areas that need to be considered or addressed. Types of data and information that can be collected, aspects and attacks to IoT devices in terms of machine and deep learning and the data yielded from them, also the solutions approached are recommended by the author.},
  eventtitle = {2nd {{Smart Cities Symposium}} ({{SCS}} 2019)}
}

@article{aliTextbasedSteganographyUsing2021,
  title = {Text-Based {{Steganography}} Using {{Huffman Compression}} and {{AES Encryption Algorithm}}},
  author = {Ali, Rawaa Hamza and Kadhim, Jamal Mohamed},
  date = {2021-11-30},
  journaltitle = {Iraqi Journal of Science},
  pages = {4110--4120},
  issn = {2312-1637},
  doi = {10.24996/ijs.2021.62.11.31},
  url = {https://ijs.uobaghdad.edu.iq/index.php/eijs/article/view/3488},
  urldate = {2025-03-12},
  abstract = {In every system of security, to keep important data confidential, we need a high degree of protection. Steganography can be defined as a way of sending confidential texts through a secure medium of communications as well as protecting the information during the process of transmission. Steganography is a technology that is used to protect users' security and privacy. Communication is majorly achieved using a network through SMS, e-mail, and so on. The presented work suggested a technology of text hiding for protecting secret texts with Unicode characters. The similarities of glyphs\&nbsp; provided invisibility and increased the hiding capacity. In conclusion, the proposed method succeeded in securing confidential data and achieving high payload capacity by using the Huffman compression algorithm, which was implemented on an unlimited text length. In addition, this approach has the ability to hide a single bit in every digit or letter in the cover file. Also, the approach meets the cognitive transparency and does not make the modifications apparent on the original data. The method suggested in this work increases the security level through coding a secret message before embedding it within the cover text, with the use of the Advanced Encryption Standard (AES) algorithm.},
  langid = {english}
}

@inproceedings{allaEvolutionHindiText2009,
  title = {An {{Evolution}} of {{Hindi Text Steganography}}},
  booktitle = {2009 {{Sixth International Conference}} on {{Information Technology}}: {{New Generations}}},
  author = {Alla, Kalavathi and Prasad, R. Siva Rama},
  date = {2009-04},
  pages = {1577--1578},
  doi = {10.1109/ITNG.2009.41},
  url = {https://ieeexplore.ieee.org/abstract/document/5070855},
  urldate = {2025-03-24},
  abstract = {This paper presents a novel steganography scheme suitable for Hindi text. It can be classified under text steganography. Conveying information secretly and establishing a hidden relationship between the message and its counterpart has been of great interest since very long time ago. Methods of steganography are mostly applied on images, audio, video and text files. During the process characteristics of these methods are to change in the structure and features so as not to be identifiable by human eye. Text documents are the best examples for this. This paper presents a novel Hindi text steganography, which uses Hindi letters and its diacritics and numerical code. This method is not only useful to Hindi text but also to all other similar Indian languages.},
  eventtitle = {2009 {{Sixth International Conference}} on {{Information Technology}}: {{New Generations}}}
}

@article{andersonLimitsSteganography1998,
  title = {On the Limits of Steganography},
  author = {Anderson, R.J. and Petitcolas, F.A.P.},
  date = {1998-05},
  journaltitle = {IEEE Journal on Selected Areas in Communications},
  volume = {16},
  number = {4},
  pages = {474--481},
  issn = {1558-0008},
  doi = {10.1109/49.668971},
  url = {https://ieeexplore.ieee.org/abstract/document/668971},
  urldate = {2025-03-23},
  abstract = {In this paper, we clarify what steganography is and what it can do. We contrast it with the related disciplines of cryptography and traffic security, present a unified terminology agreed at the first international workshop on the subject, and outline a number of approaches-many of them developed to hide encrypted copyright marks or serial numbers in digital audio or video. We then present a number of attacks, some new, on such information hiding schemes. This leads to a discussion of the formidable obstacles that lie in the way of a general theory of information hiding systems (in the sense that Shannon gave us a general theory of secrecy systems). However, theoretical considerations lead to ideas of practical value, such as the use of parity checks to amplify covertness and provide public key steganography. Finally, we show that public key information hiding systems exist, and are not necessarily constrained to the case where the warden is passive.},
  eventtitle = {{{IEEE Journal}} on {{Selected Areas}} in {{Communications}}}
}

@software{anselPyTorch2Faster2024,
  title = {{{PyTorch}} 2: {{Faster Machine Learning Through Dynamic Python Bytecode Transformation}} and {{Graph Compilation}}},
  shorttitle = {{{PyTorch}} 2},
  author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and family=Luk, given=CK, given-i=CK and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Suo, Michael and Tillet, Phil and Wang, Eikan and Wang, Xiaodong and Wen, William and Zhang, Shunting and Zhao, Xu and Zhou, Keren and Zou, Richard and Mathews, Ajit and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
  date = {2024-04},
  origdate = {2016-08-13T05:26:41Z},
  journaltitle = {29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)},
  doi = {10.1145/3620665.3640366},
  url = {https://pytorch.org/assets/pytorch2-2.pdf},
  urldate = {2025-03-12},
  abstract = {Tensors and Dynamic neural networks in Python with strong GPU acceleration},
  organization = {ACM}
}

@online{aquinoDiscordUnveiledComprehensive2025,
  title = {Discord {{Unveiled}}: {{A Comprehensive Dataset}} of {{Public Communication}} (2015-2024)},
  shorttitle = {Discord {{Unveiled}}},
  author = {Aquino, Yan and Bento, Pedro and Buzelin, Arthur and Dayrell, Lucas and Malaquias, Samira and Santana, Caio and Estanislau, Victoria and Dutenhefner, Pedro and Evangelista, Guilherme H. G. and Porfírio, Luisa G. and Grossi, Caio Souza and Rigueira, Pedro B. and Almeida, Virgilio and Pappa, Gisele L. and Jr, Wagner Meira},
  date = {2025-02-02},
  eprint = {2502.00627},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.00627},
  url = {http://arxiv.org/abs/2502.00627},
  urldate = {2025-04-05},
  abstract = {Discord has evolved from a gaming-focused communication tool into a versatile platform supporting diverse online communities. Despite its large user base and active public servers, academic research on Discord remains limited due to data accessibility challenges. This paper introduces Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024), the most extensive Discord public server's data to date. The dataset comprises over 2.05 billion messages from 4.74 million users across 3,167 public servers, representing approximately 10\% of servers listed in Discord's Discovery feature. Spanning from Discord's launch in 2015 to the end of 2024, it offers a robust temporal and thematic framework for analyzing decentralized moderation, community governance, information dissemination, and social dynamics. Data was collected through Discord's public API, adhering to ethical guidelines and privacy standards via anonymization techniques. Organized into structured JSON files, the dataset facilitates seamless integration with computational social science methodologies. Preliminary analyses reveal significant trends in user engagement, bot utilization, and linguistic diversity, with English predominating alongside substantial representations of Spanish, French, and Portuguese. Additionally, prevalent community themes such as social, art, music, and memes highlight Discord's expansion beyond its gaming origins.},
  pubstate = {prepublished}
}

@article{ayanDescriptiveAnalysisEmoticons2020,
  title = {Descriptive {{Analysis}} of {{Emoticons}}/{{Emoji}} and {{Persuasive Digital Language Use}} in {{WhatsApp Messages}}},
  author = {Ayan, Erdal},
  date = {2020-07-14},
  journaltitle = {Open Journal of Modern Linguistics},
  volume = {10},
  number = {4},
  pages = {375--389},
  publisher = {Scientific Research Publishing},
  doi = {10.4236/ojml.2020.104022},
  url = {https://www.scirp.org/journal/paperinformation?paperid=102561},
  urldate = {2025-04-10},
  abstract = {WhatsApp messaging has emerged as one of the major ways that people mostly use for communication purposes in conjunction with fast changes in Internet and computer technologies. Linguistic structures with emoticons/emoji enrich the quality of communication in the environment, which has created a digital language. One of the significant purposes of using such a digital language is obviously to persuade the receiver and send feedback to the sender of the message. On the one hand, persuasive communication is almost indispensable for people who use WhatsApp. On the other hand, persuasion is a real and intentional cognitive process based on preferring certain linguistic style, decision making and providing motivational feedback. In this regard, this work aims at clarifying and exploring persuasive messages with emoticons/emoji based on digital language styles with non-standard writing. The study particularly investigates persuasive digital language used in the WhatsApp messages in terms of the following aspects: 1) languages which are used by the participants in social media platforms, 2) purposes of the participants in using social media platforms, 3) choices of persuasive language by the participants in social media platforms, 4) words that the participants initiate to start persuasive conversations in WhatsApp messages and 5) types of sentences the participants mostly produce in WhatsApp messages. It has been observed that Wh-adverbs (WRB) and Wh-pronouns (WP) are often used in initiation of persuasive language patterns. Female participants more frequently choose emoticons, photos, abbreviations, question/question marks, fiend’s names and pictures of the events than male participants do. The participants mostly preferred to use interrogatives during production of persuasive language patterns in WhatsApp messages.},
  issue = {4},
  langid = {english}
}

@article{badgerHowMuskTrump2025,
  entrysubtype = {newspaper},
  title = {How {{Musk}} and {{Trump Are Working}} to {{Consolidate Government Data About You}}},
  author = {Badger, Emily and Frenkel, Sheera},
  date = {2025-04-09},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2025/04/09/us/politics/trump-musk-data-access.html},
  urldate = {2025-04-10},
  abstract = {Elon Musk’s team is leading an effort to link government databases, to the alarm of privacy and security experts.},
  journalsubtitle = {U.S.},
  langid = {american}
}

@article{bagnallReversingSteganographyMyth2002,
  title = {Reversing the {{Steganography Myth}} in {{Terrorist Operations}}: {{The Asymmetrical Threat}} of {{Simple Intelligence Dissemination Techniques Using Common Tools}}},
  author = {Bagnall, Robert J.},
  date = {2002},
  journaltitle = {SANS Information Security Reading Room},
  volume = {19},
  url = {http://profs.sci.univr.it/~giaco/download/Watermarking-Obfuscation/paper556.pdf},
  abstract = {The events of September 11th prompted significant discussion and speculation as to the use of Steganography by terrorists for clandestine and secured communications. Numerous prominent figures in the industry have written articles and given interviews debating whether or not terrorists are using Stego to disseminate information to sleeper cells both in America and abroad. USA Today, for example, quoted “US Officials” this way: “U.S. officials and experts say it's the latest method of communication being used by Osama bin Laden and his associates to outfox law enforcement. Bin Laden and others are hiding maps and photographs of terrorist targets and posting instructions for terrorist activities on sports chat rooms, pornographic bulletin boards and other Web sites, U.S. and foreign officials say.” (http://www.usatoday.com/life/cyber/tech/2001-0205-binladen.htm) Mostly, the commentary was not a question of if but rather how long. I contend, however, that Steganography is not required, nor significantly used, by terrorist organizations for a number of reasons. Commonly available IT software and equipment such as 802.11b wireless networks, laptop and desktop computers, highcapacity media devices, and a little creative thinking, make it possible, indeed simple, to facilitate efficient, short-duration, and completely anonymous communications between even casual hosts. In this paper, using common technology, I will demonstrate various ways and methods for simple, clandestine communications that are virtually undetectable and untraceable. In order to be most effective, clandestine data transmission between parties must be simple, stealthy, and efficient. Many would say security of the data is important, but data security in this case can also be viewed as a vector of the exposure time of the data in question to outside parties. Additionally, focus will be given to both short and long range data transmission, including transmission through methods as simple as a physical hand-off of data between parties to more complicated means across larger distances between parties which do not have physical contact, such as wireless and Internet transmissions. First we will examine three high-capacity data storage devices, their immunity to detection, and the ease with which they can be transferred between parties. Next, we will examine short burst dissemination through the use of wireless transmissions in high-density populations, such as Washington, DC or San Francisco. Lastly, we will examine the use of the web in simple, effective, and virtually undetectable intelligence dissemination.},
  langid = {english}
}

@online{bahdanauNeuralMachineTranslation2016,
  title = {Neural {{Machine Translation}} by {{Jointly Learning}} to {{Align}} and {{Translate}}},
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  date = {2016-05-19},
  eprint = {1409.0473},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1409.0473},
  url = {http://arxiv.org/abs/1409.0473},
  urldate = {2025-03-27},
  abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  pubstate = {prepublished}
}

@inproceedings{bankoScalingVeryVery2001,
  title = {Scaling to Very Very Large Corpora for Natural Language Disambiguation},
  booktitle = {Proceedings of the 39th {{Annual Meeting}} on {{Association}} for {{Computational Linguistics}}},
  author = {Banko, Michele and Brill, Eric},
  date = {2001-07-06},
  series = {{{ACL}} '01},
  pages = {26--33},
  publisher = {Association for Computational Linguistics},
  location = {USA},
  doi = {10.3115/1073012.1073017},
  url = {https://dl.acm.org/doi/10.3115/1073012.1073017},
  urldate = {2025-03-27},
  abstract = {The amount of readily available on-line text has reached hundreds of billions of words and continues to grow. Yet for most core natural language tasks, algorithms continue to be optimized, tested and compared after training on corpora consisting of only one million words or less. In this paper, we evaluate the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambiguation, when trained on orders of magnitude more labeled data than has previously been used. We are fortunate that for this particular application, correctly labeled training data is free. Since this will often not be the case, we examine methods for effectively exploiting very large corpora when labeled data comes at a cost.}
}

@online{baraniukWhyPrintersAdd2017,
  title = {Why Printers Add Secret Tracking Dots},
  author = {Baraniuk, Chris},
  date = {2017-06-07},
  url = {https://www.bbc.com/future/article/20170607-why-printers-add-secret-tracking-dots},
  urldate = {2025-01-23},
  abstract = {They’re almost invisible but contain a hidden code – and now their presence on a leaked document has sparked speculation about their usefulness to FBI investigators.},
  langid = {british}
}

@article{barnesIntelligenceOfficialsAcknowledge2025,
  entrysubtype = {newspaper},
  title = {Intelligence Officials Acknowledge the Sensitivity of the Military Strike Information.},
  author = {Barnes, Julian E.},
  date = {2025-03-25},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2025/03/25/us/politics/ratcliffe-gabbard-signal-leak.html},
  urldate = {2025-03-25},
  abstract = {Under questioning from senators, the C.I.A. chief and the director of national intelligence pointed to the defense secretary to determine what was appropriate to share.},
  journalsubtitle = {U.S.},
  langid = {american}
}

@online{baumgartnerPushshiftRedditDataset2020,
  title = {The {{Pushshift Reddit Dataset}}},
  author = {Baumgartner, Jason and Zannettou, Savvas and Keegan, Brian and Squire, Megan and Blackburn, Jeremy},
  date = {2020-01-23},
  eprint = {2001.08435},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2001.08435},
  url = {http://arxiv.org/abs/2001.08435},
  urldate = {2025-04-06},
  abstract = {Social media data has become crucial to the advancement of scientific understanding. However, even though it has become ubiquitous, just collecting large-scale social media data involves a high degree of engineering skill set and computational resources. In fact, research is often times gated by data engineering problems that must be overcome before analysis can proceed. This has resulted recognition of datasets as meaningful research contributions in and of themselves. Reddit, the so called "front page of the Internet," in particular has been the subject of numerous scientific studies. Although Reddit is relatively open to data acquisition compared to social media platforms like Facebook and Twitter, the technical barriers to acquisition still remain. Thus, Reddit's millions of subreddits, hundreds of millions of users, and hundreds of billions of comments are at the same time relatively accessible, but time consuming to collect and analyze systematically. In this paper, we present the Pushshift Reddit dataset. Pushshift is a social media data collection, analysis, and archiving platform that since 2015 has collected Reddit data and made it available to researchers. Pushshift's Reddit dataset is updated in real-time, and includes historical data back to Reddit's inception. In addition to monthly dumps, Pushshift provides computational tools to aid in searching, aggregating, and performing exploratory analysis on the entirety of the dataset. The Pushshift Reddit dataset makes it possible for social media researchers to reduce time spent in the data collection, cleaning, and storage phases of their projects.},
  pubstate = {prepublished}
}

@online{baumgartnerPushshiftTelegramDataset2020,
  title = {The {{Pushshift Telegram Dataset}}},
  author = {Baumgartner, Jason and Zannettou, Savvas and Squire, Megan and Blackburn, Jeremy},
  date = {2020-01-23},
  eprint = {2001.08438},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2001.08438},
  url = {http://arxiv.org/abs/2001.08438},
  urldate = {2025-04-06},
  abstract = {Messaging platforms, especially those with a mobile focus, have become increasingly ubiquitous in society. These mobile messaging platforms can have deceivingly large user bases, and in addition to being a way for people to stay in touch, are often used to organize social movements, as well as a place for extremists and other ne'er-do-well to congregate. In this paper, we present a dataset from one such mobile messaging platform: Telegram. Our dataset is made up of over 27.8K channels and 317M messages from 2.2M unique users. To the best of our knowledge, our dataset comprises the largest and most complete of its kind. In addition to the raw data, we also provide the source code used to collect it, allowing researchers to run their own data collection instance. We believe the Pushshift Telegram dataset can help researchers from a variety of disciplines interested in studying online social movements, protests, political extremism, and disinformation.},
  pubstate = {prepublished}
}

@article{bbcGhislaineMaxwellJeffreyEpstein2020,
  entrysubtype = {newspaper},
  title = {Ghislaine {{Maxwell-Jeffrey Epstein}} Emails Revealed in New Court Papers},
  author = {{BBC}},
  date = {2020-07-31},
  url = {https://www.bbc.com/news/world-us-canada-53605784},
  urldate = {2024-12-08},
  abstract = {In the papers, a key accuser also alleges the pair were equally involved in sex trafficking.},
  langid = {british}
}

@article{bbcPegasusSpywareSold2021,
  entrysubtype = {newspaper},
  title = {Pegasus: {{Spyware}} Sold to Governments 'Targets Activists'},
  shorttitle = {Pegasus},
  author = {{BBC}},
  date = {2021-07-18},
  url = {https://www.bbc.com/news/technology-57881364},
  urldate = {2024-12-08},
  abstract = {Israeli tech firm NSO denies media reports that its software has been sold to authoritarian regimes.},
  langid = {british}
}

@software{beewareBeewareToga2025,
  title = {Beeware/Toga},
  author = {{BeeWare}},
  date = {2025-03-29T08:31:59Z},
  origdate = {2014-08-01T21:44:10Z},
  url = {https://github.com/beeware/toga},
  urldate = {2025-03-29},
  abstract = {A Python native, OS native GUI toolkit.},
  organization = {BeeWare}
}

@misc{bennettLinguisticSteganographySurvey2004,
  title = {Linguistic Steganography: {{Survey}}, Analysis, and Robustness Concerns for Hiding Information in Text},
  author = {Bennett, Krista},
  date = {2004-05-12},
  abstract = {Steganography is an ancient art. With the advent of computers, we have vast accessible bodies of data in which to hide information, and increasingly sophisticated techniques with which to analyze and recover that information. While much of the recent research in steganography has been centered on hiding data in images, many of the solutions that work for images are more complicated when applied to natural language text as a cover medium. Many approaches to steganalysis attempt to detect statistical anomalies in cover data which predict the presence of hidden information. Natural language cover texts must not only pass the statistical muster of automatic analysis, but also the minds of human readers. Linguistically na},
  acknowledgement = {Victor Raskin, CERIAS},
  affiliation = {Interdepartmental Program in Linguistics and CERIAS},
  contents = {- Steganography, steganalysis and mimicking - Text steganography - Linguistic concerns with existing methods - Future directions in constructing linguistically and statistically robust cover texts},
  howpublished = {Research paper accepted in partial fulfillment of the Dept. of Linguistics preliminary examination requirement},
  langid = {english},
  organization = {Purdue University},
  subject = {Issues and future directions in linguistic steganography}
}

@article{berryLimitsComputationJoseph2023,
  title = {The {{Limits}} of {{Computation}}: {{Joseph Weizenbaum}} and the {{ELIZA Chatbot}}},
  shorttitle = {The {{Limits}} of {{Computation}}},
  author = {Berry, David M.},
  date = {2023-11-06},
  journaltitle = {Weizenbaum Journal of the Digital Society},
  volume = {3},
  number = {3},
  issn = {2748-5625},
  doi = {10.34669/WI.WJDS/3.3.2},
  url = {https://ojs.weizenbaum-institut.de/index.php/wjds/article/view/106},
  urldate = {2025-03-27},
  abstract = {Developed in the 1960s by Joseph Weizenbaum, ELIZA is arguably among the most influential computer programs ever written. ELIZA – and especially its most famous persona DOCTOR – continues to inspire programmers, wider discussions about AI, and imitations. This original ancestor of all conversational interfaces and chatbots maintains a special fascination for engineers, historians, and philosophers of artificial intelligence (AI) and computing. With its ability to produce human-like responses using a relatively small amount of computer code, ELIZA has paved the way for a multitude of similar programs. These take the form of conversation agents and other human-computer interfaces that have inspired entire new fields of study within computer science. This paper examines Weizenbaum’s contribution to AI and considers his more critical writings in the context of contemporary developments in generative AI, such as ChatGPT. Examining how ELIZA has been discussed can provide insights into current debates surrounding machine learning and AI.},
  issue = {3},
  langid = {english}
}

@online{biddleFacebookEngineersWe2022,
  title = {Facebook {{Engineers}}: {{We Have No Idea Where We Keep All Your Personal Data}}},
  shorttitle = {Facebook {{Engineers}}},
  author = {Biddle, Sam},
  date = {2022-09-07T11:00:49+00:00},
  url = {https://theintercept.com/2022/09/07/facebook-personal-data-no-accountability/},
  urldate = {2025-03-27},
  abstract = {In a discovery hearing, two veteran Facebook engineers said that Meta doesn’t know where it stores personal data.},
  langid = {american},
  organization = {The Intercept}
}

@article{borsciChatbotUsabilityScale2022,
  title = {The {{Chatbot Usability Scale}}: The {{Design}} and {{Pilot}} of a {{Usability Scale}} for {{Interaction}} with {{AI-Based Conversational Agents}}},
  shorttitle = {The {{Chatbot Usability Scale}}},
  author = {Borsci, Simone and Malizia, Alessio and Schmettow, Martin and family=Velde, given=Frank, prefix=van der, useprefix=true and Tariverdiyeva, Gunay and Balaji, Divyaa and Chamberlain, Alan},
  date = {2022-02-01},
  journaltitle = {Personal and Ubiquitous Computing},
  shortjournal = {Pers Ubiquit Comput},
  volume = {26},
  number = {1},
  pages = {95--119},
  issn = {1617-4917},
  doi = {10.1007/s00779-021-01582-9},
  url = {https://doi.org/10.1007/s00779-021-01582-9},
  urldate = {2025-04-10},
  abstract = {Standardised tools to assess a user’s satisfaction with the experience of using chatbots and conversational agents are currently unavailable. This work describes four studies, including a systematic literature review, with an overall sample of 141 participants in the survey (experts and novices), focus group sessions and testing of chatbots to (i) define attributes to assess the quality of interaction with chatbots and (ii) the designing and piloting a new scale to measure satisfaction after the experience with chatbots. Two instruments were developed: (i) A diagnostic tool in the form of a checklist (BOT-Check). This tool is a development of previous works which can be used reliably to check the quality of a chatbots experience in line with commonplace principles. (ii) A 15-item questionnaire (BOT Usability Scale, BUS-15) with estimated reliability between .76 and .87 distributed in five factors. BUS-15 strongly correlates with UMUX-LITE by enabling designers to consider a broader range of aspects usually not considered in satisfaction tools for non-conversational agents, e.g. conversational efficiency and accessibility, quality of the chatbot’s functionality and so on. Despite the convincing psychometric properties, BUS-15 requires further testing and validation. Designers can use it as a tool to assess products, thus building independent databases for future evaluation of its reliability, validity and sensitivity.},
  langid = {english}
}

@article{boutetAreOlderAdults2024,
  title = {Are Older Adults Adapting to New Forms of Communication? {{A}} Study on Emoji Adoption across the Adult Lifespan},
  shorttitle = {Are Older Adults Adapting to New Forms of Communication?},
  author = {Boutet, Isabelle and Goulet-Pelletier, Jean-Christophe and Sutera, Eva and Meinhardt-Injac, Bozana},
  date = {2024-03-01},
  journaltitle = {Computers in Human Behavior Reports},
  shortjournal = {Computers in Human Behavior Reports},
  volume = {13},
  pages = {100379},
  issn = {2451-9588},
  doi = {10.1016/j.chbr.2024.100379},
  url = {https://www.sciencedirect.com/science/article/pii/S2451958824000125},
  urldate = {2025-04-10},
  abstract = {Recent evidence suggests that as a form of non-verbal communication, emojis play critical communicative functions. As such, emojis can help users of all ages meet their social and emotional needs when interacting online. The present study advances our understanding of the factors that influence use of emojis across the adult lifespan. We investigated how age influences several facets of emoji use (frequency of use, diversity of use, ease of interpretation, and interpretation accuracy). We also explored putative mediators of the relationship between age and emoji use by drawing from the literature on technology acceptance. 240 adults, 18–80 years of age, participated in the study. Older users were less likely to use emojis, less likely to use a diversity of emojis, and found emojis less easy to use. Age predicted reduced accuracy of interpretation for only two of the eight emojis tested. Perceived ease of use, Technology self-efficacy, and Expertise with social exchange platforms mediated age-related effects. We conclude that older users have the motivation and ability to utilize emojis but lack the confidence to adopt this new mode of communication. Developers should consider making unambiguous emojis more accessible to facilitate intergenerational interactions on online platforms.}
}

@article{brittainMetaKnewIt2025,
  entrysubtype = {newspaper},
  title = {Meta Knew It Used Pirated Books to Train {{AI}}, Authors Say},
  author = {Brittain, Blake},
  date = {2025-01-09T21:58:00Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/artificial-intelligence/meta-knew-it-used-pirated-books-train-ai-authors-say-2025-01-09/},
  urldate = {2025-03-19},
  abstract = {Meta Platforms used pirated versions of copyrighted books to train its artificial intelligence systems with approval from its CEO Mark Zuckerberg, a group of authors alleged in newly disclosed court papers.},
  journalsubtitle = {Artificial Intelligence},
  langid = {english}
}

@online{burnsWaltzsTeamSet2025,
  title = {Waltz’s Team Set up at Least 20 {{Signal}} Group Chats for Crises across the World},
  author = {Burns, Dasha},
  date = {2025-04-02},
  url = {https://www.politico.com/news/2025/04/02/waltzs-team-set-up-at-least-20-signal-group-chats-for-crises-across-the-world-00266845},
  urldate = {2025-04-08},
  abstract = {It’s a more extensive use of the app than previously reported and sheds new light on how commonly the Trump administration’s national security team relies on Signal.},
  langid = {english},
  organization = {POLITICO}
}

@online{carreiraRevolutionizingMobileInteraction2023,
  title = {Revolutionizing {{Mobile Interaction}}: {{Enabling}} a 3 {{Billion Parameter GPT LLM}} on {{Mobile}}},
  shorttitle = {Revolutionizing {{Mobile Interaction}}},
  author = {Carreira, Samuel and Marques, Tomás and Ribeiro, José and Grilo, Carlos},
  date = {2023-09-29},
  eprint = {2310.01434},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2310.01434},
  url = {http://arxiv.org/abs/2310.01434},
  urldate = {2024-11-12},
  abstract = {The field of Artificial Intelligence has witnessed remarkable progress in recent years, especially with the emergence of powerful large language models (LLMs) based on the transformer architecture. Cloud-based LLMs, such as OpenAI's ChatGPT, offer impressive capabilities but come with concerns regarding latency and privacy due to network dependencies. This article presents an innovative approach to LLM inference, envisioning a future where LLMs with billions of parameters can be executed directly on mobile devices without network connectivity. The article showcases a fine-tuned GPT LLM with 3 billion parameters that can operate smoothly on devices with as low as 4GB of memory. Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features. The article provides insights into the training pipeline, implementation details, test results, and future directions of on-device LLM inference. This breakthrough technology opens up possibilities for empowering users with sophisticated AI capabilities while preserving their privacy and eliminating latency concerns.},
  pubstate = {prepublished},
  version = {1}
}

@inproceedings{centsNewApproachIdentify2020,
  title = {Towards a {{New Approach}} to {{Identify WhatsApp Messages}}},
  booktitle = {2020 {{IEEE}} 19th {{International Conference}} on {{Trust}}, {{Security}} and {{Privacy}} in {{Computing}} and {{Communications}} ({{TrustCom}})},
  author = {Cents, Rick and Le-Khac, Nhien-An},
  date = {2020-12},
  pages = {1895--1902},
  issn = {2324-9013},
  doi = {10.1109/TrustCom50675.2020.00259},
  url = {https://ieeexplore.ieee.org/abstract/document/9343229},
  urldate = {2025-04-10},
  abstract = {Today traditional communication methods, such as SMS or phone calls, are used less often and are replaced by the use of chat applications. WhatsApp is one of the most popular chat applications nowadays. WhatsApp offers different ways of communicating, which include sending text messages and making phone calls. The implementation of encryption makes WhatsApp more challenging for law enforcement agencies to identify when a suspect is sending or receiving messages via this chat application. Most research in literature focused on the analysis of WhatsApp data by obtaining information from a physical device, such as a seized mobile device. However, it is not always possible to extract the data needed from a mobile device for the analysis of the WhatsApp data because of the encryption, or no devices have been seized yet. In addition, the current techniques for real time analysis of WhatsApp messages show that there is a high risk of detection by the suspect. Alternative methods are needed to understand the communication patterns of a suspect and criminal organizations. In this paper, we focused on identifying when a suspect is receiving or sending WhatsApp messages using only wiretap data. Therefore, no seized devices are needed. The pattern analysis has been used to identify patterns of data sent to and received from the WhatsApp servers. The identified patterns were tested against a large dataset created with different mobile devices to determine if the patterns are consistent. By using the technique described in this paper, investigators will obtain more information if and with whom a suspect is communicating.},
  eventtitle = {2020 {{IEEE}} 19th {{International Conference}} on {{Trust}}, {{Security}} and {{Privacy}} in {{Computing}} and {{Communications}} ({{TrustCom}})}
}

@software{chaquoChaquoChaquopy2025,
  title = {Chaquo/Chaquopy},
  author = {{Chaquo}},
  date = {2025-03-29T11:27:56Z},
  origdate = {2017-06-22T17:33:02Z},
  url = {https://github.com/chaquo/chaquopy},
  urldate = {2025-03-29},
  abstract = {Chaquopy: the Python SDK for Android},
  organization = {Chaquo}
}

@article{chatterjeeAutomaticallyIdentifyingQuality2021,
  title = {Automatically {{Identifying}} the {{Quality}} of {{Developer Chats}} for {{Post Hoc Use}}},
  author = {Chatterjee, Preetha and Damevski, Kostadin and Kraft, Nicholas A. and Pollock, Lori},
  date = {2021-07-23},
  journaltitle = {ACM Trans. Softw. Eng. Methodol.},
  volume = {30},
  number = {4},
  pages = {48:1--48:28},
  issn = {1049-331X},
  doi = {10.1145/3450503},
  url = {https://dl.acm.org/doi/10.1145/3450503},
  urldate = {2025-04-05},
  abstract = {Software engineers are crowdsourcing answers to their everyday challenges on Q\&amp;A forums (e.g., Stack Overflow) and more recently in public chat communities such as Slack, IRC, and Gitter. Many software-related chat conversations contain valuable expert knowledge that is useful for both mining to improve programming support tools and for readers who did not participate in the original chat conversations. However, most chat platforms and communities do not contain built-in quality indicators (e.g., accepted answers, vote counts). Therefore, it is difficult to identify conversations that contain useful information for mining or reading, i.e., conversations of post hoc quality. In this article, we investigate automatically detecting developer conversations of post hoc quality from public chat channels. We first describe an analysis of 400 developer conversations that indicate potential characteristics of post hoc quality, followed by a machine learning-based approach for automatically identifying conversations of post hoc quality. Our evaluation of 2,000 annotated Slack conversations in four programming communities (python, clojure, elm, and racket) indicates that our approach can achieve precision of 0.82, recall of 0.90, F-measure of 0.86, and MCC of 0.57. To our knowledge, this is the first automated technique for detecting developer conversations of post hoc quality.}
}

@online{chenLLMMobileInitial2024,
  title = {{{LLM}} for {{Mobile}}: {{An Initial Roadmap}}},
  shorttitle = {{{LLM}} for {{Mobile}}},
  author = {Chen, Daihang and Liu, Yonghui and Zhou, Mingyi and Zhao, Yanjie and Wang, Haoyu and Wang, Shuai and Chen, Xiao and Bissyandé, Tegawendé F. and Klein, Jacques and Li, Li},
  date = {2024-07-09},
  eprint = {2407.06573},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2407.06573},
  url = {http://arxiv.org/abs/2407.06573},
  urldate = {2024-11-12},
  abstract = {When mobile meets LLMs, mobile app users deserve to have more intelligent usage experiences. For this to happen, we argue that there is a strong need to appl LLMs for the mobile ecosystem. We therefore provide a research roadmap for guiding our fellow researchers to achieve that as a whole. In this roadmap, we sum up six directions that we believe are urgently required for research to enable native intelligence in mobile devices. In each direction, we further summarize the current research progress and the gaps that still need to be filled by our fellow researchers.},
  pubstate = {prepublished},
  version = {1}
}

@online{chenOptimizationArmv9Architecture2024,
  title = {Optimization of {{Armv9}} Architecture General Large Language Model Inference Performance Based on {{Llama}}.Cpp},
  author = {Chen, Longhao and Zhao, Yina and Xie, Qiangjun and Sheng, Qinghua},
  date = {2024-06-16},
  eprint = {2406.10816},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.10816},
  url = {http://arxiv.org/abs/2406.10816},
  urldate = {2024-12-05},
  abstract = {This article optimizes the inference performance of the Qwen-1.8B model by performing Int8 quantization, vectorizing some operators in llama.cpp, and modifying the compilation script to improve the compiler optimization level. On the Yitian 710 experimental platform, the prefill performance is increased by 1.6 times, the decoding performance is increased by 24 times, the memory usage is reduced to 1/5 of the original, and the accuracy loss is almost negligible.},
  pubstate = {prepublished}
}

@online{chintalaPyTorchStrengthensIts2022,
  title = {{{PyTorch}} Strengthens Its Governance by Joining the {{Linux Foundation}}},
  author = {Chintala, Soumith},
  date = {2022-09-12},
  url = {https://pytorch.org/blog/PyTorchfoundation/},
  urldate = {2025-03-29},
  abstract = {Today, I am proud to announce that PyTorch is moving to the Linux Foundation (LF) as a top-level project under the name PyTorch Foundation. The core mission of the Linux Foundation is the collaborative development of open source software. With a governing board of leaders from AMD, Amazon Web Services (AWS), Google Cloud, Meta, Microsoft Azure and NVIDIA, this model aligns with where PyTorch stands today and what it needs to travel forward. The creation of the PyTorch Foundation will ensure business decisions are being made in a transparent and open manner by a diverse group of members for years to come. The technical decisions remain in control of individual maintainers. I’m excited that the Linux Foundation will be our new home as they have notable experience supporting large open-source projects like ours such as Kubernetes and NodeJS. At this pivotal moment, I want to take a look back at how we started, share why we are moving, and what’s ahead.},
  langid = {english},
  organization = {PyTorch}
}

@inproceedings{chowdhuryChatGPTThreatCIA2023,
  title = {{{ChatGPT}}: {{A Threat Against}} the {{CIA Triad}} of {{Cyber Security}}},
  shorttitle = {{{ChatGPT}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Electro Information Technology}} ({{eIT}})},
  author = {Chowdhury, MD Minhaz and Rifat, Nafiz and Ahsan, Mostofa and Latif, Shadman and Gomes, Rahul and Rahman, Md Saifur},
  date = {2023-05},
  pages = {1--6},
  issn = {2154-0373},
  doi = {10.1109/eIT57321.2023.10187355},
  url = {https://ieeexplore.ieee.org/abstract/document/10187355},
  urldate = {2025-03-28},
  abstract = {The AI revolution has brought significant changes to society. AI-powered systems can analyze enormous amounts of data to optimize processes, improve accuracy, and cut costs. Nevertheless, addressing potential hazards and ethical issues related to AI enabled technologies, such as bias and job displacement, is essential. This paper presented an example of an AI revolution threatening cyber security, the ChatGPT. ChatGPT, a chatbot, can generate essays or code on demand. However, ChatGPT's security system can be circumvented or deceived to generate malicious content. Moreover, these AI enabled tools to have design issues, e.g., accuracy issues. As a result, ChatGPT can be accused of violating the confidentiality of information (privacy invasion), producing inaccurate information, and potentially facilitating attack tool generation that can compromise the availability principle of the CIA triad. This paper presents ChatGPT as a threat against the CIA triad principle by focusing on violating these principles.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Electro Information Technology}} ({{eIT}})}
}

@inproceedings{christUndetectableWatermarksLanguage2024,
  title = {Undetectable {{Watermarks}} for {{Language Models}}},
  booktitle = {Proceedings of {{Thirty Seventh Conference}} on {{Learning Theory}}},
  author = {Christ, Miranda and Gunn, Sam and Zamir, Or},
  date = {2024-06-30},
  pages = {1125--1139},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v247/christ24a.html},
  urldate = {2025-03-12},
  abstract = {Recent advances in the capabilities of large language models such as GPT-4 have spurred increasing concern about our ability to detect AI-generated text.  Prior works have suggested methods of embedding watermarks in model outputs, by *noticeably* altering the output distribution. We ask: Is it possible to introduce a watermark without incurring *any detectable* change to the output distribution? To this end, we introduce a cryptographically-inspired notion of undetectable watermarks for language models.  That is, watermarks can be detected only with the knowledge of a secret key; without the secret key, it is computationally intractable to distinguish watermarked outputs from those of the original model. In particular, it is impossible for a user to observe any degradation in the quality of the text. Crucially, watermarks remain undetectable even when the user is allowed to adaptively query the model with arbitrarily chosen prompts. We construct undetectable watermarks based on the existence of one-way functions, a standard assumption in cryptography.},
  eventtitle = {The {{Thirty Seventh Annual Conference}} on {{Learning Theory}}},
  langid = {english}
}

@online{cmakeCMakeUpgradeYour,
  title = {{{CMake}} - {{Upgrade Your Software Build System}}},
  author = {{CMake}},
  url = {https://cmake.org/},
  urldate = {2025-03-29},
  abstract = {CMake is a powerful and comprehensive solution for managing the software build process. CMake is the de-facto standard for building C++ code, with over 2 million downloads a month.},
  langid = {american}
}

@online{cohenWhenTerrorHides2001,
  title = {When {{Terror Hides Online}}},
  author = {Cohen, Adam},
  date = {2001-11-12T05:00:00},
  url = {https://time.com/archive/6665170/when-terror-hides-online/},
  urldate = {2025-01-09},
  abstract = {Did you hear the one about Osama bin Laden hiding messages in porn websites? It sounds like one of those crazy Sept. 11 rumors, but it's actually a law-enforcement theory about how the al-Qaeda...},
  langid = {english},
  organization = {TIME}
}

@inproceedings{condeAnalyzingStudentsWhatsApp2019,
  title = {Analyzing {{Students}}’ {{WhatsApp Messages}} to {{Evaluate}} the {{Individual Acquisition}} of {{Teamwork Competence}}},
  booktitle = {Learning and {{Collaboration Technologies}}. {{Ubiquitous}} and {{Virtual Environments}} for {{Learning}} and {{Collaboration}}},
  author = {Conde, Miguel Á. and Rodríguez-Sedano, Francisco J. and Rodríguez-Lera, Francisco J. and Gutiérrez-Fernández, Alexis and Guerrero-Higueras, Ángel M.},
  editor = {Zaphiris, Panayiotis and Ioannou, Andri},
  date = {2019},
  pages = {26--36},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-21817-1_3},
  abstract = {In our present professional and educational contexts one of the key competences to assess is the teamwork competence. However, this require not only to explore the development of the competence by a group but how it is acquired by each of its members. In order to do so it is necessary to analyze several issues and one of the most relevant is students’ interaction. The problem is that the tools that students employ to interact in their learning context are not those that they use in their daily life. That’s why it is necessary to explore the students’ interaction that happens through instant messaging tools, and the most popular is WhatsApp. This paper explores the problem of analyzing WhatsApp messages and how to compile these evidences in such a way that they can be explored through a learning analytics tool. The implementation shows that the use of WhatsApp messages is possible but requires to take into account other issues such as how to manage interoperability and how to deal with user sensitive information.},
  isbn = {978-3-030-21817-1},
  langid = {english}
}

@article{conwayCodeWarsSteganography2003,
  title = {Code {{Wars}}: {{Steganography}}, {{Signals Intelligence}}, and {{Terrorism}}},
  author = {Conway, Maura},
  date = {2003-02-16},
  url = {https://doras.dcu.ie/494/1/know_tech_pol_16_2_2003.pdf},
  abstract = {This paper describes and discusses the process of secret communication known as steganography. The argument advanced here is that terrorists are unlikely to be employing digital steganography to facilitate secret intra-group communication as has been claimed. This is because terrorist use of digital steganography is both technically and operationally implausible. The position adopted in this paper is that terrorists are likely to employ low-tech steganography such as semagrams and null ciphers instead.},
  langid = {english}
}

@online{coppTrumpOfficialsTexted2025,
  title = {Trump Officials Texted Attack Plans to a Group Chat in a Secure App That Included a Journalist},
  author = {Copp, Tara and Madhani, Aamer and Tucker, Eric},
  date = {2025-03-24T19:02:02},
  url = {https://apnews.com/article/war-plans-trump-hegseth-atlantic-230718a984911dd8663d59edbcb86f2a},
  urldate = {2025-03-25},
  abstract = {President Donald Trump is downplaying the texting of attack plans to a group chat that included a journalist as “the only glitch in two months” of his administration.},
  langid = {english},
  organization = {AP News}
}

@online{coxDataBrokerSelling2022,
  title = {Data {{Broker Is Selling Location Data}} of {{People Who Visit Abortion Clinics}}},
  author = {Cox, Joseph},
  date = {2022-05-03T16:46:42+00:00},
  url = {https://www.vice.com/en/article/location-data-abortion-clinics-safegraph-planned-parenthood/},
  urldate = {2025-03-26},
  abstract = {It costs just over \$160 to get a week's worth of data on where people who visited Planned Parenthood came from, and where they went afterwards.},
  langid = {american},
  organization = {VICE}
}

@online{coxHowNewSuspected2017,
  title = {How the {{New Suspected NSA Leaker Reality Winner Was Caught}}},
  author = {Cox, Joseph},
  date = {2017-06-06T11:33:21+00:00},
  url = {https://www.vice.com/en/article/nsa-suspected-leaker-reality-leigh-winner-caught/},
  urldate = {2025-03-26},
  abstract = {From the characteristics of physical documents, to not using work computers, there’s plenty to learn from the recent bombshell leaking charge.},
  langid = {american},
  organization = {VICE}
}

@online{danielChatControlEnd2024,
  title = {Chat {{Control}}—{{The End Of Private Messaging As We Know It}}?},
  author = {Daniel, Lars},
  date = {2024-12-19},
  url = {https://www.forbes.com/sites/larsdaniel/2024/12/19/eus-chat-control-the-end-of-private-messaging-as-we-know-it/},
  urldate = {2025-03-25},
  abstract = {The EU wants to search all private chats, messages, and emails—here's what you need to know.},
  langid = {english},
  organization = {Forbes}
}

@online{dasSteganographySteganalysisDifferent2011,
  title = {Steganography and {{Steganalysis}}: {{Different Approaches}}},
  shorttitle = {Steganography and {{Steganalysis}}},
  author = {Das, Soumyendu and Das, Subhendu and Bandyopadhyay, Bijoy and Sanyal, Sugata},
  date = {2011-11-16},
  eprint = {1111.3758},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1111.3758},
  url = {http://arxiv.org/abs/1111.3758},
  urldate = {2025-03-12},
  abstract = {Steganography is the technique of hiding confidential information within any media. Steganography is often confused with cryptography because the two are similar in the way that they both are used to protect confidential information. The difference between the two is in the appearance in the processed output; the output of steganography operation is not apparently visible but in cryptography the output is scrambled so that it can draw attention. Steganlysis is process to detect of presence of steganography. In this article we have tried to elucidate the different approaches towards implementation of steganography using 'multimedia' file (text, static image, audio and video) and Network IP datagram as cover. Also some methods of steganalysis will be discussed.},
  pubstate = {prepublished},
  version = {1}
}

@article{davidavicieneEvaluationUserExperience2021,
  title = {Evaluation of User Experience in Augmented Reality Mobile Applications},
  author = {Davidavičienė, Vida and Raudeliūnienė, Jurgita and Viršilaitė, Rima},
  date = {2021-02-05},
  journaltitle = {Journal of Business Economics and Management},
  volume = {22},
  number = {2},
  pages = {467--481},
  issn = {2029-4433},
  doi = {10.3846/jbem.2020.13999},
  url = {https://journals.vilniustech.lt/index.php/JBEM/article/view/13999},
  urldate = {2025-04-10},
  abstract = {Globalization, technological development and a dynamic business environment influence the change of customer information demands. It becomes vital for organizations to find out the customer demand change and discover technological solutions to satisfy these demands. One of these technologies is augmented reality, which connects real and digital environments by expanding it with digitally coded information which is decoded by using a specific device. As this type of technology enables the changing information needs of customers to be met faster, organizations are increasingly using these technological solutions to achieve a variety of purposes: to position products innovatively, increase product awareness, create added value for the customer, increase sales. However, organizations often face the challenge of evaluating commercial augmented reality mobile applications in user experience. A two-case study has been selected to evaluate the user experience of augmented reality commercial mobile applications and provide recommendations for their development to address this issue. In this research, such methods as scoping scientific literature review, expert evaluation, and user experience questionnaire method were used. The study has identified the main factors influencing the positive user experience: the explicit purpose of the application, easy to use and learn, smooth operation, imaginative information presentation, and interactivity. First published online 29 December 2020 													Keyword :  																											augmented reality,  																			mobile application,  																			technology,  																			user,  																			user experience,  																			evaluation 																								 						 													 								How to Cite 								 									 										   Davidavičienė, V., Raudeliūnienė, J., \& Viršilaitė, R. (2021). Evaluation of user experience in augmented reality mobile applications. Journal of Business Economics and Management, 22(2), 467-481. https://doi.org/10.3846/jbem.2020.13999 									 									 										 											More Citation Formats 											 										 										 																							 													 														ACM 													 												 																							 													 														ACS 													 												 																							 													 														APA 													 												 																							 													 														ABNT 													 												 																							 													 														Chicago 													 												 																							 													 														Harvard 													 												 																							 													 														IEEE 													 												 																							 													 														MLA 													 												 																							 													 														Turabian 													 												 																							 													 														Vancouver},
  issue = {2},
  langid = {english}
}

@online{debusmannTrumpIntelligenceChiefs2025,
  title = {Trump and Intelligence Chiefs Play down {{Signal}} Group Chat Leak},
  author = {Debusmann, Bernd and Drenon, Brandon},
  date = {2025-03-25},
  url = {https://www.bbc.com/news/articles/cp8vgr0p8n6o},
  urldate = {2025-03-25},
  abstract = {President Trump also defended his national security team after a reporter was added to their message thread.},
  langid = {british}
}

@online{deepseek-aiDeepSeekR1IncentivizingReasoning2025,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  date = {2025-01-22},
  eprint = {2501.12948},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.12948},
  url = {http://arxiv.org/abs/2501.12948},
  urldate = {2025-03-28},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  pubstate = {prepublished}
}

@software{deepseekDeepseekaiDeepSeekR12025,
  title = {Deepseek-Ai/{{DeepSeek-R1}}},
  author = {{DeepSeek}},
  date = {2025-03-27T12:46:34Z},
  origdate = {2025-01-20T11:57:28Z},
  url = {https://github.com/deepseek-ai/DeepSeek-R1},
  urldate = {2025-03-27},
  organization = {DeepSeek}
}

@article{dembartEndUserHide2001,
  entrysubtype = {newspaper},
  title = {The {{End User}}: {{Hide Your Secrets}}},
  shorttitle = {The {{End User}}},
  author = {Dembart, Lee},
  date = {2001-05-07},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2001/05/07/business/worldbusiness/IHT-the-end-user-hide-your-secrets.html},
  urldate = {2025-03-11},
  abstract = {Everyone knows by now that the Internet is insecure — the bad guys can eavesdrop on what you send over the Web — and most people probably know that encryption is one way around the problem. If there's something that you don't want anyone but},
  journalsubtitle = {Business},
  langid = {american}
}

@software{devitoZdevitoATen2025,
  title = {Zdevito/{{ATen}}},
  author = {DeVito, Zachary},
  date = {2025-03-02T13:28:59Z},
  origdate = {2017-06-20T23:50:41Z},
  url = {https://github.com/zdevito/ATen},
  urldate = {2025-03-11},
  abstract = {ATen: A TENsor library for C++11}
}

@article{dolevSecurityPublicKey1983,
  title = {On the Security of Public Key Protocols},
  author = {Dolev, D. and Yao, A.},
  date = {1983-03},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {29},
  number = {2},
  pages = {198--208},
  issn = {1557-9654},
  doi = {10.1109/TIT.1983.1056650},
  url = {https://ieeexplore.ieee.org/document/1056650},
  urldate = {2025-03-28},
  abstract = {Recently the use of public key encryption to provide secure network communication has received considerable attention. Such public key systems are usually effective against passive eavesdroppers, who merely tap the lines and try to decipher the message. It has been pointed out, however, that an improperly designed protocol could be vulnerable to an active saboteur, one who may impersonate another user or alter the message being transmitted. Several models are formulated in which the security of protocols can be discussed precisely. Algorithms and characterizations that can be used to determine protocol security in these models are given.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}}
}

@online{donnerFinetuningLLMYour2024,
  title = {Fine-Tuning an {{LLM}} on Your Texts: Part 2 - Exploring Your Text Data},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-01-17T15:10:39+00:00},
  url = {https://edwarddonner.com/2024/01/17/fine-tune-llm-on-texts-part-2-the-data/},
  urldate = {2025-01-24},
  abstract = {In part 2 of my guide to fine-tuning an LLM on your text messages, we use our CSV downloads to read, organize and investigate our data.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerFinetuningLLMYour2024a,
  title = {Fine-Tuning an {{LLM}} on Your Texts: Part 3 - Curating the Dataset},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-01-24T23:17:43+00:00},
  url = {https://edwarddonner.com/2024/01/24/fine-tuning-an-llm-on-your-texts-part-3-curating-the-dataset/},
  urldate = {2025-01-24},
  abstract = {In part 3 of my guide to fine-tuning an LLM on your text messages, we curate the dataset, encrypt and upload to Hugging Face.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerFinetuningLLMYour2024b,
  title = {Fine-Tuning an {{LLM}} on Your Texts: Part 4 - {{QLoRA}}},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-01-31T17:42:51+00:00},
  url = {https://edwarddonner.com/2024/01/31/fine-tuning-an-llm-on-your-text-messages-using-qlora/},
  urldate = {2025-01-24},
  abstract = {In part 4 of my guide to fine-tuning an LLM on your text message history, we train using QLoRA and experiment with hyper-parameters.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerFinetuningLLMYour2024c,
  title = {Fine-Tuning an {{LLM}} on Your Texts: A Simulation of You},
  shorttitle = {Fine-Tuning an {{LLM}} on Your Texts},
  author = {Donner, Edward},
  date = {2024-02-07T16:04:24+00:00},
  url = {https://edwarddonner.com/2024/02/07/fine-tune-llm-on-texts-a-simulation-of-you/},
  urldate = {2025-04-05},
  abstract = {In this final part of my guide to simulating yourself from your text messages, we take your fine-tuned model and run Text Generation.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerSimulationMeFinetuning2024,
  title = {A Simulation of Me: Fine-Tuning an {{LLM}} on 240k Text Messages},
  shorttitle = {A Simulation of Me},
  author = {Donner, Edward},
  date = {2024-01-02T21:26:11+00:00},
  url = {https://edwarddonner.com/2024/01/02/fine-tuning-an-llm-on-240k-text-messages/},
  urldate = {2025-01-24},
  abstract = {Armed with a download of my 240,000 text message and Whatsapp history, I was able to fine-tune an LLM to create convincing conversations.},
  langid = {american},
  organization = {Edward Donner}
}

@online{donnerStepStepGuide2024,
  title = {Step by Step Guide: Fine-Tune an {{LLM}} on Your Texts (Part 1)},
  shorttitle = {Step by Step Guide},
  author = {Donner, Edward},
  date = {2024-01-11T14:22:20+00:00},
  url = {https://edwarddonner.com/2024/01/11/fine-tune-llama-for-text-messages-part-1/},
  urldate = {2025-01-24},
  abstract = {Part 1 of my step-by-step guide on how to fine-tune an LLM on your entire text message and WhatsApp history.},
  langid = {american},
  organization = {Edward Donner}
}

@article{drouinChattingSophisticatedChatbot2022,
  title = {Is Chatting with a Sophisticated Chatbot as Good as Chatting Online or {{FTF}} with a Stranger?},
  author = {Drouin, Michelle and Sprecher, Susan and Nicola, Robert and Perkins, Taylor},
  date = {2022-03-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {128},
  pages = {107100},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.107100},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563221004234},
  urldate = {2025-04-05},
  abstract = {Emotionally-responsive chatbots are marketed as agents with which one can form emotional connections. They can also become weak ties in the outer layers of one's acquaintance network and available for social support. In this experiment, which was designed to study the acquaintance process, we randomly assigned 417 participants into three conditions: face-to-face (FTF) chat with a human, online chat with a human, and online chat with a commercially-available, emotionally-responsive chatbot, Replika. After a 20-min getting-acquainted chat, participants reported their affective state and relational evaluations of the chat. Additionally, all chats were recorded and text analyzed using the Linguistic Inquiry and Word Count (LIWC) program. In all conditions, participants reported moderate levels of positive emotions and low levels of negative emotions. Those who chatted FTF with a human reported significantly more negative emotions than those who chatted with a bot. However, those who chatted with a human also reported more homophily with and liking of their chat partner and that their partner was more responsive. Meanwhile, participants had fewest conversational concerns with the chatbot. These findings have implications for future computer-mediated interaction studies: conversations with chatbots appear to have different affordances and effects on chatter enjoyment and conversational concerns in getting-acquainted contexts. These results may help designers improve reception and marketability for chatbots in consumer markets.}
}

@software{drukAndriydrukLMPlayground2025,
  title = {Andriydruk/{{LMPlayground}}},
  author = {Druk, Andriy},
  date = {2025-03-01T12:44:43Z},
  origdate = {2024-03-16T13:51:07Z},
  url = {https://github.com/andriydruk/LMPlayground},
  urldate = {2025-03-11},
  abstract = {Language Model Playground}
}

@article{duportailAskedTinderMy2017,
  entrysubtype = {newspaper},
  title = {I Asked {{Tinder}} for My Data. {{It}} Sent Me 800 Pages of My Deepest, Darkest Secrets},
  author = {Duportail, Judith},
  date = {2017-09-26T06:10:35},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold},
  urldate = {2025-03-26},
  abstract = {The dating app knows me better than I do, but these reams of intimate information are just the tip of the iceberg. What if my data is hacked – or sold?},
  journalsubtitle = {Technology},
  langid = {british}
}

@article{edwardsFBIPaidMore2016,
  entrysubtype = {newspaper},
  title = {{{FBI}} Paid More than \$1.3 Million to Break into {{San Bernardino iPhone}}},
  author = {Edwards, Julia},
  date = {2016-04-22T17:52:08},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/article/technology/fbi-paid-more-than-13-million-to-break-into-san-bernardino-iphone-idUSKCN0XI2IB/},
  urldate = {2025-02-18},
  abstract = {Federal Bureau of Investigation Director James Comey said on Thursday the agency paid more to get into the iPhone of one of the San Bernardino shooters than he will make in the remaining seven years and four months he has in his job.},
  journalsubtitle = {Technology},
  langid = {american}
}

@online{eldanTinyStoriesHowSmall2023,
  title = {{{TinyStories}}: {{How Small Can Language Models Be}} and {{Still Speak Coherent English}}?},
  shorttitle = {{{TinyStories}}},
  author = {Eldan, Ronen and Li, Yuanzhi},
  date = {2023-05-24},
  eprint = {2305.07759},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2305.07759},
  url = {http://arxiv.org/abs/2305.07759},
  urldate = {2024-11-27},
  abstract = {Language models (LMs) are powerful tools for natural language processing, but they often struggle to produce coherent and fluent text when they are small. Models with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can rarely generate coherent and consistent English text beyond a few words even after extensive training. This raises the question of whether the emergence of the ability to produce coherent English text only occurs at larger scales (with hundreds of millions of parameters or more) and complex architectures (with many layers of global attention). In this work, we introduce TinyStories, a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We show that TinyStories can be used to train and evaluate LMs that are much smaller than the state-of-the-art models (below 10 million total parameters), or have much simpler architectures (with only one transformer block), yet still produce fluent and consistent stories with several paragraphs that are diverse and have almost perfect grammar, and demonstrate reasoning capabilities. We also introduce a new paradigm for the evaluation of language models: We suggest a framework which uses GPT-4 to grade the content generated by these models as if those were stories written by students and graded by a (human) teacher. This new paradigm overcomes the flaws of standard benchmarks which often requires the model's output to be very structures, and moreover provides a multidimensional score for the model, providing scores for different capabilities such as grammar, creativity and consistency. We hope that TinyStories can facilitate the development, analysis and research of LMs, especially for low-resource or specialized domains, and shed light on the emergence of language capabilities in LMs.},
  pubstate = {prepublished}
}

@article{evsutinDigitalSteganographyWatermarking2020,
  title = {Digital {{Steganography}} and {{Watermarking}} for {{Digital Images}}: {{A Review}} of {{Current Research Directions}}},
  shorttitle = {Digital {{Steganography}} and {{Watermarking}} for {{Digital Images}}},
  author = {Evsutin, Oleg and Melman, Anna and Meshcheryakov, Roman},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {166589--166611},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3022779},
  url = {https://ieeexplore.ieee.org/abstract/document/9187785},
  urldate = {2025-03-27},
  abstract = {The development of information technology has led to a significant increase in the share of multimedia traffic in data networks. This has necessitated to solve the following information security tasks in relation to multimedia data: protection against leakage of confidential information, as well as identifying the source of the leak; ensuring the impossibility of unauthorized changes; copyright protection for digital objects. To solve such kind of problems, methods of steganography and watermarking are designed that implement embedding in digital objects hidden information sequences for various purposes. In this paper, an overview of promising research in the specified area is provided. First of all, we provide basic information about this field of research and consider the main applications of its methods. Next, we review works demonstrating current trends in the development of methods and algorithms for data hiding in digital images. This review is not exhaustive; it focuses on contemporary works illustrating current research directions in the field of information embedding in digital images. This is the main feature of review, which distinguishes it from previously published reviews. The paper concludes with an analysis of identified problems in the field of digital steganography and digital watermarking.},
  eventtitle = {{{IEEE Access}}}
}

@online{fangGeneratingSteganographicText2017,
  title = {Generating {{Steganographic Text}} with {{LSTMs}}},
  author = {Fang, Tina and Jaggi, Martin and Argyraki, Katerina},
  date = {2017-05-30},
  eprint = {1705.10742},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1705.10742},
  url = {http://arxiv.org/abs/1705.10742},
  urldate = {2025-01-26},
  abstract = {Motivated by concerns for user privacy, we design a steganographic system ("stegosystem") that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.},
  pubstate = {prepublished}
}

@online{fbiUpdateFBIInvestigation2024,
  type = {Press Release},
  title = {Update on the {{FBI Investigation}} of the {{Attempted Assassination}} of {{Former President Donald Trump}}},
  author = {{FBI}},
  date = {2024-07-15T15:03:00Z},
  url = {https://www.fbi.gov/news/press-releases/update-on-the-fbi-investigation-of-the-attempted-assassination-of-former-president-donald-trump},
  urldate = {2024-11-26},
  abstract = {The FBI continues to investigate the shooting incident at the July 13 rally in Butler, Pennsylvania, as an assassination attempt on former President Donald Trump and as potential domestic terrorism. The investigation is still in the early stages, and the FBI is providing the following updates.},
  langid = {american},
  organization = {Federal Bureau of Investigation}
}

@online{gaureL^2M^2C^22024,
  title = {L\textasciicircum 2 * {{M}}\textasciicircum 2 = {{C}}\textasciicircum 2: {{Large Language Models}} Are {{Covert Channels}}},
  author = {Gaure, Simen and Koffas, Stefanos and Picek, Stjepan and Rønjom, Sondre},
  date = {2024-10-07},
  eprint = {2405.15652},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.15652},
  url = {http://arxiv.org/abs/2405.15652},
  urldate = {2025-03-12},
  abstract = {Large Language Models (LLMs) have gained significant popularity recently. LLMs are susceptible to various attacks but can also improve the security of diverse systems. However, besides enabling more secure systems, how well do open source LLMs behave as covertext distributions to, e.g., facilitate censorship-resistant communication? In this paper, we explore open-source LLM-based covert channels. We empirically measure the security vs. capacity of an open-source LLM model (Llama-7B) to assess its performance as a covert channel. Although our results indicate that such channels are not likely to achieve high practical bitrates, we also show that the chance for an adversary to detect covert communication is low. To ensure our results can be used with the least effort as a general reference, we employ a conceptually simple and concise scheme and only assume public models.},
  pubstate = {prepublished},
  version = {2}
}

@software{gerganovGgerganovGgml2024,
  title = {Ggerganov/Ggml},
  author = {Gerganov, Georgi},
  date = {2024-12-08T06:39:36Z},
  origdate = {2022-09-18T17:07:19Z},
  url = {https://github.com/ggerganov/ggml},
  urldate = {2024-12-08},
  abstract = {Tensor library for machine learning}
}

@software{gerganovGgerganovLlamacpp2024,
  title = {Ggerganov/Llama.Cpp},
  author = {Gerganov, Georgi},
  date = {2024-12-08T12:18:03Z},
  origdate = {2023-03-10T18:58:00Z},
  url = {https://github.com/ggerganov/llama.cpp},
  urldate = {2024-12-08},
  abstract = {LLM inference in C/C++}
}

@software{gerganovGgerganovWhispercpp2024,
  title = {Ggerganov/Whisper.Cpp},
  author = {Gerganov, Georgi},
  date = {2024-12-08T15:39:54Z},
  origdate = {2022-09-25T18:26:37Z},
  url = {https://github.com/ggerganov/whisper.cpp},
  urldate = {2024-12-08},
  abstract = {Port of OpenAI's Whisper model in C/C++}
}

@software{ghorbaniAghorbaniPocketpalai2025,
  title = {A-Ghorbani/Pocketpal-Ai},
  author = {Ghorbani, Asghar},
  date = {2025-03-11T17:43:15Z},
  origdate = {2024-08-25T08:14:11Z},
  url = {https://github.com/a-ghorbani/pocketpal-ai},
  urldate = {2025-03-11},
  abstract = {An app that brings language models directly to your phone.}
}

@article{girayAssessmentStudentSatisfaction2021,
  title = {An Assessment of Student Satisfaction with E-Learning: {{An}} Empirical Study with Computer and Software Engineering Undergraduate Students in {{Turkey}} under Pandemic Conditions},
  shorttitle = {An Assessment of Student Satisfaction with E-Learning},
  author = {Giray, Görkem},
  date = {2021-11-01},
  journaltitle = {Education and Information Technologies},
  shortjournal = {Educ Inf Technol},
  volume = {26},
  number = {6},
  pages = {6651--6673},
  issn = {1573-7608},
  doi = {10.1007/s10639-021-10454-x},
  url = {https://doi.org/10.1007/s10639-021-10454-x},
  urldate = {2025-04-29},
  abstract = {As COVID-19 reached Turkey in March 2020, all universities switched to e-learning in a very short period. Computer and software engineering (CE/SE) undergraduate students studying at university campuses have switched to e-learning. This paper seeks to understand the e-learning experience of CE/SE undergraduate students. A questionnaire was created and applied to CE/SE undergraduate students in Turkish universities. The data were analyzed using quantitative and qualitative techniques. The questionnaire received 290 usable responses. The highlights from the findings include: the participants (1) used video recordings intensively for e-learning and found them useful; (2) found face-to-face lectures more beneficial compared to digital live lectures; (3) used external online resources to improve their learning performance in courses; (4) thought that the materials and methods utilized for assessment should be adapted to e-learning for a better and fair evaluation; (5) perceived significantly less instructor support and classmate interaction and collaboration in e-learning compared to on-campus education settings; (6) rated their perceived satisfaction from e-learning as 2.85, slightly under the mid-level of the 5-point Likert scale; (7) perceived instructor support, student interaction and collaboration, and student autonomy as noteworthy factors in high-quality e-learning.},
  langid = {english}
}

@online{gleaveMakingCompressionAlgorithms2017,
  title = {Making Compression Algorithms for {{Unicode}} Text},
  author = {Gleave, Adam and Steinruecken, Christian},
  date = {2017-01-15},
  eprint = {1701.04047},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1701.04047},
  url = {http://arxiv.org/abs/1701.04047},
  urldate = {2025-04-01},
  abstract = {The majority of online content is written in languages other than English, and is most commonly encoded in UTF-8, the world's dominant Unicode character encoding. Traditional compression algorithms typically operate on individual bytes. While this approach works well for the single-byte ASCII encoding, it works poorly for UTF-8, where characters often span multiple bytes. Previous research has focused on developing Unicode compressors from scratch, which often failed to outperform established algorithms such as bzip2. We develop a technique to modify byte-based compressors to operate directly on Unicode characters, and implement variants of LZW and PPM that apply this technique. We find that our method substantially improves compression effectiveness on a UTF-8 corpus, with our PPM variant outperforming the state-of-the-art PPMII compressor. On ASCII and binary files, our variants perform similarly to the original unmodified compressors.},
  pubstate = {prepublished}
}

@online{gnuprojectWhatFreeSoftware,
  title = {What Is {{Free Software}}? - {{GNU Project}} - {{Free Software Foundation}}},
  author = {{GNU Project}},
  url = {https://www.gnu.org/philosophy/free-sw.en.html},
  urldate = {2025-03-28}
}

@online{goldbergHereAreAttack2025,
  title = {Here {{Are}} the {{Attack Plans That Trump}}’s {{Advisers Shared}} on {{Signal}}},
  author = {Goldberg, Jeffrey and Harris, Shane},
  date = {2025-03-26},
  url = {https://www.theatlantic.com/politics/archive/2025/03/signal-group-chat-attack-plans-hegseth-goldberg/682176/},
  urldate = {2025-03-26},
  abstract = {The administration has downplayed the importance of the text messages inadvertently sent to The Atlantic’s editor in chief.},
  langid = {english},
  organization = {The Atlantic}
}

@online{goldbergTrumpAdministrationAccidentally2025,
  title = {The {{Trump Administration Accidentally Texted Me Its War Plans}}},
  author = {Goldberg, Jeffrey},
  date = {2025-03-24},
  url = {https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/},
  urldate = {2025-03-26},
  abstract = {U.S. national-security leaders included me in a group chat about upcoming military strikes in Yemen. I didn’t think it could be real. Then the bombs started falling.},
  langid = {english},
  organization = {The Atlantic}
}

@online{googleaiedgeteamTensorFlowLiteNow2024,
  title = {{{TensorFlow Lite}} Is Now {{LiteRT- Google Developers Blog}}},
  author = {{Google AI Edge team}},
  date = {2024-09-04},
  url = {https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/},
  urldate = {2025-03-18},
  abstract = {TensorFlow Lite, now named LiteRT, is still the same high-performance runtime for on-device AI, but with an expanded vision to support models authored in PyTorch, JAX, and Keras.},
  langid = {english}
}

@software{googleGoogleaiedgeLiteRT2025,
  title = {Google-Ai-Edge/{{LiteRT}}},
  author = {{Google}},
  date = {2025-03-18T20:52:11Z},
  origdate = {2024-09-04T03:33:35Z},
  url = {https://github.com/google-ai-edge/LiteRT},
  urldate = {2025-03-18},
  abstract = {LiteRT is the new name for TensorFlow Lite (TFLite). While the name is new, it's still the same trusted, high-performance runtime for on-device AI, now with an expanded vision.},
  organization = {google-ai-edge}
}

@software{googleGoogleKsp2025,
  title = {Google/Ksp},
  author = {{Google}},
  date = {2025-03-28T08:53:54Z},
  origdate = {2020-09-22T18:59:42Z},
  url = {https://github.com/google/ksp},
  urldate = {2025-03-29},
  abstract = {Kotlin Symbol Processing API},
  organization = {Google}
}

@software{googleGoogleSentencepiece2024,
  title = {Google/Sentencepiece},
  author = {{Google}},
  date = {2024-12-28T19:47:17Z},
  origdate = {2017-03-07T10:03:48Z},
  url = {https://github.com/google/sentencepiece},
  urldate = {2024-12-28},
  abstract = {Unsupervised text tokenizer for Neural Network-based text generation.},
  organization = {Google}
}

@online{gopalakrishnanTopicalChatKnowledgeGroundedOpenDomain2023,
  title = {Topical-{{Chat}}: {{Towards Knowledge-Grounded Open-Domain Conversations}}},
  shorttitle = {Topical-{{Chat}}},
  author = {Gopalakrishnan, Karthik and Hedayatnia, Behnam and Chen, Qinlang and Gottardi, Anna and Kwatra, Sanjeev and Venkatesh, Anu and Gabriel, Raefer and Hakkani-Tur, Dilek},
  date = {2023-08-23},
  eprint = {2308.11995},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.11995},
  url = {http://arxiv.org/abs/2308.11995},
  urldate = {2025-04-05},
  abstract = {Building socialbots that can have deep, engaging open-domain conversations with humans is one of the grand challenges of artificial intelligence (AI). To this end, bots need to be able to leverage world knowledge spanning several domains effectively when conversing with humans who have their own world knowledge. Existing knowledge-grounded conversation datasets are primarily stylized with explicit roles for conversation partners. These datasets also do not explore depth or breadth of topical coverage with transitions in conversations. We introduce Topical-Chat, a knowledge-grounded human-human conversation dataset where the underlying knowledge spans 8 broad topics and conversation partners don't have explicitly defined roles, to help further research in open-domain conversational AI. We also train several state-of-the-art encoder-decoder conversational models on Topical-Chat and perform automated and human evaluation for benchmarking.},
  pubstate = {prepublished}
}

@online{gradleGradleBuildTool2025,
  title = {Gradle {{Build Tool}}},
  author = {{Gradle}},
  date = {2025-03-20},
  url = {https://gradle.org/},
  urldate = {2025-03-29},
  abstract = {Accelerate developer productivity. Gradle helps teams build, automate and deliver better software, faster.},
  langid = {american},
  organization = {Gradle}
}

@article{greenwaldBoundlessInformantNSAs2013,
  entrysubtype = {newspaper},
  title = {Boundless {{Informant}}: The {{NSA}}'s Secret Tool to Track Global Surveillance Data},
  shorttitle = {Boundless {{Informant}}},
  author = {Greenwald, Glenn and MacAskill, Ewen},
  date = {2013-06-11T13:00:00},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jun/08/nsa-boundless-informant-global-datamining},
  urldate = {2025-03-26},
  abstract = {Revealed: The NSA's powerful tool for cataloguing global surveillance data – including figures on US collection • Boundless Informant: mission outlined in four slides• Read the NSA's frequently asked questions document},
  journalsubtitle = {US news},
  langid = {british}
}

@article{greenwaldEdwardSnowdenWhistleblower2013,
  entrysubtype = {newspaper},
  title = {Edward {{Snowden}}: The Whistleblower behind the {{NSA}} Surveillance Revelations},
  shorttitle = {Edward {{Snowden}}},
  author = {Greenwald, Glenn and MacAskill, Ewen and Poitras, Laura},
  date = {2013-06-11T13:00:00},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jun/09/edward-snowden-nsa-whistleblower-surveillance},
  urldate = {2025-03-26},
  abstract = {The 29-year-old source behind the biggest intelligence leak in the NSA’s history explains his motives, his uncertain future and why he never intended on hiding in the shadows},
  journalsubtitle = {US news},
  langid = {british}
}

@article{greenwaldNSAPrismProgram2013,
  entrysubtype = {newspaper},
  title = {{{NSA Prism}} Program Taps in to User Data of {{Apple}}, {{Google}} and Others},
  author = {Greenwald, Glenn and MacAskill, Ewen},
  date = {2013-06-07T19:23:00},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jun/06/us-tech-giants-nsa-data},
  urldate = {2025-03-26},
  abstract = {• Top-secret Prism program claims direct access to servers of firms including Google, Apple and Facebook• Companies deny any knowledge of program in operation since 2007},
  journalsubtitle = {US news},
  langid = {british}
}

@article{greenwaldXKeyscoreNSATool2013,
  entrysubtype = {newspaper},
  title = {{{XKeyscore}}: {{NSA}} Tool Collects 'Nearly Everything a User Does on the Internet'},
  shorttitle = {{{XKeyscore}}},
  author = {Greenwald, Glenn},
  date = {2013-07-31T12:56:51},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/jul/31/nsa-top-secret-program-online-data},
  urldate = {2025-03-26},
  abstract = {• XKeyscore gives 'widest-reaching' collection of online data• NSA analysts require no prior authorization for searches• Sweeps up emails, social media activity and browsing history},
  journalsubtitle = {US news},
  langid = {british}
}

@article{guptaChatGPTThreatGPTImpact2023,
  title = {From {{ChatGPT}} to {{ThreatGPT}}: {{Impact}} of {{Generative AI}} in {{Cybersecurity}} and {{Privacy}}},
  shorttitle = {From {{ChatGPT}} to {{ThreatGPT}}},
  author = {Gupta, Maanak and Akiri, Charankumar and Aryal, Kshitiz and Parker, Eli and Praharaj, Lopamudra},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {80218--80245},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3300381},
  url = {https://ieeexplore.ieee.org/abstract/document/10198233},
  urldate = {2025-03-27},
  abstract = {Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.},
  eventtitle = {{{IEEE Access}}}
}

@article{hamzahLinguisticSteganographyFramework2021,
  title = {A Linguistic Steganography Framework Using {{Arabic}} Calligraphy},
  author = {family=Hamzah, given=Ali. A., given-i={{Ali}}A and Khattab, Sherif and Bayomi, Hanaa},
  date = {2021-09-01},
  journaltitle = {Journal of King Saud University - Computer and Information Sciences},
  shortjournal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {33},
  number = {7},
  pages = {865--877},
  issn = {1319-1578},
  doi = {10.1016/j.jksuci.2019.04.015},
  url = {https://www.sciencedirect.com/science/article/pii/S1319157819301818},
  urldate = {2025-03-13},
  abstract = {In linguistic steganography, languages’ features are employed to hide information. The Arabic language has a rich set of features which have not been utilized until now in this area. In particular, Arabic calligraphy contains multiple fonts and multiple shapes of Arabic alphabet letters. In this paper, a framework that uses Arabic calligraphy to hide information is proposed. The phases of the framework are preparation phase, embedding phase and extraction phase. The embedding phase uses string matching to generate stego text and accompanying letter shapes according to a secret message. The framework also includes corpus creation and a modification of the Aho-Corasick string-matching algorithm. The Arabic font Naskh was used as a case study. A set of Arabic poetry and proverbs were used as a dataset. The framework was evaluated on capacity and security. Because the visual difference between the cover and the stego-cover must be unnoticeable to the human in any stego-system, the security in this framework is satisfying due there is no cover used. The cover represents the secret message itself and it provides high capacity to hide data also. The evaluation showed the potential of using the multiple shapes of Arabic letters to satisfy steganography requirements.}
}

@article{hanFolkloreSourceCoding2005,
  title = {Folklore in Source Coding: Information-Spectrum Approach},
  shorttitle = {Folklore in Source Coding},
  author = {Han, Te Sun},
  date = {2005-02},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {51},
  number = {2},
  pages = {747--753},
  issn = {1557-9654},
  doi = {10.1109/TIT.2004.840860},
  url = {https://ieeexplore.ieee.org/document/1386546},
  urldate = {2025-03-13},
  abstract = {Information theory has several traditional folklore problems about data compression or channel coding with reference to random number generation problems. Here, we focus on and reasonably formulate one of them from the viewpoint of information spectra. Specifically, we verify the validity of the folklore that the output from any source encoder working at the optimal coding rate with asymptotically vanishing probability of error looks like almost completely random.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}}
}

@article{haoReversibleNaturalLanguage2018,
  title = {Reversible Natural Language Watermarking Using Synonym Substitution and Arithmetic Coding},
  author = {Hao, Wei and Xiang, Lingyun and Li, Yan and Yang, Peng and Shen, Xiaobo},
  date = {2018},
  issn = {1546-2218},
  doi = {10.3970/cmc.2018.03510},
  url = {https://dr.ntu.edu.sg/handle/10356/106752},
  urldate = {2025-03-24},
  abstract = {For protecting the copyright of a text and recovering its original content harmlessly, this paper proposes a novel reversible natural language watermarking method that combines arithmetic coding and synonym substitution operations. By analyzing relative frequencies of synonymous words, synonyms employed for carrying payload are quantized into an unbalanced and redundant binary sequence. The quantized binary sequence is compressed by adaptive binary arithmetic coding losslessly to provide a spare for accommodating additional data. Then, the compressed data appended with the watermark are embedded into the cover text via synonym substitutions in an invertible manner. On the receiver side, the watermark and compressed data can be extracted by decoding the values of synonyms in the watermarked text, as a result of which the original context can be perfectly recovered by decompressing the extracted compressed data and substituting the replaced synonyms with their original synonyms. Experimental results demonstrate that the proposed method can extract the watermark successfully and achieve a lossless recovery of the original text. Additionally, it achieves a high embedding capacity.},
  langid = {english},
  annotation = {Accepted: 2019-06-26T05:16:58Z}
}

@article{hassijaUnleashingPotentialConversational2023,
  title = {Unleashing the {{Potential}} of {{Conversational AI}}: {{Amplifying Chat-GPT}}’s {{Capabilities}} and {{Tackling Technical Hurdles}}},
  shorttitle = {Unleashing the {{Potential}} of {{Conversational AI}}},
  author = {Hassija, Vikas and Chakrabarti, Arjab and Singh, Anushka and Chamola, Vinay and Sikdar, Biplab},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {143657--143682},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3339553},
  url = {https://ieeexplore.ieee.org/abstract/document/10343095},
  urldate = {2025-04-05},
  abstract = {Conversational AI has seen a growing interest among government, researchers, and industrialists. This comprehensive survey paper provides an in-depth analysis of large language models, specifically focusing on ChatGPT. This paper discusses the architecture, training process, and challenges associated with large language models, including bias, interpretability, and ethics. It explores various applications of ChatGPT and examines future research trends, such as improving model generalization, addressing data scarcity, and integrating multimodal capabilities. This survey also serves as a roadmap for researchers, practitioners, and policymakers, offering valuable insights into the current state and future potential of large language models and ChatGPT.}
}

@article{hernNewAIFake2019,
  entrysubtype = {newspaper},
  title = {New {{AI}} Fake Text Generator May Be Too Dangerous to Release, Say Creators},
  author = {Hern, Alex},
  date = {2019-02-14T17:00:54},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction},
  urldate = {2025-03-27},
  abstract = {The Elon Musk-backed nonprofit company OpenAI declines to release research publicly for fear of misuse},
  journalsubtitle = {Technology},
  langid = {british}
}

@article{hidellaarachchiInfluenceHumanAspects2023,
  title = {The {{Influence}} of {{Human Aspects}} on {{Requirements Engineering-related Activities}}: {{Software Practitioners}}’ {{Perspective}}},
  shorttitle = {The {{Influence}} of {{Human Aspects}} on {{Requirements Engineering-related Activities}}},
  author = {Hidellaarachchi, Dulaji and Grundy, John and Hoda, Rashina and Mueller, Ingo},
  date = {2023-07-22},
  journaltitle = {ACM Trans. Softw. Eng. Methodol.},
  volume = {32},
  number = {5},
  pages = {108:1--108:37},
  issn = {1049-331X},
  doi = {10.1145/3546943},
  url = {https://dl.acm.org/doi/10.1145/3546943},
  urldate = {2025-04-29},
  abstract = {Requirements Engineering (RE)-related activities require high collaboration between various roles in software engineering (SE), such as requirements engineers, stakeholders, developers, and so on. Their demographics, views, understanding of technologies, working styles, communication and collaboration capabilities make RE highly human-dependent. Identifying how “human aspects”—such as motivation, domain knowledge, communication skills, personality, emotions, culture, and so on—might impact RE-related activities would help us improve RE and SE in general. This study aims at better understanding current industry perspectives on the influence of human aspects on RE-related activities, specifically focusing on motivation and personality, by targeting software practitioners involved in RE-related activities. Our findings indicate that software practitioners consider motivation, domain knowledge, attitude, communication skills and personality as highly important human aspects when involved in RE-related activities. A set of factors were identified as software practitioners’ key motivational factors when involved in RE-related activities, along with important personality characteristics to have when involved in RE. We also identified factors that made individuals less effective when involved in RE-related activities and obtained some feedback on measuring individuals’ performance when involved in RE. The findings from our study suggest various areas needing more investigation, and we summarise a set of key recommendations for further research.}
}

@online{hoodIntroducingLlamafileMozilla2023,
  title = {Introducing Llamafile – {{Mozilla Hacks}} - the {{Web}} Developer Blog},
  author = {Hood, Stephen},
  date = {2023-11-29},
  url = {https://hacks.mozilla.org/2023/11/introducing-llamafile},
  urldate = {2025-03-29},
  abstract = {We're thrilled to announce the first release of llamafile, inviting the open source community to join this groundbreaking project.},
  langid = {american},
  organization = {Mozilla Hacks – the Web developer blog}
}

@online{hossainLLMProSAnalyzingLarge2025,
  title = {{{LLM-ProS}}: {{Analyzing Large Language Models}}' {{Performance}} in {{Competitive Problem Solving}}},
  shorttitle = {{{LLM-ProS}}},
  author = {Hossain, Md Sifat and Tabassum, Anika and Arefin, Md Fahim and Zaman, Tarannum Shaila},
  date = {2025-02-04},
  eprint = {2502.04355},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.04355},
  url = {http://arxiv.org/abs/2502.04355},
  urldate = {2025-03-24},
  abstract = {The rapid advancement of large language models has opened new avenues for automating complex problem-solving tasks such as algorithmic coding and competitive programming. This paper introduces a novel evaluation technique, LLM-ProS, to assess the performance of state-of-the-art LLMs on International Collegiate Programming Contest (ICPC) problems. Using a curated dataset of 166 World Finals problems from 2011 to 2024, we benchmark the models' reasoning, accuracy, and efficiency. We evaluate the five models-GPT-4o, Mistral Large, Llama-3.1-405B, and the o1 family, consisting of o1-mini and o1-preview, across critical metrics like correctness, resource utilization, and response calibration. Our results reveal significant differences in the models' abilities to generalize, adapt, and solve novel problems. We also investigated the impact of training methodologies, dataset contamination, and chain-of-thought reasoning on model performance. The findings provide new insights into optimizing LLMs for algorithmic tasks, highlighting both strengths and limitations of current models.},
  pubstate = {prepublished}
}

@article{huffmanMethodConstructionMinimumRedundancy1952,
  title = {A {{Method}} for the {{Construction}} of {{Minimum-Redundancy Codes}}},
  author = {Huffman, David A.},
  date = {1952-09},
  journaltitle = {Proceedings of the IRE},
  volume = {40},
  number = {9},
  pages = {1098--1101},
  issn = {2162-6634},
  doi = {10.1109/JRPROC.1952.273898},
  url = {https://ieeexplore.ieee.org/document/4051119},
  urldate = {2025-03-19},
  abstract = {An optimum method of coding an ensemble of messages consisting of a finite number of members is developed. A minimum-redundancy code is one constructed in such a way that the average number of coding digits per message is minimized.},
  eventtitle = {Proceedings of the {{IRE}}}
}

@online{huggingfaceGGUF,
  title = {{{GGUF}}},
  author = {{HuggingFace}},
  url = {https://huggingface.co/docs/hub/gguf},
  urldate = {2025-03-29},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingfaceModelCards,
  title = {Model {{Cards}}},
  author = {{HuggingFace}},
  url = {https://huggingface.co/docs/hub/model-cards},
  urldate = {2025-03-29},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingfaceModelsHuggingFace2025,
  title = {Models - {{Hugging Face}}},
  author = {{HuggingFace}},
  date = {2025-03-16},
  url = {https://huggingface.co/models},
  urldate = {2025-03-17},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingfacesmolmodelsresearchHuggingFaceTBSmolLM217BInstructGGUFHugging2024,
  title = {{{HuggingFaceTB}}/{{SmolLM2-1}}.{{7B-Instruct-GGUF}} · {{Hugging Face}}},
  author = {{Hugging Face Smol Models Research}},
  date = {2024-10-31},
  url = {https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huggingquantsHuggingquantsLlama321BInstructQ4_K_MGGUFHugging2024,
  title = {Hugging-Quants/{{Llama-3}}.2-{{1B-Instruct-Q4}}\_{{K}}\_{{M-GGUF}} · {{Hugging Face}}},
  author = {{Hugging Quants}},
  date = {2024-09-26},
  url = {https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q4_K_M-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  date = {2021-10-16},
  eprint = {2106.09685},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.09685},
  url = {http://arxiv.org/abs/2106.09685},
  urldate = {2025-03-27},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  pubstate = {prepublished}
}

@inproceedings{ischenPrivacyConcernsChatbot2020,
  title = {Privacy {{Concerns}} in {{Chatbot Interactions}}},
  booktitle = {Chatbot {{Research}} and {{Design}}},
  author = {Ischen, Carolin and Araujo, Theo and Voorveld, Hilde and family=Noort, given=Guda, prefix=van, useprefix=true and Smit, Edith},
  editor = {Følstad, Asbjørn and Araujo, Theo and Papadopoulos, Symeon and Law, Effie Lai-Chong and Granmo, Ole-Christoffer and Luger, Ewa and Brandtzaeg, Petter Bae},
  date = {2020},
  pages = {34--48},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-39540-7_3},
  abstract = {Chatbots are increasingly used in a commercial context to make product- or service-related recommendations. By doing so, they collect personal information of the user, similar to other online services. While privacy concerns in an online (website-) context are widely studied, research in the context of chatbot-interaction is lacking. This study investigates the extent to which chatbots with human-like cues influence perceptions of anthropomorphism (i.e., attribution of human-like characteristics), privacy concerns, and consequently, information disclosure, attitudes and recommendation adherence. Findings show that a human-like chatbot leads to more information disclosure, and recommendation adherence mediated by higher perceived anthropomorphism and subsequently, lower privacy concerns in comparison to a machine-like chatbot. This result does not hold in comparison to a website; human-like chatbot and website were perceived as equally high in anthropomorphism. The results show the importance of both mediating concepts in regards to attitudinal and behavioral outcomes when interacting with chatbots.},
  isbn = {978-3-030-39540-7},
  langid = {english}
}

@inproceedings{ishizakiTransformingJavaPrograms2014,
  title = {Transforming {{Java}} Programs for Concurrency Using {{Double-Checked Locking}} Pattern},
  booktitle = {2014 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  author = {Ishizaki, Kazuaki and Daijavad, Shahrokh and Nakatani, Toshio},
  date = {2014-03},
  pages = {128--129},
  doi = {10.1109/ISPASS.2014.6844469},
  url = {https://ieeexplore.ieee.org/abstract/document/6844469},
  urldate = {2025-03-31},
  abstract = {Java provides a synchronized construct for multi-core programming with many workloads. However, naïve use of the synchronized construct causes performance scalability problems due to lock contention. One of the sources of lock contentions is a synchronized collection class. There are known concurrency code patterns to alleviate lock contentions such as a Concurrent Collection (CC), Read-Write Lock (RWL), and Double-Checked Locking (DCL). To date, there is no algorithm to transform a program using DCL. This paper describes steps on how to rewrite synchronized blocks using DCL.},
  eventtitle = {2014 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})}
}

@online{jandaghiFaithfulPersonabasedConversational2023,
  title = {Faithful {{Persona-based Conversational Dataset Generation}} with {{Large Language Models}}},
  author = {Jandaghi, Pegah and Sheng, XiangHai and Bai, Xinyi and Pujara, Jay and Sidahmed, Hakim},
  date = {2023-12-15},
  eprint = {2312.10007},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10007},
  url = {http://arxiv.org/abs/2312.10007},
  urldate = {2025-04-05},
  abstract = {High-quality conversational datasets are essential for developing AI models that can communicate with users. One way to foster deeper interactions between a chatbot and its user is through personas, aspects of the user's character that provide insights into their personality, motivations, and behaviors. Training Natural Language Processing (NLP) models on a diverse and comprehensive persona-based dataset can lead to conversational models that create a deeper connection with the user, and maintain their engagement. In this paper, we leverage the power of Large Language Models (LLMs) to create a large, high-quality conversational dataset from a seed dataset. We propose a Generator-Critic architecture framework to expand the initial dataset, while improving the quality of its conversations. The Generator is an LLM prompted to output conversations. The Critic consists of a mixture of expert LLMs that control the quality of the generated conversations. These experts select the best generated conversations, which we then use to improve the Generator. We release Synthetic-Persona-Chat, consisting of 20k conversations seeded from Persona-Chat. We evaluate the quality of Synthetic-Persona-Chat and our generation framework on different dimensions through extensive experiments, and observe that the losing rate of Synthetic-Persona-Chat against Persona-Chat during Turing test decreases from 17.2\% to 8.8\% over three iterations.},
  pubstate = {prepublished}
}

@software{jaxJaxmlJax2025,
  title = {Jax-Ml/Jax},
  author = {{Jax}},
  date = {2025-03-17T10:56:50Z},
  origdate = {2018-10-25T21:25:02Z},
  url = {https://github.com/jax-ml/jax},
  urldate = {2025-03-17},
  abstract = {Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more},
  organization = {jax-ml}
}

@article{jebbReviewKeyLikert2021,
  title = {A {{Review}} of {{Key Likert Scale Development Advances}}: 1995–2019},
  shorttitle = {A {{Review}} of {{Key Likert Scale Development Advances}}},
  author = {Jebb, Andrew T. and Ng, Vincent and Tay, Louis},
  date = {2021-05-04},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {12},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2021.637547},
  url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.637547/full},
  urldate = {2025-04-10},
  abstract = {Developing self-report Likert scales is an essential part of modern psychology. However, it is hard for psychologists to remain apprised of best practices as methodological developments accumulate. To address this, this current paper offers a selective review of advances in Likert scale development that have occurred over the past 25 years. We reviewed six major measurement journals (e.g., Psychological Methods, Educational, and Psychological Measurement) between the years 1995–2019 and identified key advances, ultimately including 40 papers and offering written summaries of each. We supplemented this review with an in-depth discussion of five particular advances: (1) conceptions of construct validity, (2) creating better construct definitions, (3) readability tests for generating items, (4) alternative measures of precision [e.g., coefficient omega and item response theory (IRT) information], and (5) ant colony optimization (ACO) for creating short forms. The Supplementary Material provides further technical details on these advances and offers guidance on software implementation. This paper is intended to be a resource for psychological researchers to be informed about more recent psychometric progress in Likert scale creation.},
  langid = {english}
}

@online{jiangChatBugCommonVulnerability2025,
  title = {{{ChatBug}}: {{A Common Vulnerability}} of {{Aligned LLMs Induced}} by {{Chat Templates}}},
  shorttitle = {{{ChatBug}}},
  author = {Jiang, Fengqing and Xu, Zhangchen and Niu, Luyao and Lin, Bill Yuchen and Poovendran, Radha},
  date = {2025-01-07},
  eprint = {2406.12935},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.12935},
  url = {http://arxiv.org/abs/2406.12935},
  urldate = {2025-04-03},
  abstract = {Large language models (LLMs) are expected to follow instructions from users and engage in conversations. Techniques to enhance LLMs' instruction-following capabilities typically fine-tune them using data structured according to a predefined chat template. Although chat templates are shown to be effective in optimizing LLM performance, their impact on safety alignment of LLMs has been less understood, which is crucial for deploying LLMs safely at scale. In this paper, we investigate how chat templates affect safety alignment of LLMs. We identify a common vulnerability, named ChatBug, that is introduced by chat templates. Our key insight to identify ChatBug is that the chat templates provide a rigid format that need to be followed by LLMs, but not by users. Hence, a malicious user may not necessarily follow the chat template when prompting LLMs. Instead, malicious users could leverage their knowledge of the chat template and accordingly craft their prompts to bypass safety alignments of LLMs. We develop two attacks to exploit the ChatBug vulnerability. We demonstrate that a malicious user can exploit the ChatBug vulnerability of eight state-of-the-art (SOTA) LLMs and effectively elicit unintended responses from these models. Moreover, we show that ChatBug can be exploited by existing jailbreak attacks to enhance their attack success rates. We investigate potential countermeasures to ChatBug. Our results show that while adversarial training effectively mitigates the ChatBug vulnerability, the victim model incurs significant performance degradation. These results highlight the trade-off between safety alignment and helpfulness. Developing new methods for instruction tuning to balance this trade-off is an open and critical direction for future research},
  pubstate = {prepublished}
}

@article{jianReadingPrintDigital2022,
  title = {Reading in Print versus Digital Media Uses Different Cognitive Strategies: Evidence from Eye Movements during Science-Text Reading},
  shorttitle = {Reading in Print versus Digital Media Uses Different Cognitive Strategies},
  author = {Jian, Yu-Cin},
  date = {2022-09-01},
  journaltitle = {Reading and Writing},
  shortjournal = {Read Writ},
  volume = {35},
  number = {7},
  pages = {1549--1568},
  issn = {1573-0905},
  doi = {10.1007/s11145-021-10246-2},
  url = {https://doi.org/10.1007/s11145-021-10246-2},
  urldate = {2025-04-30},
  abstract = {Comparing comprehension outcomes in print and digital reading is an active area of research but little is known about the reading processes that these media entail. This study involved an eye-tracking experiment with 50 undergraduate students to investigate the differences in reading processes in print and digital media. The participants were randomly assigned to read the same six-page popular science article that included several diagrams either in print or on a tablet computer and then answer reading comprehension questions. The results showed that comprehension was better when reading in print. Eye-movement data indicated that the print and digital groups spent about the same amount of time processing the article, texts, diagrams, and diagram statements, but the time was not divided evenly between the first pass and the rereading stages. The digital group spent more time reading the article at the first-pass reading stage and seldom reread it. In contrast, the print group first skimmed the article and then reread the important parts, exhibiting both longer total fixation durations in the rereading stage and a higher number of rereading instances across pages. In sum, the findings indicate that reading in print versus digital media employs different cognitive strategies with those reading in print showing more selective and intentional reading behavior.},
  langid = {english}
}

@article{jonesSexDifferencesEmoji2020,
  title = {Sex Differences in Emoji Use, Familiarity, and Valence},
  author = {Jones, Lara L. and Wurm, Lee H. and Norville, Gregory A. and Mullins, Kate L.},
  date = {2020-07-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {108},
  pages = {106305},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2020.106305},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563220300595},
  urldate = {2025-04-10},
  abstract = {Emojis (particularly smiley emojis, ☺) are increasingly used in computer-mediated communication as well as in applied domains within marketing, healthcare, and psychology. The emotional negativity bias in the facial emotion processing literature posits that women are more sensitive to negative facial emotion than are men. Given the similarity in neural processing between human faces and smiley emojis, women may likewise view negative smiley emojis as more negative than do men. Moreover, the familiarity of the emoji and the participants' overall emoji use may increase the positivity of the emoji. To investigate these potential influences of sex, familiarity, and emoji use on the valence of smiley emojis, we assessed the familiarity and the perceived valence for 70 iOS facial emojis in a large sample (N~=~299; 163 women) of United States college students (Mage~=~19.66, SDage~=~2.72). Results indicated higher emoji usage and familiarity ratings for women than for men. In assessing valence we found higher overall positive ratings for men than for women. Consistent with the emotional negativity bias, this sex difference was limited to the negative smiley emojis with no sex difference in valence for the positive emojis. The obtained sex differences in smiley emojis’ use, familiarity, and valence are an important consideration in the selection of such stimuli in future studies.}
}

@article{kasterPrivatizedEspionageNSO2023,
  title = {Privatized Espionage: {{NSO Group Technologies}} and Its {{Pegasus}} Spyware},
  shorttitle = {Privatized Espionage},
  author = {Kaster, Sean D. and Ensign, Prescott C.},
  date = {2023},
  journaltitle = {Thunderbird International Business Review},
  volume = {65},
  number = {3},
  pages = {355--364},
  issn = {1520-6874},
  doi = {10.1002/tie.22321},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/tie.22321},
  urldate = {2025-03-12},
  abstract = {Advanced cyber technology like NSO Group Technologies' (NSO) controversial Pegasus spyware blurs distinctions between “good” and “bad.” This case follows the Israeli-based international leader in cyber espionage and developer NSO and one of its co-founders, Shalev Hulio from its creation in 2010 to the present. It includes NSO's acquisition by US-based private equity fund Francisco Partners in 2014. NSO's re-acquisition in 2019 by co-founders Hulio and Omri Lavie with funding support from London-based private equity fund Novalpina Capital. During this time, Pegasus had helped capture Mexican drug baron El Chapo, prevented terrorist attacks and broken up pedophilia, sex, and drug-trafficking rings. But Pegasus also contributed to the murder of Washington Post reporter Jamal Khashoggi as well as other illegal incidents against dissidents, journalist, and governments. As the case suggests, controlling access to such powerful technology that involves accountability, responsibility, and enforceability within a firm and within nations appears illusive.},
  langid = {english}
}

@article{kilgarriffIntroductionSpecialIssue2003,
  title = {Introduction to the {{Special Issue}} on the {{Web}} as {{Corpus}}},
  author = {Kilgarriff, Adam and Grefenstette, Gregory},
  date = {2003-09-01},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {29},
  number = {3},
  pages = {333--347},
  issn = {0891-2017},
  doi = {10.1162/089120103322711569},
  url = {https://doi.org/10.1162/089120103322711569},
  urldate = {2025-03-27},
  abstract = {The Web, teeming as it is with language data, of all manner of varieties and languages, in vast quantity and freely available, is a fabulous linguists' playground. This special issue of Computational Linguistics explores ways in which this dream is being explored.}
}

@software{kivyKivyKivy2025,
  title = {Kivy/Kivy},
  author = {{Kivy}},
  date = {2025-03-29T00:27:04Z},
  origdate = {2010-11-03T20:27:32Z},
  url = {https://github.com/kivy/kivy},
  urldate = {2025-03-29},
  abstract = {Open source UI framework written in Python, running on Windows, Linux, macOS, Android and iOS},
  organization = {Kivy}
}

@online{kleinmanApplePullsData2025,
  title = {Apple Pulls Data Protection Tool after {{UK}} Government Security Row},
  author = {Kleinman, Zoe},
  date = {2025-02-22},
  url = {https://www.bbc.com/news/articles/cgj54eq4vejo},
  urldate = {2025-02-25},
  abstract = {Customers' photos and documents stored online will no longer be protected by end-to-end encryption.},
  langid = {british}
}

@online{kleinmanUKGovernmentDemands2025,
  title = {{{UK}} Government Demands Access to {{Apple}} Users' Encrypted Data},
  author = {Kleinman, Zoe},
  date = {2025-02-07},
  url = {https://www.bbc.com/news/articles/c20g288yldko},
  urldate = {2025-02-25},
  abstract = {The Home Office served the notice to the tech giant under the Investigatory Powers Act.},
  langid = {british}
}

@inproceedings{knochelTextSteganographyMethods2024,
  title = {Text {{Steganography Methods}} and Their {{Influence}} in {{Malware}}: {{A Comprehensive Overview}} and {{Evaluation}}},
  shorttitle = {Text {{Steganography Methods}} and Their {{Influence}} in {{Malware}}},
  booktitle = {Proceedings of the 2024 {{ACM Workshop}} on {{Information Hiding}} and {{Multimedia Security}}},
  author = {Knöchel, Mandy and Karius, Sebastian},
  date = {2024-06-24},
  series = {{{IH}}\&amp;{{MMSec}} '24},
  pages = {113--124},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3658664.3659637},
  url = {https://dl.acm.org/doi/10.1145/3658664.3659637},
  urldate = {2025-03-12},
  abstract = {Steganography describes techniques and algorithms for hiding secret information in a cover medium such as images, audio or text files. Malware that makes use of steganographic techniques, known as stegomalware, is becoming increasingly common. This paper provides a comprehensive analysis of various text steganography methods and their application in the context of stegomalware. We give an extensive overview of occurrences of text stegomalware in the real world and the steganographic methods used in these attacks. The cover text includes any files or data containing natural language text or machine-readable digital texts and source code such as HTML, CSS, JavaScript, etc. A categorical overview of known text steganography methods is presented, whereas text steganography techniques are classified into the categories insertion, substitution, permutation and generation. For each category, selected representatives have been practically implemented and tested with different cover text files and messages of varying lengths. The authors also look at real-world applications and instances of stegomalware that utilize these methods. The paper reveals that while there is a vast array of text steganography methods, only a few are used in practice. To assess the strengths and weaknesses of each method, the evaluation is based on the metrics capacity, imperceptibility and robustness, which are commonly used to evaluate steganographic methods, and additionally complexity. The evaluation results show the performance of each method based on the defined metrics. We further discuss possible countermeasures and their effect on each steganography method. The analysis also shows that with the rise of machine learning and large language models, text steganography methods might become more common in the future.},
  isbn = {979-8-4007-0637-0}
}

@article{kolataVeiledMessagesTerror2001,
  entrysubtype = {newspaper},
  title = {Veiled {{Messages}} of {{Terror May Lurk}} in {{Cyberspace}}},
  author = {Kolata, Gina},
  date = {2001-10-30},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2001/10/30/science/veiled-messages-of-terror-may-lurk-in-cyberspace.html},
  urldate = {2025-03-11},
  abstract = {Probe into terrorist attacks on United States is drawing new attention to steganography, stealthy way of sending messages through Internet by hiding them in digital photographs or music files; method allegedly was used by recently seized terrorists who were planning to blow up United States's Paris embassy; takes advantage of fact that digital files can be slightly altered and still look or sound same; computer programs that look for statistical deviations are reportedly detecting widespread use of steganography on Internet; diagram; photos (M)},
  journalsubtitle = {Science},
  langid = {american}
}

@article{kollnigAreIPhonesReally2022,
  title = {Are {{iPhones Really Better}} for {{Privacy}}? {{Comparative Study}} of {{iOS}} and {{Android Apps}}},
  shorttitle = {Are {{iPhones Really Better}} for {{Privacy}}?},
  author = {Kollnig, Konrad and Shuba, Anastasia and Binns, Reuben and Kleek, Max Van and Shadbolt, Nigel},
  date = {2022-04-01},
  journaltitle = {Proceedings on Privacy Enhancing Technologies},
  volume = {2022},
  number = {2},
  eprint = {2109.13722},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {6--24},
  issn = {2299-0984},
  doi = {10.2478/popets-2022-0033},
  url = {http://arxiv.org/abs/2109.13722},
  urldate = {2024-12-13},
  abstract = {While many studies have looked at privacy properties of the Android and Google Play app ecosystem, comparatively much less is known about iOS and the Apple App Store, the most widely used ecosystem in the US. At the same time, there is increasing competition around privacy between these smartphone operating system providers. In this paper, we present a study of 24k Android and iOS apps from 2020 along several dimensions relating to user privacy. We find that third-party tracking and the sharing of unique user identifiers was widespread in apps from both ecosystems, even in apps aimed at children. In the children's category, iOS apps tended to use fewer advertising-related tracking than their Android counterparts, but could more often access children's location. Across all studied apps, our study highlights widespread potential violations of US, EU and UK privacy law, including 1) the use of third-party tracking without user consent, 2) the lack of parental consent before sharing personally identifiable information (PII) with third-parties in children's apps, 3) the non-data-minimising configuration of tracking libraries, 4) the sending of personal data to countries without an adequate level of data protection, and 5) the continued absence of transparency around tracking, partly due to design decisions by Apple and Google. Overall, we find that neither platform is clearly better than the other for privacy across the dimensions we studied.}
}

@software{kotlinKotlinKotlinxserialization2025,
  title = {Kotlin/Kotlinx.Serialization},
  author = {{Kotlin}},
  date = {2025-03-28T21:35:41Z},
  origdate = {2017-07-20T11:25:23Z},
  url = {https://github.com/Kotlin/kotlinx.serialization},
  urldate = {2025-03-29},
  abstract = {Kotlin multiplatform / multi-format serialization},
  organization = {Kotlin}
}

@online{kotlinKotlinProgrammingLanguage,
  title = {Kotlin {{Programming Language}}},
  author = {{Kotlin}},
  url = {https://kotlinlang.org/},
  urldate = {2025-03-29},
  abstract = {Kotlin is a concise and multiplatform programming language by JetBrains. Enjoy coding and build server-side, mobile, web, and desktop applications efficiently.},
  langid = {english},
  organization = {Kotlin}
}

@inproceedings{leeGitHubRecentBugs2024,
  title = {The {{GitHub Recent Bugs Dataset}} for {{Evaluating LLM-Based Debugging Applications}}},
  booktitle = {2024 {{IEEE Conference}} on {{Software Testing}}, {{Verification}} and {{Validation}} ({{ICST}})},
  author = {Lee, Jae Yong and Kang, Sungmin and Yoon, Juyeon and Yoo, Shin},
  date = {2024-05},
  pages = {442--444},
  issn = {2159-4848},
  doi = {10.1109/ICST60714.2024.00049},
  url = {https://ieeexplore.ieee.org/abstract/document/10638568},
  urldate = {2025-03-24},
  abstract = {While Large Language Models (LLMs) have demon-strated strong natural language and code processing capabilities, concern has been raised as to whether existing bug benchmarks are included in their training data. We examine the training data of the open-source LLM StarCoder, and find it likely that data from the widely used Defects4J benchmark was included, raising the possibility of its inclusion in the training data of the GPT model as well. This makes it difficult to tell how well LLM-based results on Defects4J would generalize, as for any results it would be unclear whether a technique's performance is due to LLM generalization or memorization. To remedy this issue and facilitate continued research on LLM-based SE, we present the GitHub Recent Bugs (GHRB) framework, which continuously gathers real-world Java bugs for use in evaluation of LLM-based techniques. To date, we have gathered 89 bugs reported after the GPT-3.5 training data cutoff point of September 2021.},
  eventtitle = {2024 {{IEEE Conference}} on {{Software Testing}}, {{Verification}} and {{Validation}} ({{ICST}})}
}

@online{leeUnifiedDebuggingApproach2024,
  title = {A {{Unified Debugging Approach}} via {{LLM-Based Multi-Agent Synergy}}},
  author = {Lee, Cheryl and Xia, Chunqiu Steven and Yang, Longji and Huang, Jen-tse and Zhu, Zhouruixin and Zhang, Lingming and Lyu, Michael R.},
  date = {2024-10-23},
  eprint = {2404.17153},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.17153},
  url = {http://arxiv.org/abs/2404.17153},
  urldate = {2025-03-24},
  abstract = {Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25\$\textbackslash times\$ to 2.56\$\textbackslash times\$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on https://github.com/AcceptePapier/UniDebugger.},
  pubstate = {prepublished}
}

@article{lewisMeasuringUserExperience2021,
  title = {Measuring {{User Experience With}} 3, 5, 7, or 11 {{Points}}: {{Does It Matter}}?},
  shorttitle = {Measuring {{User Experience With}} 3, 5, 7, or 11 {{Points}}},
  author = {Lewis, James R.},
  date = {2021-09-01},
  journaltitle = {Human Factors},
  shortjournal = {Hum Factors},
  volume = {63},
  number = {6},
  pages = {999--1011},
  publisher = {SAGE Publications Inc},
  issn = {0018-7208},
  doi = {10.1177/0018720819881312},
  url = {https://doi.org/10.1177/0018720819881312},
  urldate = {2025-04-10},
  abstract = {Objective To assess versions of the shorter form variant of Usability Metric for User Experience (UMUX-LITE) questionnaire differing in the number of response options for the items (3, 5, 7, and 11). Background The UMUX-LITE is an efficient (two-item) standardized questionnaire that measures perceived usability. A growing body of evidence shows it closely corresponds to one of the most widely used standardized usability questionnaires, the System Usability Scale (SUS), with regard to both correlation and magnitude of concurrently collected means. Although the “standard” version of the UMUX-LITE uses items with seven response options, there is some variance in practice. Method Members of a corporate user experience panel (n = 242) completed surveys rating a recent Web site experience with the SUS and UMUX-LITE, also providing ratings of overall experience and likelihood-to-recommend. Results Scale reliabilities were acceptable (coefficient α {$>$}.70) with the exception of UMUX-LITE with three response options. All UMUX-LITE correlations with SUS, overall experience, and likelihood-to-recommend were highly significant. For likelihood-to-recommend, there was a significant difference in the magnitude of correlations, with 11 response options higher than three. Although some statistically significant differences were observed in correspondence between SUS and UMUX-LITE scores, these did not seem to translate to practically significant differences. Conclusion The number of UMUX-LITE response options does not matter much, especially in practice. Because the version with three response options showed some weakness with regard to reliability and correlation with likelihood-to-recommend, practitioners should avoid it. Application Unless there is a strong reason to do otherwise, use the “standard” version with seven response options.},
  langid = {english}
}

@online{liangUserSelfReportedLikert2020,
  title = {Beyond {{User Self-Reported Likert Scale Ratings}}: {{A Comparison Model}} for {{Automatic Dialog Evaluation}}},
  shorttitle = {Beyond {{User Self-Reported Likert Scale Ratings}}},
  author = {Liang, Weixin and Zou, James and Yu, Zhou},
  date = {2020-06-12},
  eprint = {2005.10716},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.10716},
  url = {http://arxiv.org/abs/2005.10716},
  urldate = {2025-04-10},
  abstract = {Open Domain dialog system evaluation is one of the most important challenges in dialog research. Existing automatic evaluation metrics, such as BLEU are mostly reference-based. They calculate the difference between the generated response and a limited number of available references. Likert-score based self-reported user rating is widely adopted by social conversational systems, such as Amazon Alexa Prize chatbots. However, self-reported user rating suffers from bias and variance among different users. To alleviate this problem, we formulate dialog evaluation as a comparison task. We also propose an automatic evaluation model CMADE (Comparison Model for Automatic Dialog Evaluation) that automatically cleans self-reported user ratings as it trains on them. Specifically, we first use a self-supervised method to learn better dialog feature representation, and then use KNN and Shapley to remove confusing samples. Our experiments show that CMADE achieves 89.2\% accuracy in the dialog comparison task.},
  pubstate = {prepublished}
}

@inproceedings{liesenfeldOpeningChatGPTTracking2023,
  title = {Opening up {{ChatGPT}}: {{Tracking}} Openness, Transparency, and Accountability in Instruction-Tuned Text Generators},
  shorttitle = {Opening up {{ChatGPT}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Conversational User Interfaces}}},
  author = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
  date = {2023-07-19},
  series = {{{CUI}} '23},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3571884.3604316},
  url = {https://dl.acm.org/doi/10.1145/3571884.3604316},
  urldate = {2025-03-28},
  abstract = {Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.},
  isbn = {979-8-4007-0014-9}
}

@inproceedings{liImperceptibleTextSteganography2024,
  title = {Imperceptible {{Text Steganography}} Based on {{Group Chat}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})},
  author = {Li, Fanxiao and Wei, Ping and Fu, Tingchao and Lin, Yu and Zhou, Wei},
  date = {2024-07},
  pages = {1--6},
  issn = {1945-788X},
  doi = {10.1109/ICME57554.2024.10687958},
  url = {https://ieeexplore.ieee.org/abstract/document/10687958},
  urldate = {2024-12-07},
  abstract = {Text steganography is a technique for hiding secret messages within texts. Previous approaches neglect the contextual relevance of generated stego texts (texts containing secrets) and consistently transmitted secret messages unidirectionally. This behavior is considered anomalous and thus arouses the suspicion of potential attackers. In this paper, we first propose a text steganography framework grounded in the group chat scenario named GCStego, aimed at enhancing the behavior imperceptibility. Additionally, we employ a large language model (LLM) to generate stego texts according to the chatting history and thus boosts the contextual relevance. The proposed scheme is well-suited for secret transmission in group chatting, where multiple agents can pass secret messages through stego texts like regular conversations. Furthermore, we propose token index-based encoding, position filtering and sentence split strategies to deliver the performance. Experimental results demonstrate the superiority of our proposed framework in terms of text semantic controllability, behavioral imperceptibility, and anti-steganalysis ability.},
  eventtitle = {2024 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})}
}

@article{likertTechniqueMeasurementAttitudes1932,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, Rensis},
  date = {1932},
  journaltitle = {Archives of Psychology},
  abstract = {The project conceived in 1929 by Gardner Murphy and the writer aimed first to present a wide array of problems having to do with five major "attitude areas"—international relations, race relations, economic conflict, political conflict, and religion. The kind of questionnaire material falls into four classes: yes-no, multiple choice, propositions to be responded to by degrees of approval, and a series of brief newspaper narratives to be approved or disapproved in various degrees. The monograph aims to describe a technique rather than to give results. The appendix, covering ten pages, shows the method of constructing an attitude scale. A bibliography is also given. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@online{liTransformerLiteHighefficiencyDeployment2024,
  title = {Transformer-{{Lite}}: {{High-efficiency Deployment}} of {{Large Language Models}} on {{Mobile Phone GPUs}}},
  shorttitle = {Transformer-{{Lite}}},
  author = {Li, Luchang and Qian, Sheng and Lu, Jie and Yuan, Lunxi and Wang, Rui and Xie, Qin},
  date = {2024-07-05},
  eprint = {2403.20041},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.20041},
  url = {http://arxiv.org/abs/2403.20041},
  urldate = {2025-03-12},
  abstract = {The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text summarization, translation, and multi-modality on mobile phones. However, the current methods for on-device LLM deployment maintain slow inference speed, which causes poor user experience. To facilitate high-efficiency LLM deployment on device GPUs, we propose four optimization techniques: (a) a symbolic expression-based approach to support dynamic shape model inference; (b) operator optimizations and execution priority setting to enhance inference speed and reduce phone lagging; (c) an FP4 quantization method termed M0E4 to reduce dequantization overhead; (d) a sub-tensor-based technique to eliminate the need for copying KV cache after LLM inference. Furthermore, we implement these methods in our mobile inference engine, Transformer-Lite, which is compatible with both Qualcomm and MTK processors. We evaluated Transformer-Lite's performance using LLMs with varied architectures and parameters ranging from 2B to 14B. Specifically, we achieved prefill and decoding speeds of 121 token/s and 14 token/s for ChatGLM2 6B, and 330 token/s and 30 token/s for smaller Gemma 2B, respectively. Compared with CPU-based FastLLM and GPU-based MLC-LLM, our engine attains over 10x speedup for the prefill speed and 2\textasciitilde 3x speedup for the decoding speed.},
  pubstate = {prepublished},
  version = {3}
}

@online{lmstudiocommunityLmstudiocommunityDeepSeekR1DistillQwen15BGGUFHugging2025,
  title = {Lmstudio-Community/{{DeepSeek-R1-Distill-Qwen-1}}.{{5B-GGUF}} · {{Hugging Face}}},
  author = {{LM Studio Community}},
  date = {2025-01-20},
  url = {https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-1.5B-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{lmstudiocommunityLmstudiocommunityGemma31bItGGUF2025,
  title = {Lmstudio-Community/Gemma-3-1b-It-{{GGUF}} · {{Hugging Face}}},
  author = {{LM Studio Community}},
  date = {2025-03-12},
  url = {https://huggingface.co/lmstudio-community/gemma-3-1b-it-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@online{lovonEvaluatingLLMAbilities2025,
  title = {Evaluating {{LLM Abilities}} to {{Understand Tabular Electronic Health Records}}: {{A Comprehensive Study}} of {{Patient Data Extraction}} and {{Retrieval}}},
  shorttitle = {Evaluating {{LLM Abilities}} to {{Understand Tabular Electronic Health Records}}},
  author = {Lovon, Jesus and Mouysset, Martin and Oleiwan, Jo and Moreno, Jose G. and Damase-Michel, Christine and Tamine, Lynda},
  date = {2025-01-16},
  eprint = {2501.09384},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.09384},
  url = {http://arxiv.org/abs/2501.09384},
  urldate = {2025-03-27},
  abstract = {Electronic Health Record (EHR) tables pose unique challenges among which is the presence of hidden contextual dependencies between medical features with a high level of data dimensionality and sparsity. This study presents the first investigation into the abilities of LLMs to comprehend EHRs for patient data extraction and retrieval. We conduct extensive experiments using the MIMICSQL dataset to explore the impact of the prompt structure, instruction, context, and demonstration, of two backbone LLMs, Llama2 and Meditron, based on task performance. Through quantitative and qualitative analyses, our findings show that optimal feature selection and serialization methods can enhance task performance by up to 26.79\% compared to naive approaches. Similarly, in-context learning setups with relevant example selection improve data extraction performance by 5.95\%. Based on our study findings, we propose guidelines that we believe would help the design of LLM-based models to support health search.},
  pubstate = {prepublished}
}

@inproceedings{lowDocumentMarkingIdentification1995,
  title = {Document Marking and Identification Using Both Line and Word Shifting},
  booktitle = {Proceedings of {{INFOCOM}}'95},
  author = {Low, S.H. and Maxemchuk, N.F. and Brassil, J.T. and O'Gorman, L.},
  date = {1995-04},
  volume = {2},
  pages = {853-860 vol.2},
  issn = {0743-166X},
  doi = {10.1109/INFCOM.1995.515956},
  url = {https://ieeexplore.ieee.org/abstract/document/515956},
  urldate = {2025-03-23},
  abstract = {Continues a study of document marking to deter illicit dissemination. An experiment performed reveals that the distortion on the photocopy of a document is very different in the vertical and horizontal directions. This leads to the strategy that marks a text line both vertically using line shifting and horizontally using word shifting. A line that is marked is always accompanied by two unmarked control lines one above and one below. They are used to measure distortions in the vertical and horizontal directions in order to decide whether line or word shift should be detected. Line shifts are detected using a centroid method that bases its decision on the relative distance of line centroids. Word shifts are detected using a correlation method that treats a profile as a waveform and decides whether it originated from a waveform whose middle block has been shifted left or right. The maximum likelihood detectors for both methods are given.},
  eventtitle = {Proceedings of {{INFOCOM}}'95}
}

@inproceedings{luoTextSteganographyHigh2017,
  title = {Text {{Steganography}} with {{High Embedding Rate}}: {{Using Recurrent Neural Networks}} to {{Generate Chinese Classic Poetry}}},
  shorttitle = {Text {{Steganography}} with {{High Embedding Rate}}},
  booktitle = {Proceedings of the 5th {{ACM Workshop}} on {{Information Hiding}} and {{Multimedia Security}}},
  author = {Luo, Yubo and Huang, Yongfeng},
  date = {2017-06-20},
  series = {{{IH}}\&amp;{{MMSec}} '17},
  pages = {99--104},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3082031.3083240},
  url = {https://dl.acm.org/doi/10.1145/3082031.3083240},
  urldate = {2025-03-12},
  abstract = {We propose a novel text steganography method using RNN Encoder-Decoder structure to generate quatrains, one genre of Chinese poetry. Compared to other text-generation based steganography methods which have either very low embedding rate or flaws in the naturalness of generated texts, our method has higher embedding rate and better text quality. In this paper, we use the LSTM Encoder-Decoder model to generate the first line of a quatrain with a keyword and then generate the following lines one by one. RNN has proved effective in generating poetry, but when applied to steganograpy, poetry quality decreases sharply, because of the redundancy we create to hide information. To overcome this problem, we propose a template-constrained generation method and develop a word-choosing approach using inner-word mutual information. Through a series of experiments, it is proven that our approach outperforms other poetry steganography methods in both embedding rate and poetry quality.},
  isbn = {978-1-4503-5061-7}
}

@online{luSmallLanguageModels2024,
  title = {Small {{Language Models}}: {{Survey}}, {{Measurements}}, and {{Insights}}},
  shorttitle = {Small {{Language Models}}},
  author = {Lu, Zhenyan and Li, Xiang and Cai, Dongqi and Yi, Rongjie and Liu, Fangming and Zhang, Xiwen and Lane, Nicholas D. and Xu, Mengwei},
  date = {2024-09-24},
  eprint = {2409.15790},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.15790},
  url = {http://arxiv.org/abs/2409.15790},
  urldate = {2025-03-11},
  abstract = {Small language models (SLMs), despite their widespread adoption in modern smart devices, have received significantly less academic attention compared to their large language model (LLM) counterparts, which are predominantly deployed in data centers and cloud environments. While researchers continue to improve the capabilities of LLMs in the pursuit of artificial general intelligence, SLM research aims to make machine intelligence more accessible, affordable, and efficient for everyday tasks. Focusing on transformer-based, decoder-only language models with 100M-5B parameters, we survey 59 state-of-the-art open-source SLMs, analyzing their technical innovations across three axes: architectures, training datasets, and training algorithms. In addition, we evaluate their capabilities in various domains, including commonsense reasoning, in-context learning, mathematics, and coding. To gain further insight into their on-device runtime costs, we benchmark their inference latency and memory footprints. Through in-depth analysis of our benchmarking data, we offer valuable insights to advance research in this field.},
  pubstate = {prepublished},
  version = {1}
}

@article{macaskillGCHQTapsFibreoptic2013,
  entrysubtype = {newspaper},
  title = {{{GCHQ}} Taps Fibre-Optic Cables for Secret Access to World's Communications},
  author = {MacAskill, Ewen and Borger, Julian and Hopkins, Nick and Davies, Nick and Ball, James},
  date = {2013-06-21T16:23:17},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa},
  urldate = {2025-03-26},
  abstract = {Exclusive: British spy agency collects and stores vast quantities of global email messages, Facebook posts, internet histories and calls, and shares them with NSA, latest documents from Edward Snowden reveal},
  journalsubtitle = {UK news},
  langid = {british}
}

@article{mackeyFrenchScientistDenied2025,
  entrysubtype = {newspaper},
  title = {French Scientist Denied {{US}} Entry after Phone Messages Critical of {{Trump}} Found},
  author = {Mackey, Robert},
  date = {2025-03-19T21:41:55},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/us-news/2025/mar/19/trump-musk-french-scientist-detained},
  urldate = {2025-04-10},
  abstract = {France’s research minister said the scientist was traveling to Houston for a conference when his phone was searched},
  journalsubtitle = {US news},
  langid = {british}
}

@article{mahdavi-hezavehSoftwareDevelopmentFeature2021,
  title = {Software Development with Feature Toggles: Practices Used by Practitioners},
  shorttitle = {Software Development with Feature Toggles},
  author = {Mahdavi-Hezaveh, Rezvan and Dremann, Jacob and Williams, Laurie},
  date = {2021-01-08},
  journaltitle = {Empirical Software Engineering},
  shortjournal = {Empir Software Eng},
  volume = {26},
  number = {1},
  pages = {1},
  issn = {1573-7616},
  doi = {10.1007/s10664-020-09901-z},
  url = {https://doi.org/10.1007/s10664-020-09901-z},
  urldate = {2025-04-10},
  abstract = {Using feature toggles is a technique that allows developers to either turn a feature on or off with a variable in a conditional statement. Feature toggles are increasingly used by software companies to facilitate continuous integration and continuous delivery. However, using feature toggles inappropriately may cause problems which can have a severe impact, such as code complexity, dead code, and system failure. For example, the erroneous repurposing of an old feature toggle caused Knight Capital Group, an American global financial services firm, to go bankrupt due to the implications of the resultant incorrect system behavior.},
  langid = {english}
}

@article{maiKnowYouveSeen2015,
  title = {“{{I}} Know You’ve Seen It!” {{Individual}} and Social Factors for Users’ Chatting Behavior on {{Facebook}}},
  author = {Mai, Lisa M. and Freudenthaler, Rainer and Schneider, Frank M. and Vorderer, Peter},
  date = {2015-08-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {49},
  pages = {296--302},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2015.01.074},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563215001028},
  urldate = {2025-04-10},
  abstract = {An online survey (N=207) investigated how the seen-function influences users’ answering behavior in Facebook chatting. The seen-function is a chat-feature that provides more transparency over the course of a chat conversation and thus may also intensify the mutual awareness of chat partners. Based on the need to belong and fear of ostracism as motivators for user behavior it was hypothesized that users with a higher value of these personality traits would have a higher expectation for others to answer immediately and a higher perceived obligation to answer immediately. Indeed, fear of ostracism and need to belong were positively related to perceived obligations to answer and expectations toward chat partners. However, the perceived obligation to answer immediately was higher than the average expectation toward others to do so. Looking for different clusters of users, we found three groups of users in the data set that differ in terms of their expectations and perceived obligations.}
}

@article{malikHighCapacityText2017,
  title = {A High Capacity Text Steganography Scheme Based on Huffman Compression and Color Coding},
  author = {Malik, Aruna and Sikka, Geeta and Verma, Harsh K.},
  date = {2017-07-04},
  journaltitle = {Journal of Information and Optimization Sciences},
  volume = {38},
  number = {5},
  pages = {647--664},
  publisher = {Taylor \& Francis},
  issn = {0252-2667},
  doi = {10.1080/02522667.2016.1197572},
  url = {https://doi.org/10.1080/02522667.2016.1197572},
  urldate = {2025-03-12},
  abstract = {In this paper, we propose a high capacity text steganography scheme by using a combination of Move to Front (MTF) encoding, huffman compression, and color coding. The forward email platform is used to hide the secret data. In this scheme, we first encode the secret data using MTF encoding to increase the similarity among the element of the secret data and then apply huffman compression technique on the resultant secret data to obtain huffman codes for condensing the size of the secret data. Part of the compressed secret data is embedded into the email addresses, and residual part of the secret data stream is hide in the text message using a user defined color coding table. To make optimal utilization of number of characters in email ids, the characters added to the email id to indicate the secret data bits are taken from the processed secret data. The new characters are appended just before the ‘@’ symbol of email ids. Hence, the hiding capacity is further increased. Experimental results show that our method performs much better than the existing methods in terms of hiding capacity.}
}

@online{mallisTechniquesKVCache2024,
  title = {Techniques for {{KV Cache Optimization}} in {{Large Language Models}}},
  author = {Mallis, Omri},
  date = {2024-02-25},
  url = {https://www.omrimallis.com/posts/techniques-for-kv-cache-optimization/},
  urldate = {2025-01-08},
  abstract = {This post explores techniques for optimizing the Key-Value (KV) cache in large language models, from Grouped-query attention to PagedAttention and distributed cache management.},
  langid = {english}
}

@online{mallisUnderstandingHowLLM2023,
  title = {Understanding How {{LLM}} Inference Works with Llama.Cpp},
  author = {Mallis, Omri},
  date = {2023-11-11},
  url = {https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/},
  urldate = {2024-12-03},
  abstract = {In this post we will understand how large language models (LLMs) answer user prompts by exploring the source code of llama.cpp, a C++ implementation of LLaMA, covering subjects such as tokenization, embedding, self-attention and sampling.},
  langid = {english}
}

@online{martinezCombiningGenerativeArtificial2023,
  title = {Combining {{Generative Artificial Intelligence}} ({{AI}}) and the {{Internet}}: {{Heading}} towards {{Evolution}} or {{Degradation}}?},
  shorttitle = {Combining {{Generative Artificial Intelligence}} ({{AI}}) and the {{Internet}}},
  author = {Martínez, Gonzalo and Watson, Lauren and Reviriego, Pedro and Hernández, José Alberto and Juarez, Marc and Sarkar, Rik},
  date = {2023-02-17},
  eprint = {2303.01255},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.01255},
  url = {http://arxiv.org/abs/2303.01255},
  urldate = {2025-03-19},
  abstract = {In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve with the new data sets or degenerate? Will evolution introduce biases in subsequent generations of generative AI tools? In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool. These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate. Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet.},
  pubstate = {prepublished}
}

@online{martinezUnderstandingInterplayGenerative2023,
  title = {Towards {{Understanding}} the {{Interplay}} of {{Generative Artificial Intelligence}} and the {{Internet}}},
  author = {Martínez, Gonzalo and Watson, Lauren and Reviriego, Pedro and Hernández, José Alberto and Juarez, Marc and Sarkar, Rik},
  date = {2023-06-08},
  eprint = {2306.06130},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.06130},
  url = {http://arxiv.org/abs/2306.06130},
  urldate = {2025-03-19},
  abstract = {The rapid adoption of generative Artificial Intelligence (AI) tools that can generate realistic images or text, such as DALL-E, MidJourney, or ChatGPT, have put the societal impacts of these technologies at the center of public debate. These tools are possible due to the massive amount of data (text and images) that is publicly available through the Internet. At the same time, these generative AI tools become content creators that are already contributing to the data that is available to train future models. Therefore, future versions of generative AI tools will be trained with a mix of human-created and AI-generated content, causing a potential feedback loop between generative AI and public data repositories. This interaction raises many questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve and improve with the new data sets or on the contrary will they degrade? Will evolution introduce biases or reduce diversity in subsequent generations of generative AI tools? What are the societal implications of the possible degradation of these models? Can we mitigate the effects of this feedback loop? In this document, we explore the effect of this interaction and report some initial results using simple diffusion models trained with various image datasets. Our results show that the quality and diversity of the generated images can degrade over time suggesting that incorporating AI-created data can have undesired effects on future versions of generative models.},
  pubstate = {prepublished}
}

@online{mathewHiddenPlainText2024,
  title = {Hidden in {{Plain Text}}: {{Emergence}} \& {{Mitigation}} of {{Steganographic Collusion}} in {{LLMs}}},
  shorttitle = {Hidden in {{Plain Text}}},
  author = {Mathew, Yohan and Matthews, Ollie and McCarthy, Robert and Velja, Joan and family=Witt, given=Christian Schroeder, prefix=de, useprefix=false and Cope, Dylan and Schoots, Nandi},
  date = {2024-10-02},
  eprint = {2410.03768},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.03768},
  url = {http://arxiv.org/abs/2410.03768},
  urldate = {2025-03-12},
  abstract = {The rapid proliferation of frontier model agents promises significant societal advances but also raises concerns about systemic risks arising from unsafe interactions. Collusion to the disadvantage of others has been identified as a central form of undesirable agent cooperation. The use of information hiding (steganography) in agent communications could render collusion practically undetectable. This underscores the need for evaluation frameworks to monitor and mitigate steganographic collusion capabilities. We address a crucial gap in the literature by demonstrating, for the first time, that robust steganographic collusion in LLMs can arise indirectly from optimization pressure. To investigate this problem we design two approaches -- a gradient-based reinforcement learning (GBRL) method and an in-context reinforcement learning (ICRL) method -- for reliably eliciting sophisticated LLM-generated linguistic text steganography. Importantly, we find that emergent steganographic collusion can be robust to both passive steganalytic oversight of model outputs and active mitigation through communication paraphrasing. We contribute a novel model evaluation framework and discuss limitations and future work. Our findings imply that effective risk mitigation from steganographic collusion post-deployment requires innovation in passive and active oversight techniques.},
  pubstate = {prepublished},
  version = {1}
}

@online{maurerLikertplotcomPlotLikert2013,
  title = {Likertplot.Com - {{Plot Likert Scales}}},
  author = {Maurer, Max-Emanuel},
  date = {2013},
  url = {https://likertplot.com/},
  urldate = {2025-05-07}
}

@article{mccallumMetaFacebookOwner2023,
  entrysubtype = {newspaper},
  title = {Meta: {{Facebook}} Owner Fined €1.2bn for Mishandling Data},
  shorttitle = {Meta},
  author = {McCallum, Shiona},
  date = {2023-05-22},
  url = {https://www.bbc.com/news/technology-65669839},
  urldate = {2025-03-27},
  abstract = {The dispute is over Facebook's transfer of European data to US servers.},
  langid = {british}
}

@article{mccullaghBinLadenSteganography2001,
  entrysubtype = {magazine},
  title = {Bin {{Laden}}: {{Steganography Master}}?},
  shorttitle = {Bin {{Laden}}},
  author = {McCullagh, Declan},
  date = {2001-02-07},
  journaltitle = {Wired},
  issn = {1059-1028},
  url = {https://www.wired.com/2001/02/bin-laden-steganography-master/},
  urldate = {2025-01-09},
  abstract = {Are the FBI and CIA using reports that Osama bin Laden and others are using messaging scrambling techniques to justify further restrictions of encryption and steganography programs? Declan McCullagh reports from Washington.},
  langid = {american}
}

@article{megiasDataHidingIts2021,
  title = {Data {{Hiding}} and {{Its Applications}}: {{Digital Watermarking}} and {{Steganography}}},
  shorttitle = {Data {{Hiding}} and {{Its Applications}}},
  author = {Megías, David and Mazurczyk, Wojciech and Kuribayashi, Minoru},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {22},
  pages = {10928},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app112210928},
  url = {https://www.mdpi.com/2076-3417/11/22/10928},
  urldate = {2025-03-27},
  abstract = {Data hiding techniques [...]},
  issue = {22},
  langid = {english}
}

@software{metaMetallamaLlamamodels2025,
  title = {Meta-Llama/Llama-Models},
  author = {{Meta}},
  date = {2025-03-14T12:52:56Z},
  origdate = {2024-06-27T22:14:09Z},
  url = {https://github.com/meta-llama/llama-models},
  urldate = {2025-03-14},
  abstract = {Utilities intended for use with Llama models.},
  organization = {Meta Llama}
}

@article{michaelsonJournalistsMore11002025,
  entrysubtype = {newspaper},
  title = {Journalists among More than 1,100 Arrested in {{Turkey}} Crackdown},
  author = {Michaelson, Ruth},
  date = {2025-03-24T17:04:13},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2025/mar/24/journalists-among-more-than-1100-arrested-in-turkey-crackdown-istanbul},
  urldate = {2025-03-24},
  abstract = {Authorities ask X to block accounts as tens of thousands take to streets in largest anti-government protests in years},
  journalsubtitle = {World news},
  langid = {british}
}

@article{mienyeChatGPTEducationReview2025,
  title = {{{ChatGPT}} in {{Education}}: {{A Review}} of {{Ethical Challenges}} and {{Approaches}} to {{Enhancing Transparency}} and {{Privacy}}},
  shorttitle = {{{ChatGPT}} in {{Education}}},
  author = {Mienye, Ibomoiye Domor and Swart, Theo G.},
  date = {2025-01-01},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  series = {International {{Conference}} on {{Digital Sovereignty}} ({{ICDS}})},
  volume = {254},
  pages = {181--190},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2025.02.077},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050925004272},
  urldate = {2025-03-27},
  abstract = {The integration of ChatGPT and large language models (LLMs) into education has created new possibilities for personalized learning, tutoring, and automation of administrative tasks. However, these advancements also present ethical challenges. This paper critically examines the ethical implications of deploying ChatGPT in educational settings, with a focus on data privacy, the opaque nature of AI decision-making, and the risks of biased outputs. To address these issues, we outline actionable approaches, including Explainable AI (XAI) techniques and privacy-preserving strategies, aimed at enabling transparency and protecting student data. We also outline frameworks that support human oversight and governance to maintain trust and accountability in Al-driven educational tools.}
}

@inproceedings{millerHowWasYour2021,
  title = {"{{How Was Your Weekend}}?" {{Software Development Teams Working From Home During COVID-19}}},
  shorttitle = {"{{How Was Your Weekend}}?},
  booktitle = {2021 {{IEEE}}/{{ACM}} 43rd {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  author = {Miller, Courtney and Rodeghero, Paige and Storey, Margaret-Anne and Ford, Denae and Zimmermann, Thomas},
  date = {2021-05},
  pages = {624--636},
  issn = {1558-1225},
  doi = {10.1109/ICSE43902.2021.00064},
  url = {https://ieeexplore.ieee.org/abstract/document/9401956},
  urldate = {2025-04-10},
  abstract = {The mass shift to working at home during the COVID-19 pandemic radically changed the way many software development teams collaborate and communicate. To investigate how team culture and team productivity may also have been affected, we conducted two surveys at a large software company. The first, an exploratory survey during the early months of the pandemic with 2,265 developer responses, revealed that many developers faced challenges reaching milestones and that their team productivity had changed. We also found through qualitative analysis that important team culture factors such as communication and social connection had been affected. For example, the simple phrase "How was your weekend?" had become a subtle way to show peer support. In our second survey, we conducted a quantitative analysis of the team cultural factors that emerged from our first survey to understand the prevalence of the reported changes. From 608 developer responses, we found that 74\% of these respondents missed social interactions with colleagues and 51\% reported a decrease in their communication ease with colleagues. We used data from the second survey to build a regression model to identify important team culture factors for modeling team productivity. We found that the ability to brainstorm with colleagues, difficulty communicating with colleagues, and satisfaction with interactions from social activities are important factors that are associated with how developers report their software development team's productivity. Our findings inform how managers and leaders in large software companies can support sustained team productivity during times of crisis and beyond.},
  eventtitle = {2021 {{IEEE}}/{{ACM}} 43rd {{International Conference}} on {{Software Engineering}} ({{ICSE}})}
}

@inproceedings{mitchellModelCardsModel2019,
  title = {Model {{Cards}} for {{Model Reporting}}},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  date = {2019-01-29},
  eprint = {1810.03993},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {220--229},
  doi = {10.1145/3287560.3287596},
  url = {http://arxiv.org/abs/1810.03993},
  urldate = {2025-03-30},
  abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related AI technology, increasing transparency into how well AI technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.}
}

@inproceedings{mollerMetricsSuccessEvaluating2025,
  title = {Metrics of {{Success}}: {{Evaluating User Satisfaction}} in {{AI Chatbots}}},
  shorttitle = {Metrics of {{Success}}},
  booktitle = {Proceedings of the 2024 8th {{International Conference}} on {{Advances}} in {{Artificial Intelligence}}},
  author = {Møller, Cecilie Grace and Ang, Ke En and family=Lourdes Bongiovanni, given=María, prefix=de, useprefix=true and Khalid, Md Saifuddin and Wu, Jiayan},
  date = {2025-03-03},
  series = {{{ICAAI}} '24},
  pages = {168--173},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3704137.3704182},
  url = {https://dl.acm.org/doi/10.1145/3704137.3704182},
  urldate = {2025-04-05},
  abstract = {The rapid advancement of Artificial Intelligence (AI), particularly through Large Language Models (LLMs), has catalysed a technological revolution, leading to the widespread adoption of AI-driven chatbots across industries. OpenAI’s customisable generative pre-trained transformer (GPT) offerings have popularised generative AI, enabling organisations of all sizes to implement chatbots for customer support. This development presents an opportunity for businesses to offer 24/7, cost-efficient customer service that can overcome the historical limitations of chatbots that lack a "human element." However, despite the proliferation of AI chatbots, there remains a crucial need to evaluate their effectiveness in meeting user needs and preferences for human-like interaction. Current service quality assessment tools, such as SERVQUAL and E-SERVQUAL, are unable to evaluate AI-specific capabilities like language intelligence and recognition. Existing research also lacks information on factors that affect user satisfaction and the continued use of AI chatbots. Based on a mixed-methods study, this paper proposes a new instrument for measuring user satisfaction with AI chatbots, specifically for customer support roles. Using the Stanford five-step Design Thinking Process, this study devised a customer support AI chatbot evaluation instrument through a literature review, Cheatstorming, and SCAMPER techniques, followed by testing in a Danish company. The research employs Prentice and Nguyen’s three-stage scale development process to ensure content, reliability, and construct validity, addressing gaps in current scholarship and advancing understanding of AI chatbot user satisfaction.},
  isbn = {979-8-4007-1801-4}
}

@online{morgiaTGDatasetCollectingExploring2025,
  title = {{{TGDataset}}: {{Collecting}} and {{Exploring}} the {{Largest Telegram Channels Dataset}}},
  shorttitle = {{{TGDataset}}},
  author = {Morgia, Massimo La and Mei, Alessandro and Mongardini, Alberto Maria},
  date = {2025-03-03},
  eprint = {2303.05345},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.05345},
  url = {http://arxiv.org/abs/2303.05345},
  urldate = {2025-04-06},
  abstract = {Telegram is one of the most popular instant messaging apps in today's digital age. In addition to providing a private messaging service, Telegram, with its channels, represents a valid medium for rapidly broadcasting content to a large audience (COVID-19 announcements), but, unfortunately, also for disseminating radical ideologies and coordinating attacks (Capitol Hill riot). This paper presents the TGDataset, a new dataset that includes 120,979 Telegram channels and over 400 million messages, making it the largest collection of Telegram channels to the best of our knowledge. After a brief introduction to the data collection process, we analyze the languages spoken within our dataset and the topic covered by English channels. Finally, we discuss some use cases in which our dataset can be extremely useful to understand better the Telegram ecosystem, as well as to study the diffusion of questionable news. In addition to the raw dataset, we released the scripts we used to analyze the dataset and the list of channels belonging to the network of a new conspiracy theory called Sabmyk.},
  pubstate = {prepublished}
}

@software{mozillaMozillaOchoLlamafile2025,
  title = {Mozilla-{{Ocho}}/Llamafile},
  author = {{Mozilla}},
  date = {2025-03-11T19:50:12Z},
  origdate = {2023-09-10T21:12:32Z},
  url = {https://github.com/Mozilla-Ocho/llamafile},
  urldate = {2025-03-11},
  abstract = {Distribute and run LLMs with a single file.},
  organization = {Mozilla Ocho}
}

@inproceedings{mukherjeeChatGPTBasedImage2023,
  title = {{{ChatGPT Based Image Steganography}} ({{CGIS}}): {{A Novel Intelligent Information Hiding Approach}} to {{Achieve Secure Covert Communication}}},
  shorttitle = {{{ChatGPT Based Image Steganography}} ({{CGIS}})},
  booktitle = {2023 {{First International Conference}} on {{Advances}} in {{Electrical}}, {{Electronics}} and {{Computational Intelligence}} ({{ICAEECI}})},
  author = {Mukherjee, Subhadip and Mukhopadhyay, Somnath and Sarkar, Sunita},
  date = {2023-10},
  pages = {1--5},
  doi = {10.1109/ICAEECI58247.2023.10370937},
  url = {https://ieeexplore.ieee.org/abstract/document/10370937},
  urldate = {2025-03-12},
  abstract = {Covert communication refers to the practice of exchanging information or messages in a discreet or secretive manner, with the intent of keeping the communication hidden from unintended or unauthorized recipients. Steganography is a widely used, strategy for establishing covert communication, for maintaining the privacy and security of sensitive information. Steganography ensures that the message remains concealed from surveillance or eavesdropping. Artificial Intelligence (AI) plays a crucial role in enhancing security across various domains of covert communication. ChatGPT is an AI model, specifically a natural language processing (NLP) model. It belongs to the broader category of AI models which can comprehend and produce language for humans. In this paper, a new image steganographic model named CGIS is developed for covert communication using ChatGPT. Proposed steganographic method has achieved 3.0 bpp of hiding capacity. In situations where confidentiality is critical, such as in military operations, intelligence agencies, or corporate strategies, proposed method ensures that the message cannot be detected and or extracted by any surveillance or eavesdropper.},
  eventtitle = {2023 {{First International Conference}} on {{Advances}} in {{Electrical}}, {{Electronics}} and {{Computational Intelligence}} ({{ICAEECI}})}
}

@online{obrienNebraskaTeenMother2022,
  title = {Nebraska Teen and Mother Facing Charges in Abortion-Related Case That Involved Obtaining Their {{Facebook}} Messages | {{CNN Business}}},
  author = {O'Brien, Sara and Duffy, Clare},
  date = {2022-08-10T15:00:43Z},
  url = {https://www.cnn.com/2022/08/10/tech/teen-charged-abortion-facebook-messages/index.html},
  urldate = {2024-11-26},
  abstract = {A Nebraska mother and her 18-year-old daughter are facing multiple charges in a case that involved police obtaining Facebook messages between the two that authorities allege show evidence of an illegal self-managed medication abortion, as well as a plan to hide the remains.},
  langid = {english},
  organization = {CNN}
}

@online{omitaomuEmpathicConversationsMultilevel2022,
  title = {Empathic {{Conversations}}: {{A Multi-level Dataset}} of {{Contextualized Conversations}}},
  shorttitle = {Empathic {{Conversations}}},
  author = {Omitaomu, Damilola and Tafreshi, Shabnam and Liu, Tingting and Buechel, Sven and Callison-Burch, Chris and Eichstaedt, Johannes and Ungar, Lyle and Sedoc, João},
  date = {2022-05-25},
  eprint = {2205.12698},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.12698},
  url = {http://arxiv.org/abs/2205.12698},
  urldate = {2025-04-05},
  abstract = {Empathy is a cognitive and emotional reaction to an observed situation of others. Empathy has recently attracted interest because it has numerous applications in psychology and AI, but it is unclear how different forms of empathy (e.g., self-report vs counterpart other-report, concern vs. distress) interact with other affective phenomena or demographics like gender and age. To better understand this, we created the \{\textbackslash it Empathic Conversations\} dataset of annotated negative, empathy-eliciting dialogues in which pairs of participants converse about news articles. People differ in their perception of the empathy of others. These differences are associated with certain characteristics such as personality and demographics. Hence, we collected detailed characterization of the participants' traits, their self-reported empathetic response to news articles, their conversational partner other-report, and turn-by-turn third-party assessments of the level of self-disclosure, emotion, and empathy expressed. This dataset is the first to present empathy in multiple forms along with personal distress, emotion, personality characteristics, and person-level demographic information. We present baseline models for predicting some of these features from conversations.},
  pubstate = {prepublished}
}

@software{onnxruntimedevelopersONNXRuntime2018,
  title = {{{ONNX Runtime}}},
  author = {{ONNX Runtime developers}},
  date = {2018-11},
  origdate = {2018-11-10T02:22:53Z},
  url = {https://github.com/microsoft/onnxruntime},
  urldate = {2025-03-11},
  abstract = {ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator}
}

@online{onnxruntimeONNXRuntimeHome,
  title = {{{ONNX Runtime}} | {{Home}}},
  author = {{ONNX Runtime}},
  url = {https://onnxruntime.ai/},
  urldate = {2025-03-11},
  abstract = {Cross-platform accelerated machine learning. Built-in optimizations speed up training and inferencing with your existing technology stack.},
  langid = {english}
}

@software{openaiOpenaiTiktoken2025,
  title = {Openai/Tiktoken},
  author = {{OpenAI}},
  date = {2025-03-14T18:27:50Z},
  origdate = {2022-12-01T23:22:11Z},
  url = {https://github.com/openai/tiktoken},
  urldate = {2025-03-14},
  abstract = {tiktoken is a fast BPE tokeniser for use with OpenAI's models.},
  organization = {OpenAI}
}

@online{oracleJNIFunctions,
  title = {{{JNI Functions}}},
  author = {{Oracle}},
  url = {https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/functions.html#NewStringUTF},
  urldate = {2025-04-04}
}

@online{osiOpenSourceAI,
  title = {The {{Open Source AI Definition}} – 1.0},
  author = {{OSI}},
  url = {https://opensource.org/ai/open-source-ai-definition},
  urldate = {2025-03-27},
  abstract = {version 1.0 Preamble Why we need Open Source Artificial Intelligence (AI) Open Source has demonstrated that massive benefits accrue to everyone after removing the barriers to learning, using, sharing and…},
  langid = {american},
  organization = {Open Source Initiative}
}

@online{oversecOVERSECPrivacyAll2016,
  title = {{{OVERSEC}} - {{Privacy}} for All {{Android Apps}}},
  author = {{Oversec}},
  date = {2016},
  url = {https://www.oversec.io/},
  urldate = {2025-03-11}
}

@software{panchalShubham0204SmolChatAndroid2025,
  title = {Shubham0204/{{SmolChat-Android}}},
  author = {Panchal, Shubham},
  date = {2025-03-11T02:44:46Z},
  origdate = {2024-11-10T08:26:09Z},
  url = {https://github.com/shubham0204/SmolChat-Android},
  urldate = {2025-03-11},
  abstract = {Running any GGUF SLMs/LLMs locally, on-device in Android}
}

@article{panQuantumManybodyPhysics2025,
  title = {Quantum Many-Body Physics Calculations with Large Language Models},
  author = {Pan, Haining and Mudur, Nayantara and Taranto, William and Tikhanovskaya, Maria and Venugopalan, Subhashini and Bahri, Yasaman and Brenner, Michael P. and Kim, Eun-Ah},
  date = {2025-01-31},
  journaltitle = {Communications Physics},
  shortjournal = {Commun Phys},
  volume = {8},
  number = {1},
  pages = {1--8},
  publisher = {Nature Publishing Group},
  issn = {2399-3650},
  doi = {10.1038/s42005-025-01956-y},
  url = {https://www.nature.com/articles/s42005-025-01956-y},
  urldate = {2025-03-24},
  abstract = {Large language models (LLMs) have demonstrated abilities to perform complex tasks in multiple domains, including mathematical and scientific reasoning. We demonstrate that with carefully designed prompts, LLMs can accurately carry out key calculations in research papers in theoretical physics. We focus on a broadly-used approximation method in quantum physics: the Hartree-Fock method, requiring an analytic multi-step calculation deriving approximate Hamiltonian and corresponding self-consistency equations. To carry out the calculations using LLMs, we design multi-step prompt templates that break down the analytic calculation into standardized steps with placeholders for problem-specific information. We evaluate GPT-4’s performance in executing the calculation for 15 papers from the past decade, demonstrating that, with the correction of intermediate steps, it can correctly derive the final Hartree-Fock Hamiltonian in 13 cases. Aggregating across all research papers, we find an average score of 87.5 (out of 100) on the execution of individual calculation steps. We further use LLMs to mitigate the two primary bottlenecks in this evaluation process: (i) extracting information from papers to fill in templates and (ii) automatic scoring of the calculation steps, demonstrating good results in both cases.},
  langid = {english}
}

@article{pearsonSignalHeadDefends2025,
  entrysubtype = {newspaper},
  title = {Signal Head Defends Messaging App's Security after {{US}} War Plan Leak},
  author = {Pearson, James},
  date = {2025-03-25T22:33:08Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/world/us/signal-head-defends-messaging-apps-security-after-us-war-plan-leak-2025-03-25/},
  urldate = {2025-03-25},
  abstract = {The president of Signal defended the messaging app's security on Wednesday after top Trump administration officials mistakenly included a journalist in an encrypted chatroom they used to discuss looming U.S. military action against Yemen's Houthis.},
  journalsubtitle = {United States},
  langid = {english}
}

@article{perez-moronElevenYearsCyberattacks2021,
  title = {Eleven Years of Cyberattacks on {{Chinese}} Supply Chains in an Era of Cyber Warfare, a Review and Future Research Agenda},
  author = {Pérez-Morón, James},
  date = {2021-11-03T00:00:00Z},
  journaltitle = {Journal of Asia Business Studies},
  volume = {16},
  number = {2},
  pages = {371--395},
  publisher = {Emerald Publishing Limited},
  issn = {1558-7894},
  doi = {10.1108/JABS-11-2020-0444},
  url = {https://www.emerald.com/insight/content/doi/10.1108/jabs-11-2020-0444/full/html},
  urldate = {2025-03-26},
  abstract = {The contribution of this study aims to twofold: First, it provides an overview of the current state of research on cyberattacks on Chinese supply chains (SCs). Second, it offers a look at the Chinese Government’s approach to fighting cyberattacks on Chinese SCs and its calls for global governance.,A comprehensive literature review was conducted on Clarivate Analytics’ Web of Science, in Social Sciences Citation Index journals, Scopus and Google Scholar, published between 2010–2021. A systematic review of practitioner literature was also conducted.,Chinese SCs have become a matter of national security, especially in the era of cyber warfare. The risks to SC have been outlined. Cybersecurity regulations are increasing as China aims to build a robust environment for cyberspace development. Using the Technology-organization-environment (TOE) framework, the results show that the top five factors influencing the adoption process in firms are as follows: relative advantage and technological readiness (Technology context); top management support and firm size (Organization context) and government policy and regulations (Environment context).,This review focuses on cyberattacks on Chinese SCs and great care was taken when selecting search terms. However, the author acknowledges that the choice of databases/terms may have excluded a few articles on cyberattacks from this review.,This review provides managerial insights for SC practitioners into how cyberattacks have the potential to disrupt the global SC network.,Past researchers proposed a taxonomic approach to evaluate progress with SC integration into Industry 4.0; in contrast, this study is one of the first steps toward an enhanced understanding of cyberattacks on Chinese SCs and their contribution to the global SC network using the TOE framework.},
  langid = {english}
}

@online{perezAppleOpposesJudges2016,
  title = {Apple Opposes Judge’s Order to Hack {{San Bernardino}} Shooter’s {{iPhone}}},
  author = {Perez, Evan and Hume, Tim},
  date = {2016-02-17T02:33:06Z},
  url = {https://www.cnn.com/2016/02/16/us/san-bernardino-shooter-phone-apple/index.html},
  urldate = {2025-03-18},
  abstract = {Apple is opposing a judge’s order to help the FBI break into the iPhone of one of the San Bernardino, California, shooters.},
  langid = {english},
  organization = {CNN}
}

@online{perrigoExclusive$2Hour2023,
  title = {Exclusive: {{The}} \$2 {{Per Hour Workers Who Made ChatGPT Safer}}},
  shorttitle = {Exclusive},
  author = {Perrigo, Billy},
  date = {2023-01-18T12:00:58},
  url = {https://time.com/6247678/openai-chatgpt-kenya-workers/},
  urldate = {2025-03-27},
  abstract = {A TIME investigation reveals the difficult conditions faced by the workers who made ChatGPT possible},
  langid = {english},
  organization = {TIME}
}

@online{petitcolasInformationHidingHomepage,
  title = {The Information Hiding Homepage},
  author = {Petitcolas, Fabien A. P.},
  url = {http://www.petitcolas.net/steganography/},
  urldate = {2025-03-13},
  abstract = {The information hiding homepage},
  organization = {The information hiding homepage}
}

@article{petitcolasInformationHidingSurvey1999,
  title = {Information {{Hiding}} - {{A Survey}}},
  author = {Petitcolas, F.A.P. and Anderson, R.J. and Kuhn, M.G.},
  date = {1999-07},
  journaltitle = {Proceedings of the IEEE},
  volume = {87},
  number = {7},
  pages = {1062--1078},
  issn = {1558-2256},
  doi = {10.1109/5.771065},
  url = {https://ieeexplore.ieee.org/abstract/document/771065},
  urldate = {2025-03-23},
  abstract = {Information-hiding techniques have recently become important in a number of application areas. Digital audio, video, and pictures are increasingly furnished with distinguishing but imperceptible marks, which may contain a hidden copyright notice or serial number or even help to prevent unauthorized copying directly. Military communications systems make increasing use of traffic security techniques which, rather than merely concealing the content of a message using encryption, seek to conceal its sender, its receiver, or its very existence. Similar techniques are used in some mobile phone systems and schemes proposed for digital elections. Criminals try to use whatever traffic security properties are provided intentionally or otherwise in the available communications systems, and police forces try to restrict their use. However, many of the techniques proposed in this young and rapidly evolving field can trace their history back to antiquity, and many of them are surprisingly easy to circumvent. In this article, we try to give an overview of the field, of what we know, what works, what does not, and what are the interesting topics for research.},
  eventtitle = {Proceedings of the {{IEEE}}}
}

@online{petroniLanguageModelsKnowledge2019,
  title = {Language {{Models}} as {{Knowledge Bases}}?},
  author = {Petroni, Fabio and Rocktäschel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H. and Riedel, Sebastian},
  date = {2019-09-04},
  eprint = {1909.01066},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1909.01066},
  url = {http://arxiv.org/abs/1909.01066},
  urldate = {2025-03-19},
  abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as "fill-in-the-blank" cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.},
  pubstate = {prepublished}
}

@online{pytorchPyTorch,
  title = {{{PyTorch}}},
  author = {{PyTorch}},
  url = {https://pytorch.org/},
  urldate = {2025-03-17},
  langid = {english},
  organization = {PyTorch}
}

@software{pytorchPytorchAndroiddemoapp2025,
  title = {Pytorch/Android-Demo-App},
  author = {{PyTorch}},
  date = {2025-03-16T08:10:20Z},
  origdate = {2019-09-27T03:11:18Z},
  url = {https://github.com/pytorch/android-demo-app},
  urldate = {2025-03-17},
  abstract = {PyTorch android examples of usage in applications},
  organization = {pytorch}
}

@online{pytorchPyTorchAPIPyTorch,
  title = {{{PyTorch C}}++ {{API}} — {{PyTorch}} Main Documentation},
  author = {{PyTorch}},
  url = {https://pytorch.org/cppdocs/},
  urldate = {2025-03-29}
}

@software{pytorchPytorchExecutorch2025,
  title = {Pytorch/Executorch},
  author = {{PyTorch}},
  date = {2025-03-12T08:13:36Z},
  origdate = {2022-02-25T17:58:31Z},
  url = {https://github.com/pytorch/executorch},
  urldate = {2025-03-12},
  abstract = {On-device AI across mobile, embedded and edge for PyTorch},
  organization = {pytorch}
}

@online{pytorchStartLocally,
  title = {Start {{Locally}}},
  author = {{PyTorch}},
  url = {https://pytorch.org/get-started/locally/},
  urldate = {2025-03-29},
  abstract = {Start Locally},
  langid = {english},
  organization = {PyTorch}
}

@inproceedings{qadirReviewPaperCryptography2019,
  title = {A {{Review Paper}} on {{Cryptography}}},
  booktitle = {2019 7th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})},
  author = {Qadir, Abdalbasit Mohammed and Varol, Nurhayat},
  date = {2019-06},
  pages = {1--6},
  doi = {10.1109/ISDFS.2019.8757514},
  url = {https://ieeexplore.ieee.org/abstract/document/8757514},
  urldate = {2025-03-28},
  abstract = {With the internet having reached a level that merges with our lives, growing explosively during the last several decades, data security has become a main concern for anyone connected to the web. Data security ensures that our data is only accessible by the intended receiver and prevents any modification or alteration of data. In order to achieve this level of security, various algorithms and methods have been developed. Cryptography can be defined as techniques that cipher data, depending on specific algorithms that make the data unreadable to the human eye unless decrypted by algorithms that are predefined by the sender.},
  eventtitle = {2019 7th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})}
}

@online{qwenQwenQwen215BInstructGGUFHugging2024,
  title = {Qwen/{{Qwen2-1}}.{{5B-Instruct-GGUF}} · {{Hugging Face}}},
  author = {{Qwen}},
  date = {2024-06-14},
  url = {https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF},
  urldate = {2025-04-03},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.}
}

@article{raiaanReviewLargeLanguage2024,
  title = {A {{Review}} on {{Large Language Models}}: {{Architectures}}, {{Applications}}, {{Taxonomies}}, {{Open Issues}} and {{Challenges}}},
  shorttitle = {A {{Review}} on {{Large Language Models}}},
  author = {Raiaan, Mohaimenul Azam Khan and Mukta, Md. Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {26839--26874},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3365742},
  url = {https://ieeexplore.ieee.org/abstract/document/10433480},
  urldate = {2025-03-27},
  abstract = {Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.},
  eventtitle = {{{IEEE Access}}}
}

@online{rashkinEmpatheticOpendomainConversation2019,
  title = {Towards {{Empathetic Open-domain Conversation Models}}: A {{New Benchmark}} and {{Dataset}}},
  shorttitle = {Towards {{Empathetic Open-domain Conversation Models}}},
  author = {Rashkin, Hannah and Smith, Eric Michael and Li, Margaret and Boureau, Y.-Lan},
  date = {2019-08-28},
  eprint = {1811.00207},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1811.00207},
  url = {http://arxiv.org/abs/1811.00207},
  urldate = {2025-04-05},
  abstract = {One challenge for dialogue agents is recognizing feelings in the conversation partner and replying accordingly, a key communicative skill. While it is straightforward for humans to recognize and acknowledge others' feelings in a conversation, this is a significant challenge for AI systems due to the paucity of suitable publicly-available datasets for training and evaluation. This work proposes a new benchmark for empathetic dialogue generation and EmpatheticDialogues, a novel dataset of 25k conversations grounded in emotional situations. Our experiments indicate that dialogue models that use our dataset are perceived to be more empathetic by human evaluators, compared to models merely trained on large-scale Internet conversation data. We also present empirical comparisons of dialogue model adaptations for empathetic responding, leveraging existing models or datasets without requiring lengthy re-training of the full model.},
  pubstate = {prepublished}
}

@article{rayBenchmarkingEthicalAlignment2023,
  title = {Benchmarking, Ethical Alignment, and Evaluation Framework for Conversational {{AI}}: {{Advancing}} Responsible Development of {{ChatGPT}}},
  shorttitle = {Benchmarking, Ethical Alignment, and Evaluation Framework for Conversational {{AI}}},
  author = {Ray, Partha Pratim},
  date = {2023-09-01},
  journaltitle = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
  shortjournal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
  volume = {3},
  number = {3},
  pages = {100136},
  issn = {2772-4859},
  doi = {10.1016/j.tbench.2023.100136},
  url = {https://www.sciencedirect.com/science/article/pii/S2772485923000534},
  urldate = {2025-03-27},
  abstract = {Conversational AI systems like ChatGPT have seen remarkable advancements in recent years, revolutionizing human–computer interactions. However, evaluating the performance and ethical implications of these systems remains a challenge. This paper delves into the creation of rigorous benchmarks, adaptable standards, and an intelligent evaluation methodology tailored specifically for ChatGPT. We meticulously analyze several prominent benchmarks, including GLUE, SuperGLUE, SQuAD, CoQA, Persona-Chat, DSTC, BIG-Bench, HELM and MMLU illuminating their strengths and limitations. This paper also scrutinizes the existing standards set by OpenAI, IEEE’s Ethically Aligned Design, the Montreal Declaration, and Partnership on AI’s Tenets, investigating their relevance to ChatGPT. Further, we propose adaptive standards that encapsulate ethical considerations, context adaptability, and community involvement. In terms of evaluation, we explore traditional methods like BLEU, ROUGE, METEOR, precision–recall, F1 score, perplexity, and user feedback, while also proposing a novel evaluation approach that harnesses the power of reinforcement learning. Our proposed evaluation framework is multidimensional, incorporating task-specific, real-world application, and multi-turn dialogue benchmarks. We perform feasibility analysis, SWOT analysis and adaptability analysis of the proposed framework. The framework highlights the significance of user feedback, integrating it as a core component of evaluation alongside subjective assessments and interactive evaluation sessions. By amalgamating these elements, this paper contributes to the development of a comprehensive evaluation framework that fosters responsible and impactful advancement in the field of conversational AI.}
}

@inproceedings{reegardConceptCybersecurityCulture2019,
  title = {The {{Concept}} of {{Cybersecurity Culture}}},
  author = {Reegård, Kine and Blackett, Claire and Katta, Vikash},
  date = {2019-09-27},
  doi = {10.3850/978-981-11-2724-3_0761-cd},
  abstract = {Due to a growing understanding that cybersecurity needs to be addressed also through organizational measures and not by technical measures alone, cybersecurity culture is attracting increasing attention. In this paper, we present findings from a narrative literature review of 69 papers with the purpose to identify the dimensions of cybersecurity culture and how these may be targeted by the organization. The results show that cybersecurity culture is understood as a sub-component of organizational culture comprised of layers that are increasingly more observable. Further, key practices for developing cybersecurity culture resemble those highlighted in the literature on safety culture: management support; policy; awareness and training; involvement and communication; and learning from experience. We conclude with a brief discussion of whether cybersecurity culture and safety culture are two distinct sub-components of organizational culture or can be understood to be overlapping.}
}

@article{resnikWebParallelCorpus2003,
  title = {The {{Web}} as a {{Parallel Corpus}}},
  author = {Resnik, Philip and Smith, Noah A.},
  date = {2003-09-01},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {29},
  number = {3},
  pages = {349--380},
  issn = {0891-2017},
  doi = {10.1162/089120103322711578},
  url = {https://doi.org/10.1162/089120103322711578},
  urldate = {2025-03-27},
  abstract = {Parallel corpora have become an essential resource for work in multilingual natural language processing. In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web, first reviewing the original algorithm and results and then presenting a set of significant enhancements. These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale. Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.}
}

@article{rindellSecurityAgileSoftware2021,
  title = {Security in Agile Software Development: {{A}} Practitioner Survey},
  shorttitle = {Security in Agile Software Development},
  author = {Rindell, Kalle and Ruohonen, Jukka and Holvitie, Johannes and Hyrynsalmi, Sami and Leppänen, Ville},
  date = {2021-03-01},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  volume = {131},
  pages = {106488},
  issn = {0950-5849},
  doi = {10.1016/j.infsof.2020.106488},
  url = {https://www.sciencedirect.com/science/article/pii/S0950584920302305},
  urldate = {2025-04-10},
  abstract = {Context: Software security engineering provides the means to define, implement and verify security in software products. Software security engineering is performed by following a software security development life cycle model or a security capability maturity model. However, agile software development methods and processes, dominant in the software industry, are viewed to be in conflict with these security practices and the security requirements. Objective: Empirically verify the use and impact of software security engineering activities in the context of agile software development, as practiced by software developer professionals. Method: A survey (N=61) was performed among software practitioners in Finland regarding their use of 40 common security engineering practices and their perceived security impact, in conjunction with the use of 16 agile software development items and activities. Results: The use of agile items and activities had a measurable effect on the selection of security engineering practices. Perceived impact of the security practices was lower than the rate of use would imply: This was taken to indicate a selection bias, caused by e.g. developers’ awareness of only certain security engineering practices, or by difficulties in applying the security engineering practices into an iterative software development workflow. Security practices deemed to have most impact were proactive and took place in the early phases of software development. Conclusion: Systematic use of agile practices conformed, and was observed to take place in conjunction with the use of security practices. Security activities were most common in the requirement and implementation phases. In general, the activities taking place early in the life cycle were also considered most impactful. A discrepancy between the level of use and the perceived security impact of many security activities was observed. This prompts research and methodological development for better integration of security engineering activities into software development processes, methods, and tools.}
}

@article{rissanenArithmeticCoding1979,
  title = {Arithmetic {{Coding}}},
  author = {Rissanen, J. and Langdon, G. G.},
  date = {1979-03},
  journaltitle = {IBM Journal of Research and Development},
  volume = {23},
  number = {2},
  pages = {149--162},
  issn = {0018-8646},
  doi = {10.1147/rd.232.0149},
  url = {https://ieeexplore.ieee.org/abstract/document/5390830},
  urldate = {2024-12-15},
  abstract = {The earlier introduced arithmetic coding idea has been generalized to a very broad and flexible coding technique which includes virtually all known variable rate noiseless coding techniques as special cases. An outstanding feature of this technique is that alphabet extensions are not required. A complete decodability analysis is given. The relationship of arithmetic coding to other known nonblock codes is illuminated.},
  eventtitle = {{{IBM Journal}} of {{Research}} and {{Development}}}
}

@online{robertsonDocumentsRevealQaedas2012,
  title = {Documents Reveal al {{Qaeda}}’s Plans for Seizing Cruise Ships, Carnage in {{Europe}}},
  author = {Robertson, Nic and Cruickshank, Paul and Lister, Tim},
  date = {2012-04-30T19:08:07Z},
  url = {https://www.cnn.com/2012/04/30/world/al-qaeda-documents-future/index.html},
  urldate = {2025-02-18},
  abstract = {CNN has obtained access to details of al Qaeda documents which shed light on future plans including seizing cruise ships and causing carnage in Europe.},
  langid = {english},
  organization = {CNN}
}

@article{rubinArithmeticStreamCoding1979,
  title = {Arithmetic Stream Coding Using Fixed Precision Registers},
  author = {Rubin, F.},
  date = {1979-11},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {25},
  number = {6},
  pages = {672--675},
  issn = {1557-9654},
  doi = {10.1109/TIT.1979.1056107},
  url = {https://ieeexplore.ieee.org/abstract/document/1056107},
  urldate = {2025-03-14},
  abstract = {Algorithms are presented for encoding and decoding strings of characters as real binary fractions, using registers of fixed precision. The encoding is left to right and does not require blocking. The algorithms have storage requirementsO(N)and computation timeO(n łog\_2N)for string lengthnand alphabet sizeN.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}}
}

@article{ruggiaDarkSideNative2025,
  title = {The {{Dark Side}} of {{Native Code}} on {{Android}}},
  author = {Ruggia, Antonio and Possemato, Andrea and Dambra, Savino and Merlo, Alessio and Aonzo, Simone and Balzarotti, Davide},
  date = {2025-02-22},
  journaltitle = {ACM Trans. Priv. Secur.},
  volume = {28},
  number = {2},
  pages = {13:1--13:33},
  issn = {2471-2566},
  doi = {10.1145/3712308},
  url = {https://dl.acm.org/doi/10.1145/3712308},
  urldate = {2025-03-29},
  abstract = {From a little research experiment to an essential component of military arsenals, malicious software has constantly been growing and evolving for more than three decades. On the other hand, from a negligible market share, the Android operating system is nowadays the most widely used mobile operating system, becoming a desirable target for large-scale malware distribution. While scientific literature has followed this trend, one aspect has been understudied: the role of native code in malicious Android apps. Android apps are written in high-level languages, but thanks to the Java Native Interface (JNI), Android also supports calling native (C/C++) library functions. While allowing native code in Android apps has a strong positive impact from a performance perspective, it dramatically complicates its analysis because bytecode and native code need different abstractions and analysis algorithms, and they thus pose different challenges and limitations. Consequently, these difficulties are often (ab)used to hide malicious payloads.In this work, we propose a novel methodology to reverse engineering Android apps focusing on suspicious patterns related to native components, i.e., surreptitious code that requires further inspection. We implemented a static analysis tool based on such methodology, which can bridge the “Java” and the native worlds and perform an in-depth analysis of tag code blocks responsible for suspicious behavior. These tags benefit the human facing the reverse engineering task: they clearly indicate which part of the code to focus on to find malicious code.Then, we performed a longitudinal analysis of Android malware over the past 10 years and compared the recent malicious samples with actual top apps on the Google Play Store. Our work depicts typical behaviors of modern malware, its evolution, and how it abuses the native layer to complicate the analysis, especially with dynamic code loading and novel anti-analysis techniques. Finally, we show a use case for our suspicious tags: we trained and tested a machine learning algorithm for a binary classification task. Even if suspicious does not imply malicious, our classifier obtained a remarkable F1-score of 0.97, showing that our methodology can be helpful to both humans and machines.}
}

@inproceedings{salleeModelBasedSteganography2004,
  title = {Model-{{Based Steganography}}},
  booktitle = {Digital {{Watermarking}}},
  author = {Sallee, Phil},
  editor = {Kalker, Ton and Cox, Ingemar and Ro, Yong Man},
  date = {2004},
  pages = {154--167},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-24624-4_12},
  abstract = {This paper presents an information-theoretic method for performing steganography and steganalysis using a statistical model of the cover medium. The methodology is general, and can be applied to virtually any type of media. It provides answers for some fundamental questions which have not been fully addressed by previous steganographic methods, such as how large a message can be hidden without risking detection by certain statistical methods, and how to achieve this maximum capacity. Current steganographic methods have been shown to be insecure against fairly simple statistical attacks. Using the model-based methodology, an example steganography method is proposed for JPEG images which achieves a higher embedding efficiency and message capacity than previous methods while remaining secure against first order statistical attacks.},
  isbn = {978-3-540-24624-4},
  langid = {english}
}

@article{satterSignalAppChoice2025,
  entrysubtype = {newspaper},
  title = {Signal Is App of Choice for {{Trump}} Allies and Opponents Alike},
  author = {Satter, Raphael},
  date = {2025-03-25T17:36:54Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/signal-is-app-choice-trump-allies-opponents-alike-2025-03-25/},
  urldate = {2025-03-25},
  abstract = {Elon Musk's team working to dismantle the federal bureaucracy and the protesters hoping to stop him have something in common.},
  journalsubtitle = {Technology},
  langid = {english}
}

@online{schmidgallAgentLaboratoryUsing2025,
  title = {Agent {{Laboratory}}: {{Using LLM Agents}} as {{Research Assistants}}},
  shorttitle = {Agent {{Laboratory}}},
  author = {Schmidgall, Samuel and Su, Yusheng and Wang, Ze and Sun, Ximeng and Wu, Jialian and Yu, Xiaodong and Liu, Jiang and Liu, Zicheng and Barsoum, Emad},
  date = {2025-01-08},
  eprint = {2501.04227},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.04227},
  url = {http://arxiv.org/abs/2501.04227},
  urldate = {2025-03-24},
  abstract = {Historically, scientific discovery has been a lengthy and costly process, demanding substantial time and resources from initial conception to final results. To accelerate scientific discovery, reduce research costs, and improve research quality, we introduce Agent Laboratory, an autonomous LLM-based framework capable of completing the entire research process. This framework accepts a human-provided research idea and progresses through three stages--literature review, experimentation, and report writing to produce comprehensive research outputs, including a code repository and a research report, while enabling users to provide feedback and guidance at each stage. We deploy Agent Laboratory with various state-of-the-art LLMs and invite multiple researchers to assess its quality by participating in a survey, providing human feedback to guide the research process, and then evaluate the final paper. We found that: (1) Agent Laboratory driven by o1-preview generates the best research outcomes; (2) The generated machine learning code is able to achieve state-of-the-art performance compared to existing methods; (3) Human involvement, providing feedback at each stage, significantly improves the overall quality of research; (4) Agent Laboratory significantly reduces research expenses, achieving an 84\% decrease compared to previous autonomous research methods. We hope Agent Laboratory enables researchers to allocate more effort toward creative ideation rather than low-level coding and writing, ultimately accelerating scientific discovery.},
  pubstate = {prepublished}
}

@online{schneierTerroristsScienceHiding2001,
  title = {Terrorists and the Science of Hiding Messages},
  author = {Schneier, Bruce},
  date = {2001-09-25},
  url = {https://www.zdnet.com/article/terrorists-and-the-science-of-hiding-messages/},
  urldate = {2025-01-09},
  abstract = {Security expert Bruce Schneier writes that terrorist groups may be using steganography to communicate, allowing communication without any group knowing the identity of the other.},
  langid = {english}
}

@online{schneierTerroristsSteganography2001,
  title = {Terrorists and Steganography},
  author = {Schneier, Bruce},
  date = {2001-09-23},
  url = {https://www.zdnet.com/article/terrorists-and-steganography/},
  urldate = {2025-02-18},
  abstract = {Security expert Bruce Schneier writes that terrorist groups may be using steganography to communicate, allowing communication without any group knowing the identity of the other.},
  langid = {english},
  organization = {ZDNET}
}

@online{sennrichNeuralMachineTranslation2016,
  title = {Neural {{Machine Translation}} of {{Rare Words}} with {{Subword Units}}},
  author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  date = {2016-06-10},
  eprint = {1508.07909},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1508.07909},
  url = {http://arxiv.org/abs/1508.07909},
  urldate = {2025-03-12},
  abstract = {Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.},
  pubstate = {prepublished}
}

@article{serpanosCyberwarfareUkraine2022,
  title = {The {{Cyberwarfare}} in {{Ukraine}}},
  author = {Serpanos, Dimitrios and Komninos, Theodoros},
  date = {2022-07},
  journaltitle = {Computer},
  volume = {55},
  number = {7},
  pages = {88--91},
  issn = {1558-0814},
  doi = {10.1109/MC.2022.3170644},
  url = {https://ieeexplore.ieee.org/abstract/document/9810126},
  urldate = {2025-03-26},
  abstract = {The hybrid war in Ukraine is shaping cybersecurity for critical infrastructures and services worldwide. The events will be changing cybersecurity processes worldwide for a long time beyond the resolution of the conflict.},
  eventtitle = {Computer}
}

@article{seufertShareMultiplyModeling2023,
  title = {Share and {{Multiply}}: {{Modeling Communication}} and {{Generated Traffic}} in {{Private WhatsApp Groups}}},
  shorttitle = {Share and {{Multiply}}},
  author = {Seufert, Anika and Poignée, Fabian and Seufert, Michael and Hoßfeld, Tobias},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {25401--25414},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3254913},
  url = {https://ieeexplore.ieee.org/abstract/document/10064263},
  urldate = {2025-04-05},
  abstract = {Group-based communication is a highly popular communication paradigm, which is especially prominent in mobile instant messaging (MIM) applications, such as WhatsApp. Chat groups in MIM applications facilitate the sharing of various types of messages (e.g., text, voice, image, video) among a large number of participants. As each message has to be transmitted to every other member of the group, which multiplies the traffic, this has a massive impact on the underlying communication networks. However, most chat groups are private and network operators cannot obtain deep insights into MIM communication via network measurements due to end-to-end encryption. Thus, the generation of traffic is not well understood, given that it depends on sizes of communication groups, speed of communication, and exchanged message types. In this work, we provide a huge data set of 5,956 private WhatsApp chat histories, which contains over 76 million messages from more than 117,000 users. We describe and model the properties of chat groups and users, and the communication within these chat groups, which gives unprecedented insights into private MIM communication. In addition, we conduct exemplary measurements for the most popular message types, which empower the provided models to estimate the traffic over time in a chat group.}
}

@article{shahriarLetsHaveChat2023,
  title = {Let's Have a Chat! {{A Conversation}} with {{ChatGPT}}: {{Technology}}, {{Applications}}, and {{Limitations}}},
  shorttitle = {Let's Have a Chat! {{A Conversation}} with {{ChatGPT}}},
  author = {Shahriar, Sakib and Hayawi, Kadhim},
  date = {2023-06-02},
  journaltitle = {Artificial Intelligence and Applications},
  shortjournal = {AIA},
  volume = {2},
  number = {1},
  eprint = {2302.13817},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {11--20},
  issn = {2811-0854},
  doi = {10.47852/bonviewAIA3202939},
  url = {http://arxiv.org/abs/2302.13817},
  urldate = {2025-04-05},
  abstract = {The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.}
}

@article{shannonCommunicationTheorySecrecy1949,
  title = {Communication Theory of Secrecy Systems},
  author = {Shannon, C. E.},
  date = {1949-10},
  journaltitle = {The Bell System Technical Journal},
  volume = {28},
  number = {4},
  pages = {656--715},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1949.tb00928.x},
  url = {https://ieeexplore.ieee.org/document/6769090},
  urldate = {2025-03-13},
  abstract = {THE problems of cryptography and secrecy systems furnish an interesting application of communication theory.1 In this paper a theory of secrecy systems is developed. The approach is on a theoretical level and is intended to complement the treatment found in standard works on cryptography.2 There, a detailed study is made of the many standard types of codes and ciphers, and of the ways of breaking them. We will be more concerned with the general mathematical structure and properties of secrecy systems.},
  eventtitle = {The {{Bell System Technical Journal}}}
}

@article{shannonMathematicalTheoryCommunication1948,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, C. E.},
  date = {1948-07},
  journaltitle = {The Bell System Technical Journal},
  volume = {27},
  number = {3},
  pages = {379--423},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1948.tb01338.x},
  url = {https://ieeexplore.ieee.org/abstract/document/6773024},
  urldate = {2025-04-05},
  abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.}
}

@online{shenNearimperceptibleNeuralLinguistic2020,
  title = {Near-Imperceptible {{Neural Linguistic Steganography}} via {{Self-Adjusting Arithmetic Coding}}},
  author = {Shen, Jiaming and Ji, Heng and Han, Jiawei},
  date = {2020-10-01},
  eprint = {2010.00677},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2010.00677},
  url = {http://arxiv.org/abs/2010.00677},
  urldate = {2025-04-05},
  abstract = {Linguistic steganography studies how to hide secret messages in natural language cover texts. Traditional methods aim to transform a secret message into an innocent text via lexical substitution or syntactical modification. Recently, advances in neural language models (LMs) enable us to directly generate cover text conditioned on the secret message. In this study, we present a new linguistic steganography method which encodes secret messages using self-adjusting arithmetic coding based on a neural language model. We formally analyze the statistical imperceptibility of this method and empirically show it outperforms the previous state-of-the-art methods on four datasets by 15.3\% and 38.9\% in terms of bits/word and KL metrics, respectively. Finally, human evaluations show that 51\% of generated cover texts can indeed fool eavesdroppers.},
  pubstate = {prepublished}
}

@online{shiCodeCorrectnessClosing2024,
  title = {From {{Code}} to {{Correctness}}: {{Closing}} the {{Last Mile}} of {{Code Generation}} with {{Hierarchical Debugging}}},
  shorttitle = {From {{Code}} to {{Correctness}}},
  author = {Shi, Yuling and Wang, Songsong and Wan, Chengcheng and Gu, Xiaodong},
  date = {2024-10-05},
  eprint = {2410.01215},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.01215},
  url = {http://arxiv.org/abs/2410.01215},
  urldate = {2025-03-24},
  abstract = {While large language models have made significant strides in code generation, the pass rate of the generated code is bottlenecked on subtle errors, often requiring human intervention to pass tests, especially for complex problems. Existing LLM-based debugging systems treat generated programs as monolithic units, failing to address bugs at multiple levels of granularity, from low-level syntax errors to high-level algorithmic flaws. In this paper, we introduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger by isolating, identifying, and resolving bugs at various levels of granularity. MGDebugger decomposes problematic code into a hierarchical tree structure of subfunctions, with each level representing a particular granularity of error. During debugging, it analyzes each subfunction and iteratively resolves bugs in a bottom-up manner. To effectively test each subfunction, we propose an LLM-simulated Python executor, which traces code execution and tracks important variable states to pinpoint errors accurately. Extensive experiments demonstrate that MGDebugger outperforms existing debugging systems, achieving an 18.9\% improvement in accuracy over seed generations in HumanEval and a 97.6\% repair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes bugs across different categories and difficulty levels, demonstrating its robustness and effectiveness.},
  pubstate = {prepublished}
}

@inproceedings{shirali-shahrezaNewApproachPersian2006,
  title = {A {{New Approach}} to {{Persian}}/{{Arabic Text Steganography}}},
  booktitle = {5th {{IEEE}}/{{ACIS International Conference}} on {{Computer}} and {{Information Science}} and 1st {{IEEE}}/{{ACIS International Workshop}} on {{Component-Based Software Engineering}},{{Software Architecture}} and {{Reuse}} ({{ICIS-COMSAR}}'06)},
  author = {Shirali-Shahreza, M.H. and Shirali-Shahreza, M.},
  date = {2006-07},
  pages = {310--315},
  doi = {10.1109/ICIS-COMSAR.2006.10},
  url = {https://ieeexplore.ieee.org/abstract/document/1652009},
  urldate = {2025-03-23},
  abstract = {Conveying information secretly and establishing hidden relationship has been of interest since long past. Text documents have been widely used since very long time ago. Therefore, we have witnessed different method of hiding information in texts (text steganography) since past to the present. In this paper we introduce a new approach for steganography in Persian and Arabic texts. Considering the existence of too many points in Persian and Arabic phrases, in this approach, by vertical displacement of the points, we hide information in the texts. This approach can be categorized under feature coding methods. This method can be used for Persian/Arabic watermarking. Our method has been implemented by Java programming language},
  eventtitle = {5th {{IEEE}}/{{ACIS International Conference}} on {{Computer}} and {{Information Science}} and 1st {{IEEE}}/{{ACIS International Workshop}} on {{Component-Based Software Engineering}},{{Software Architecture}} and {{Reuse}} ({{ICIS-COMSAR}}'06)}
}

@inproceedings{shirali-shahrezaTextSteganographySMS2007,
  title = {Text {{Steganography}} in {{SMS}}},
  booktitle = {2007 {{International Conference}} on {{Convergence Information Technology}} ({{ICCIT}} 2007)},
  author = {Shirali-Shahreza, Mohammad and Shirali-Shahreza, M. Hassan},
  date = {2007-11},
  pages = {2260--2265},
  doi = {10.1109/ICCIT.2007.100},
  url = {https://ieeexplore.ieee.org/abstract/document/4420590},
  urldate = {2025-03-08},
  abstract = {One of the services used in mobile phone is the short message service (SMS) which is widely used by the public in all parts of the world especially in Asia and Europe. This service enables people to write and exchange short messages via mobile phone. Due to the limited size of SMS, lack of a proper keyboard on the mobile phone and to improve the speed of typing, new abbreviations have been invented for different words and phrases which has lead to the invention of a new language called SMS-texting. One of the main issues in communication is information security and privacy. There are many methods for secret communication and many researchers are working on steganography. In steganography the data is hidden in a cover media such as picture or text. The present paper offers a new method for secret exchange of information through SMS by using and developing abbreviation text steganography with the use of the invented language of SMS-texting. This project has been implemented by J2ME (Java 2 Micro Edition) programming language and tested on a Nokia N71 mobile phone.},
  eventtitle = {2007 {{International Conference}} on {{Convergence Information Technology}} ({{ICCIT}} 2007)}
}

@online{shragerELIZAReinterpretedWorlds2024,
  title = {{{ELIZA Reinterpreted}}: {{The}} World's First Chatbot Was Not Intended as a Chatbot at All},
  shorttitle = {{{ELIZA Reinterpreted}}},
  author = {Shrager, Jeff},
  date = {2024-09-19},
  eprint = {2406.17650},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.17650},
  url = {http://arxiv.org/abs/2406.17650},
  urldate = {2025-03-27},
  abstract = {ELIZA, often considered the world's first chatbot, was written by Joseph Weizenbaum in the early 1960s. Weizenbaum did not intend to invent the chatbot, but rather to build a platform for research into human-machine conversation and the important cognitive processes of interpretation and misinterpretation. His purpose was obscured by ELIZA's fame, resulting in large part from the fortuitous timing of it's creation, and it's escape into the wild. In this paper I provide a rich historical context for ELIZA's creation, demonstrating that ELIZA arose from the intersection of some of the central threads in the technical history of AI. I also briefly discuss how ELIZA escaped into the world, and how its accidental escape, along with several coincidental turns of the programming language screws, led both to the misapprehension that ELIZA was intended as a chatbot, and to the loss of the original ELIZA to history for over 50 years.},
  pubstate = {prepublished}
}

@online{shumailovCurseRecursionTraining2024,
  title = {The {{Curse}} of {{Recursion}}: {{Training}} on {{Generated Data Makes Models Forget}}},
  shorttitle = {The {{Curse}} of {{Recursion}}},
  author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  date = {2024-04-14},
  eprint = {2305.17493},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.17493},
  url = {http://arxiv.org/abs/2305.17493},
  urldate = {2025-03-19},
  abstract = {Stable Diffusion revolutionised image creation from descriptive text. GPT-2, GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of language tasks. ChatGPT introduced such language models to the general public. It is now clear that large language models (LLMs) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to GPT-\{n\} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of content generated by LLMs in data crawled from the Internet.},
  pubstate = {prepublished}
}

@article{shumanovMakingConversationsChatbots2021,
  title = {Making Conversations with Chatbots More Personalized},
  author = {Shumanov, Michael and Johnson, Lester},
  date = {2021-04-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {117},
  pages = {106627},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2020.106627},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563220303745},
  urldate = {2025-04-05},
  abstract = {Many of the world's leading brands and increasingly government agencies are using intelligent agent technologies, also known as chatbots to interact with consumers. However, consumer satisfaction with chatbots is mixed. Consumers report frustration with chatbots arising from misunderstood questions, irrelevant responses, and poor integration with human service agents. This study examines whether human-computer interactions can be more personalized by matching consumer personality with congruent machine personality using language. Although the idea that personality is manifested through language, and that people are more likely to be responsive to others with the same personality is well known, there is a dearth of research that examines whether this is consistent for human-computer interactions. Based on a sample of over 57,000 chatbot interactions, this study demonstrates that consumer personality can be predicted during contextual interactions, and that chatbots can be manipulated to ‘assume a personality’ using response language. Matching consumer personality with congruent chatbot personality had a positive impact on consumer engagement with chatbots and purchasing outcomes for interactions involving social gain.}
}

@inproceedings{silvaUnveilingQualityChatbot2023,
  title = {Unveiling {{Quality}} in {{Chatbot Conversations}}: {{Quantitative Analysis}} of {{Chatbot Requirements}}},
  shorttitle = {Unveiling {{Quality}} in {{Chatbot Conversations}}},
  booktitle = {Proceedings of the {{XXII Brazilian Symposium}} on {{Software Quality}}},
  author = {Silva, Geovana Ramos Sousa and Canedo, Edna Dias},
  date = {2023-12-06},
  series = {{{SBQS}} '23},
  pages = {148--157},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3629479.3629481},
  url = {https://dl.acm.org/doi/10.1145/3629479.3629481},
  urldate = {2025-04-05},
  abstract = {As conversational assistants and natural language interfaces proliferate, the demand for a precise understanding of quality software requirements for chatbots becomes increasingly critical. In this work, we adopted a quantitative methodology, scrutinizing a dataset composed of conversational requirements from a diverse range of agile projects for chatbot development, and identified meaningful patterns in the language and structure utilized. Our investigation led to significant findings, revealing the importance of structured documentation, conversation flow, and user interaction in the development of chatbots, with the most desired quality attributes being capability, naturalness, straightforwardness, and clarity. In addition, a significant emphasis was placed on feature development and meeting acceptance criteria. The research also illuminated the iterative nature of chatbot development, with a recurrent presence of verbs related to improvement or refactoring. While less pronounced, the roles of documentation and testing in ensuring chatbot quality and effectiveness were also noted. This work provides valuable insights into chatbot requirements management and the significance of quality attributes in chatbot development.},
  isbn = {979-8-4007-0786-5}
}

@online{smithEffectiveSecurityObscurity2022,
  title = {Effective {{Security}} by {{Obscurity}}},
  author = {Smith, J. Christian},
  date = {2022-04-30},
  eprint = {2205.01547},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.01547},
  url = {http://arxiv.org/abs/2205.01547},
  urldate = {2025-03-28},
  abstract = {"Security by obscurity" is a bromide which is frequently applied to undermine the perceived value of a certain class of techniques in security. This usage initially stemmed from applications and experience in the areas of cryptographic theory, and the open vs. closed source debate. Through the perceived absence of true security, the field of security by obscurity has not coalesced into a viable or recognizable approach for security practitioners. The ramifications of this has resulted in these techniques going underused and underappreciated by defenders, while they continue to provide value to attackers, which creates an unfortunate information asymmetry. Exploring effective methods for employing security by obscurity, it can be seen that examples are already embedded unrecognized in other viable security disciplines, such as information hiding, obfuscation, diversity, and moving target defense. In showing that obscurity measures are an achievable and desirable supplement to other security measures, it is apparent that the in-depth defense of an organization's assets can be enhanced by intentional and effective use of security by obscurity.},
  pubstate = {prepublished}
}

@online{smithMillionWhatsAppMessages2018,
  title = {A Million {{WhatsApp}} Messages Were Sent in the Time It's Taken You to Read This Headline},
  author = {Smith, Rob},
  date = {2018-03-19},
  url = {https://www.weforum.org/stories/2018/03/internet-minute-whatsapp-facebook-emails/},
  urldate = {2025-04-21},
  abstract = {A lot happens on the internet in 60 seconds. Here we take a look at the staggering number of messages, pictures and emails shared across the web and social media every minute.},
  langid = {english},
  organization = {World Economic Forum}
}

@article{solankiPrintScanResilient2006,
  title = {`{{Print}} and {{Scan}}' {{Resilient Data Hiding}} in {{Images}}},
  author = {Solanki, Kaushal and Madhow, Upamanyu and Manjunath, B. S. and Chandrasekaran, Shiv and El-Khalil, Ibrahim},
  date = {2006-12},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {1},
  number = {4},
  pages = {464--478},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2006.885032},
  url = {https://ieeexplore.ieee.org/abstract/document/4014110},
  urldate = {2025-05-02},
  abstract = {Print-scan resilient data hiding finds important applications in document security and image copyright protection. This paper proposes methods to hide information into images that achieve robustness against printing and scanning with blind decoding. The selective embedding in low frequencies scheme hides information in the magnitude of selected low-frequency discrete Fourier transform coefficients. The differential quantization index modulation scheme embeds information in the phase spectrum of images by quantizing the difference in phase of adjacent frequency locations. A significant contribution of this paper is analytical and experimental modeling of the print-scan process, which forms the basis of the proposed embedding schemes. A novel approach for estimating the rotation undergone by the image during the scanning process is also proposed, which specifically exploits the knowledge of the digital halftoning scheme employed by the printer. Using the proposed methods, several hundred information bits can be embedded into images with perfect recovery against the print-scan operation. Moreover, the hidden images also survive several other attacks, such as Gaussian or median filtering, scaling or aspect ratio change, heavy JPEG compression, and rows and/or columns removal}
}

@article{soltanipanahPropertiesNonMediaDigital2016,
  title = {On the {{Properties}} of {{Non-Media Digital Watermarking}}: {{A Review}} of {{State}} of the {{Art Techniques}}},
  shorttitle = {On the {{Properties}} of {{Non-Media Digital Watermarking}}},
  author = {Soltani Panah, Arezou and Van Schyndel, Ron and Sellis, Timos and Bertino, Elisa},
  date = {2016},
  journaltitle = {IEEE Access},
  volume = {4},
  pages = {2670--2704},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2016.2570812},
  url = {https://ieeexplore.ieee.org/document/7473843},
  urldate = {2025-03-27},
  abstract = {Over the last 25 years, there has been much work on multimedia digital watermarking. In this domain, the primary limitation to watermark strength has been in its visibility. For multimedia watermarks, invisibility is defined in human terms (that is, in terms of human sensory limitations). In this paper, we review recent developments in the non-media applications of data watermarking, which have emerged over the last decade as an exciting new sub-domain. Since by definition, the intended receiver should be able to detect the watermark, we have to redefine invisibility in an acceptable way that is often application-specific and thus cannot be easily generalized. In particular, this is true when the data is not intended to be directly consumed by humans. For example, a loose definition of robustness might be in terms of the resilience of a watermark against normal host data operations, and of invisibility as resilience of the data interpretation against change introduced by the watermark. In this paper, we classify the data in terms of data mining rules on complex types of data such as time-series, symbolic sequences, data streams, and so forth. We emphasize the challenges involved in non-media watermarking in terms of common watermarking properties, including invisibility, capacity, robustness, and security. With the aid of a few examples of watermarking applications, we demonstrate these distinctions and we look at the latest research in this regard to make our argument clear and more meaningful. As the last aim, we look at the new challenges of digital watermarking that have arisen with the evolution of big data.},
  eventtitle = {{{IEEE Access}}}
}

@online{songLLMFeynmanLeveragingLarge2025,
  title = {{{LLM-Feynman}}: {{Leveraging Large Language Models}} for {{Universal Scientific Formula}} and {{Theory Discovery}}},
  shorttitle = {{{LLM-Feynman}}},
  author = {Song, Zhilong and Ju, Minggang and Ren, Chunjin and Li, Qiang and Li, Chongyi and Zhou, Qionghua and Wang, Jinlan},
  date = {2025-03-09},
  eprint = {2503.06512},
  eprinttype = {arXiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2503.06512},
  url = {http://arxiv.org/abs/2503.06512},
  urldate = {2025-03-24},
  abstract = {Distilling the underlying principles from data has long propelled scientific breakthroughs. However, conventional data-driven machine learning -- lacking deep, contextual domain knowledge -- tend to yield opaque or over-complex models that are challenging to interpret and generalize. Here, we present LLM-Feynman, a framework that leverages the embedded expertise of large language models (LLMs) with systematic optimization to distill concise, interpretable formula from data and domain knowledge. Our framework seamlessly integrates automated feature engineering, LLM-based symbolic regression augmented by self-evaluation and iterative refinement, and formula interpretation via Monte Carlo tree search. Ablation studies show that incorporating domain knowledge and self-evaluation yields more accurate formula at equivalent formula complexity than conventional symbolic regression. Validation on datasets from Feynman physics lectures confirms that LLM-Feynman can rediscover over 90\% real physical formulas. Moreover, when applied to four key materials science tasks -- from classifying the synthesizability of 2D and perovskite structures to predicting ionic conductivity in lithium solid-state electrolytes and GW bandgaps in 2D materials -- LLM-Feynman consistently yields interpretable formula with accuracy exceeding 90\% and R2 values above 0.8. By transcending mere data fitting through the integration of deep domain knowledge, LLM-Feynman establishes a new paradigm for the automated discovery of generalizable scientific formula and theory across disciplines.},
  pubstate = {prepublished}
}

@article{soniOpenAIOutlinesNew2025,
  entrysubtype = {newspaper},
  title = {{{OpenAI}} Outlines New For-Profit Structure in Bid to Stay Ahead in Costly {{AI}} Race},
  author = {Soni, Aditya and Bajwa, Arsheeya and Hu, Krystal},
  date = {2025-01-02T20:17:57Z},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/artificial-intelligence/openai-lays-out-plan-shift-new-for-profit-structure-2024-12-27/},
  urldate = {2025-03-27},
  abstract = {OpenAI on Friday outlined plans to revamp its structure, saying it would create a public benefit corporation to make it easier to "raise more capital than we'd imagined," and remove the restrictions imposed on the startup by its current nonprofit parent.},
  journalsubtitle = {Artificial Intelligence},
  langid = {english}
}

@article{southEffectiveUseLikert2022,
  title = {Effective {{Use}} of {{Likert Scales}} in {{Visualization Evaluations}}: {{A Systematic Review}}},
  shorttitle = {Effective {{Use}} of {{Likert Scales}} in {{Visualization Evaluations}}},
  author = {South, Laura and Saffo, David and Vitek, Olga and Dunne, Cody and Borkin, Michelle A.},
  date = {2022},
  journaltitle = {Computer Graphics Forum},
  volume = {41},
  number = {3},
  pages = {43--55},
  issn = {1467-8659},
  doi = {10.1111/cgf.14521},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14521},
  urldate = {2025-04-10},
  abstract = {Likert scales are often used in visualization evaluations to produce quantitative estimates of subjective attributes, such as ease of use or aesthetic appeal. However, the methods used to collect, analyze, and visualize data collected with Likert scales are inconsistent among evaluations in visualization papers. In this paper, we examine the use of Likert scales as a tool for measuring subjective response in a systematic review of 134 visualization evaluations published between 2009 and 2019. We find that papers with both objective and subjective measures do not hold the same reporting and analysis standards for both aspects of their evaluation, producing less rigorous work for the subjective qualities measured by Likert scales. Additionally, we demonstrate that many papers are inconsistent in their interpretations of Likert data as discrete or continuous and may even sacrifice statistical power by applying nonparametric tests unnecessarily. Finally, we identify instances where key details about Likert item construction with the potential to bias participant responses are omitted from evaluation methodology reporting, inhibiting the feasibility and reliability of future replication studies. We summarize recommendations from other fields for best practices with Likert data in visualization evaluations, based on the results of our survey. A full copy of this paper and all supplementary material are available at https://osf.io/exbz8/.},
  langid = {english}
}

@online{spammimicSpammimic2000,
  title = {Spammimic},
  author = {{Spammimic}},
  date = {2000},
  url = {https://www.spammimic.com/},
  urldate = {2025-03-11},
  abstract = {and you thought spam was useless},
  langid = {english}
}

@software{srivastavaBhrigu123Huffmancoding2025,
  title = {Bhrigu123/Huffman-Coding},
  author = {Srivastava, Bhrigu},
  date = {2025-03-09T06:50:15Z},
  origdate = {2017-01-18T13:17:33Z},
  url = {https://github.com/bhrigu123/huffman-coding},
  urldate = {2025-03-20},
  abstract = {Python Implementaion of Huffman Coding - compression and decompression}
}

@inproceedings{steinebachNaturalLanguageSteganography2024,
  title = {Natural {{Language Steganography}} by {{ChatGPT}}},
  booktitle = {Proceedings of the 19th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Steinebach, Martin},
  date = {2024-07-30},
  series = {{{ARES}} '24},
  pages = {1--9},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3664476.3670930},
  url = {https://dl.acm.org/doi/10.1145/3664476.3670930},
  urldate = {2024-11-12},
  abstract = {Natural language steganography as well as natural language watermarking have been challenging because of the complexity and lack of noise in natural language. But with the advent of LLMs like ChatGPT, controlled synthesis of written language has become available. In this work, we show how ChatGPT can be utilized to generate synthetic texts of a given topic that act as stego covers for hidden messages.},
  isbn = {979-8-4007-1718-5}
}

@article{sufiSocialMediaAnalytics2023,
  title = {Social {{Media Analytics}} on {{Russia}}–{{Ukraine Cyber War}} with {{Natural Language Processing}}: {{Perspectives}} and {{Challenges}}},
  shorttitle = {Social {{Media Analytics}} on {{Russia}}–{{Ukraine Cyber War}} with {{Natural Language Processing}}},
  author = {Sufi, Fahim},
  date = {2023-09},
  journaltitle = {Information},
  volume = {14},
  number = {9},
  pages = {485},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info14090485},
  url = {https://www.mdpi.com/2078-2489/14/9/485},
  urldate = {2025-03-26},
  abstract = {Utilizing social media data is imperative in comprehending critical insights on the Russia–Ukraine cyber conflict due to their unparalleled capacity to provide real-time information dissemination, thereby enabling the timely tracking and analysis of cyber incidents. The vast array of user-generated content on these platforms, ranging from eyewitness accounts to multimedia evidence, serves as invaluable resources for corroborating and contextualizing cyber attacks, facilitating the attribution of malicious actors. Furthermore, social media data afford unique access to public sentiment, the propagation of propaganda, and emerging narratives, offering profound insights into the effectiveness of information operations and shaping counter-messaging strategies. However, there have been hardly any studies reported on the Russia–Ukraine cyber war harnessing social media analytics. This paper presents a comprehensive analysis of the crucial role of social-media-based cyber intelligence in understanding Russia’s cyber threats during the ongoing Russo–Ukrainian conflict. This paper introduces an innovative multidimensional cyber intelligence framework and utilizes Twitter data to generate cyber intelligence reports. By leveraging advanced monitoring tools and NLP algorithms, like language detection, translation, sentiment analysis, term frequency–inverse document frequency (TF-IDF), latent Dirichlet allocation (LDA), Porter stemming, n-grams, and others, this study automatically generated cyber intelligence for Russia and Ukraine. Using 37,386 tweets originating from 30,706 users in 54 languages from 13 October 2022 to 6 April 2023, this paper reported the first detailed multilingual analysis on the Russia–Ukraine cyber crisis in four cyber dimensions (geopolitical and socioeconomic; targeted victim; psychological and societal; and national priority and concerns). It also highlights challenges faced in harnessing reliable social-media-based cyber intelligence.},
  issue = {9},
  langid = {english}
}

@online{tarkowskiDataGovernanceOpen2025,
  title = {Data {{Governance}} in {{Open Source AI}}},
  author = {Tarkowski, Alek},
  date = {2025-02-03},
  url = {https://opensource.org/data-governance-open-source-ai},
  urldate = {2025-03-27},
  abstract = {Data Governance in Open Source AI},
  langid = {american},
  organization = {Open Source Initiative}
}

@online{tawfeeqCanadaWarnsTravelers2025,
  title = {Canada Warns Travelers That {{US}} Border Agents Could Search Electronic Devices},
  author = {Tawfeeq, Mohammed},
  date = {2025-04-05T18:00:40},
  url = {https://www.cnn.com/2025/04/05/world/canada-travel-advisory-us-electronic-devices-intl-latam/index.html},
  urldate = {2025-04-08},
  abstract = {The revised travel advisory urges Canadians to “expect scrutiny” when crossing the border and warns that refusing to comply involves risks including device seizure, travel delays, or the denial of entry for non-US citizens.},
  langid = {english},
  organization = {CNN}
}

@video{tedGlennGreenwaldWhy2014,
  entrysubtype = {video},
  title = {Glenn {{Greenwald}}: {{Why}} Privacy Matters},
  shorttitle = {Glenn {{Greenwald}}},
  editor = {{TED}},
  editortype = {director},
  date = {2014-10-10},
  url = {https://www.youtube.com/watch?v=pcSlowAhvUk},
  urldate = {2025-03-11}
}

@online{tensorflowAPIDocumentationTensorFlow,
  title = {{{API Documentation}} | {{TensorFlow}} v2.16.1},
  author = {{TensorFlow}},
  url = {https://www.tensorflow.org/api_docs},
  urldate = {2025-03-29},
  abstract = {An open source machine learning library for research and production.},
  langid = {english},
  organization = {TensorFlow}
}

@online{tensorflowTensorFlow,
  title = {{{TensorFlow}}},
  author = {{TensorFlow}},
  url = {https://www.tensorflow.org/},
  urldate = {2025-03-29},
  abstract = {An end-to-end open source machine learning platform for everyone. Discover TensorFlow's flexible ecosystem of tools, libraries and community resources.},
  langid = {english},
  organization = {TensorFlow}
}

@article{thabitComparativeAnalysisArabic2021,
  title = {A {{Comparative Analysis}} of {{Arabic Text Steganography}}},
  author = {Thabit, Reema and Udzir, Nur Izura and Yasin, Sharifah Md and Asmawi, Aziah and Roslan, Nuur Alifah and Din, Roshidi},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {15},
  pages = {6851},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app11156851},
  url = {https://www.mdpi.com/2076-3417/11/15/6851},
  urldate = {2025-03-12},
  abstract = {Protecting sensitive information transmitted via public channels is a significant issue faced by governments, militaries, organizations, and individuals. Steganography protects the secret information by concealing it in a transferred object such as video, audio, image, text, network, or DNA. As text uses low bandwidth, it is commonly used by Internet users in their daily activities, resulting a vast amount of text messages sent daily as social media posts and documents. Accordingly, text is the ideal object to be used in steganography, since hiding a secret message in a text makes it difficult for the attacker to detect the hidden message among the massive text content on the Internet. Language’s characteristics are utilized in text steganography. Despite the richness of the Arabic language in linguistic characteristics, only a few studies have been conducted in Arabic text steganography. To draw further attention to Arabic text steganography prospects, this paper reviews the classifications of these methods from its inception. For analysis, this paper presents a comprehensive study based on the key evaluation criteria (i.e., capacity, invisibility, robustness, and security). It opens new areas for further research based on the trends in this field.},
  issue = {15},
  langid = {english}
}

@inproceedings{thakkarDeepfakesDigitalTruths2024,
  title = {From {{Deepfakes}} to {{Digital Truths}}: {{The Role}} of {{Watermarking}} in {{AI-Generated Image Verification}}},
  shorttitle = {From {{Deepfakes}} to {{Digital Truths}}},
  booktitle = {2024 47th {{International Conference}} on {{Telecommunications}} and {{Signal Processing}} ({{TSP}})},
  author = {Thakkar, Jinal Jagdishkumar and Kaur, Arashdeep},
  date = {2024-07},
  pages = {216--222},
  issn = {2768-3311},
  doi = {10.1109/TSP63128.2024.10605975},
  url = {https://ieeexplore.ieee.org/abstract/document/10605975},
  urldate = {2025-03-31},
  abstract = {The evolution of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) has introduced deepfake technology. Deepfake technology is a form of digital manipulation that alters video, image, and audio content with the help of Generative AI. Those deepfakes have increased concerns in various fields, including education, art, and they also raise ethical and security concerns due to their potential for deceptive content. Reviewing the increasing challenge of identifying high-quality deepfakes, there's a pressing need for robust measures to counter them. This review explores various watermarking techniques and their use to protect content authenticity and origin. Watermarking embeds a subtle watermark and provides a strong defense against deepfake technologies and similar AI-driven tools. The paper discusses current watermarking methods, their strengths and weaknesses, and potential improvements to verify AI-generated content.},
  eventtitle = {2024 47th {{International Conference}} on {{Telecommunications}} and {{Signal Processing}} ({{TSP}})}
}

@online{tianDebugBenchEvaluatingDebugging2024,
  title = {{{DebugBench}}: {{Evaluating Debugging Capability}} of {{Large Language Models}}},
  shorttitle = {{{DebugBench}}},
  author = {Tian, Runchu and Ye, Yining and Qin, Yujia and Cong, Xin and Lin, Yankai and Pan, Yinxu and Wu, Yesai and Hui, Haotian and Liu, Weichuan and Liu, Zhiyuan and Sun, Maosong},
  date = {2024-06-06},
  eprint = {2401.04621},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.04621},
  url = {http://arxiv.org/abs/2401.04621},
  urldate = {2025-03-24},
  abstract = {Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs' debugging ability are significantly limited by the risk of data leakage, the scale of the dataset, and the variety of tested bugs. To overcome these deficiencies, we introduce `DebugBench', an LLM debugging benchmark consisting of 4,253 instances. It covers four major bug categories and 18 minor types in C++, Java, and Python. To construct DebugBench, we collect code snippets from the LeetCode community, implant bugs into source data with GPT-4, and assure rigorous quality checks. We evaluate two commercial and four open-source models in a zero-shot scenario. We find that (1) while closed-source models exhibit inferior debugging performance compared to humans, open-source models relatively lower pass rate scores; (2) the complexity of debugging notably fluctuates depending on the bug category; (3) incorporating runtime feedback has a clear impact on debugging performance which is not always helpful. As an extension, we also compare LLM debugging and code generation, revealing a strong correlation between them for closed-source models. These findings will benefit the development of LLMs in debugging.},
  pubstate = {prepublished}
}

@article{titcombMillionsPeoplesDNA2025,
  entrysubtype = {newspaper},
  title = {Millions of People’s {{DNA}} up for Sale as {{23andMe}} Goes Bankrupt},
  author = {Titcomb, James},
  date = {2025-03-24},
  journaltitle = {The Telegraph},
  issn = {0307-1235},
  url = {https://www.telegraph.co.uk/business/2025/03/24/millions-of-peoples-dna-up-for-sale-as-23andme-goes-bankrup/},
  urldate = {2025-03-26},
  abstract = {Customers urged to consider deleting their data after genetic testing company collapses},
  langid = {british}
}

@article{tizardVoiceUsersExtended2022,
  title = {Voice of the Users: An Extended Study of Software Feedback Engagement},
  shorttitle = {Voice of the Users},
  author = {Tizard, James and Rietz, Tim and Liu, Xuanhui and Blincoe, Kelly},
  date = {2022-09-01},
  journaltitle = {Requirements Engineering},
  shortjournal = {Requirements Eng},
  volume = {27},
  number = {3},
  pages = {293--315},
  issn = {1432-010X},
  doi = {10.1007/s00766-021-00357-1},
  url = {https://doi.org/10.1007/s00766-021-00357-1},
  urldate = {2025-04-29},
  abstract = {Many software users give feedback online about the applications they use. This feedback often contains valuable requirements information that can be used to guide the effective maintenance and evolution of a software product. Yet, not all software users give online feedback. If the demographics of a user-base aren’t fairly represented, there is a danger that the needs of less vocal users won’t be considered in development. This work investigates feedback on three prominent online channels: app stores, product forums, and social media. We directly survey software users about their feedback habits, as well as what motivates and dissuades them from providing feedback online. In an initial survey of 1040 software users, we identify statistically significant differences in the demographics of users who give feedback (gender, age, etc.), and key differences in what motivates them to engage with each of the three studied channels. In a second survey of 936 software users, we identify the top reasons users don’t give feedback, including significant differences between demographic groups. We also present a detailed list of user-rated methods to encourage their feedback. This work provides meaningful context for requirements sourced from online feedback, identifying demographic groups who are underrepresented. Findings on what motivates and discourages user feedback give insight into how feedback channels and developers can increase engagement with their user-base.},
  langid = {english}
}

@online{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  date = {2023-02-27},
  eprint = {2302.13971},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.13971},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2025-03-28},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
  pubstate = {prepublished}
}

@inproceedings{traperoIntegratedTheoryChatbot2020,
  title = {An {{Integrated Theory}} for {{Chatbot Use}} in {{Air Travel}}: {{Questionnaire Development}} and {{Validation}}},
  shorttitle = {An {{Integrated Theory}} for {{Chatbot Use}} in {{Air Travel}}},
  booktitle = {2020 {{IEEE REGION}} 10 {{CONFERENCE}} ({{TENCON}})},
  author = {Trapero, Hazel and Ilao, Joel and Lacaza, Rutcher},
  date = {2020-11},
  pages = {652--657},
  issn = {2159-3450},
  doi = {10.1109/TENCON50793.2020.9293710},
  url = {https://ieeexplore.ieee.org/abstract/document/9293710},
  urldate = {2025-04-10},
  abstract = {Airline industry is a major global leader in aviation which has made the world an alluring smaller place with an enormous level of mobility and accessibility. It even provides service to almost every other sector, however, it does not receive significant attention, despite its importance. Moreover, its service quality is an aggregate of different interactions between the customers and airline companies. This drove them to implement new business model to conform to the new competitive atmosphere in the industry whose operation is taking place in a completely globalized environment. Thus, the use of chatbots is one of the avenues to meet this end. However, there is a dearth of standardized and validated instrument that best fit to evaluate the use of chatbots in the airline industry based on the combined set of constructs as identified in the conceptual framework. Thus, this study aims to develop and validate an instrument that will evaluate the adoption of chatbots in a service industry, like the airline industry, as well as its non-adoption. Based on the reliability and internal consistency evaluation, only one item was deleted (PIIT construct) since it has the lowest item-test correlation that caused the reliability coefficient to be less than the suggested value of 0.70. All statements in each of the constructs had positive signs, thus, were not reversely worded. Lastly, all the scale reliability coefficient or the overall alpha values are way higher than the suggested value, which means that the internal consistency is either acceptable or highly acceptable.},
  eventtitle = {2020 {{IEEE REGION}} 10 {{CONFERENCE}} ({{TENCON}})}
}

@article{traynorMerkelComparedNSA2013,
  entrysubtype = {newspaper},
  title = {Merkel Compared {{NSA}} to {{Stasi}} in Heated Encounter with {{Obama}}},
  author = {Traynor, Ian and Lewis, Paul},
  date = {2013-12-17T18:23:22},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2013/dec/17/merkel-compares-nsa-stasi-obama},
  urldate = {2025-03-26},
  abstract = {German chancellor furious after revelations US intelligence agency listened in on her personal mobile phone},
  journalsubtitle = {World news},
  langid = {british}
}

@online{turnerIntroductionTransformers2024,
  title = {An {{Introduction}} to {{Transformers}}},
  author = {Turner, Richard E.},
  date = {2024-02-08},
  eprint = {2304.10557},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.10557},
  url = {http://arxiv.org/abs/2304.10557},
  urldate = {2025-03-12},
  abstract = {The transformer is a neural network component that can be used to learn useful representations of sequences or sets of data-points. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture. We will not discuss training as this is rather standard. We assume that the reader is familiar with fundamental topics in machine learning including multi-layer perceptrons, linear transformations, softmax functions and basic probability.},
  pubstate = {prepublished},
  version = {5}
}

@article{ueberwasserWhatsSwitzerlandCorpusbased2017,
  title = {What’s up, Switzerland? A corpus-based research project in a multilingual country},
  shorttitle = {What’s up, Switzerland?},
  author = {Ueberwasser, Simone and Stark, Elisabeth},
  date = {2017-09-17},
  journaltitle = {Linguistik Online},
  volume = {84},
  number = {5},
  issn = {1615-3014},
  doi = {10.13092/lo.84.3849},
  url = {https://bop.unibe.ch/linguistik-online/article/view/3849},
  urldate = {2025-04-05},
  abstract = {This paper offers some initial insights into the first large-scale and multilingual corpus of WhatsApp messages for linguistic research and the related research project “What’s up, Swit-zerland?”. Data was gathered in Switzerland in the summer of 2014 and will be made availa-ble to the academic public online at the end of the project (end of 2018). This article presents facts and figures about the corpus and the participants’ demographic data as well as an over-view of (the lack of) existing linguistic research in the field and the research intended in the SNSF-funded research project.},
  issue = {5},
  langid = {ngerman}
}

@online{united4iranNahoft2021,
  title = {Nahoft},
  author = {{United 4 Iran}},
  date = {2021},
  url = {https://nahoftapp.com/index-en.html},
  urldate = {2025-03-11}
}

@software{united4iranU4iadminNahoft2025,
  title = {U4i-Admin/{{Nahoft}}},
  author = {{United 4 Iran}},
  date = {2025-01-09T21:35:47Z},
  origdate = {2021-07-22T16:06:15Z},
  url = {https://github.com/u4i-admin/Nahoft},
  urldate = {2025-03-24},
  organization = {U4I}
}

@software{vali-98Vali98ChatterUI2025,
  title = {Vali-98/{{ChatterUI}}},
  author = {{Vali-98}},
  date = {2025-03-11T17:42:50Z},
  origdate = {2023-10-18T11:28:06Z},
  url = {https://github.com/Vali-98/ChatterUI},
  urldate = {2025-03-11},
  abstract = {Simple frontend for LLMs built in react-native.}
}

@online{vandersarMetaTorrented812025,
  title = {'{{Meta Torrented}} over 81 {{TB}} of {{Data Through Anna}}'s {{Archive}}, {{Despite Few Seeders}}' * {{TorrentFreak}}},
  author = {Van der Sar, Ernesto},
  date = {2025-02-06},
  url = {https://torrentfreak.com/meta-torrented-over-81-tb-of-data-through-annas-archive-despite-few-seeders-250206/},
  urldate = {2025-03-19}
}

@online{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2023-08-02},
  eprint = {1706.03762},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2024-12-28},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {prepublished}
}

@online{vendrowLargeLanguageModel2025,
  title = {Do {{Large Language Model Benchmarks Test Reliability}}?},
  author = {Vendrow, Joshua and Vendrow, Edward and Beery, Sara and Madry, Aleksander},
  date = {2025-02-05},
  eprint = {2502.03461},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.03461},
  url = {http://arxiv.org/abs/2502.03461},
  urldate = {2025-03-24},
  abstract = {When deploying large language models (LLMs), it is important to ensure that these models are not only capable, but also reliable. Many benchmarks have been created to track LLMs' growing capabilities, however there has been no similar focus on measuring their reliability. To understand the potential ramifications of this gap, we investigate how well current benchmarks quantify model reliability. We find that pervasive label errors can compromise these evaluations, obscuring lingering model failures and hiding unreliable behavior. Motivated by this gap in the evaluation of reliability, we then propose the concept of so-called platinum benchmarks, i.e., benchmarks carefully curated to minimize label errors and ambiguity. As a first attempt at constructing such benchmarks, we revise examples from fifteen existing popular benchmarks. We evaluate a wide range of models on these platinum benchmarks and find that, indeed, frontier LLMs still exhibit failures on simple tasks such as elementary-level math word problems. Analyzing these failures further reveals previously unidentified patterns of problems on which frontier models consistently struggle. We provide code at https://github.com/MadryLab/platinum-benchmarks},
  pubstate = {prepublished}
}

@inproceedings{verheijenCollectingFacebookPosts2016,
  title = {Collecting {{Facebook Posts}} and {{WhatsApp Chats}}},
  booktitle = {Text, {{Speech}}, and {{Dialogue}}},
  author = {Verheijen, Lieke and Stoop, Wessel},
  editor = {Sojka, Petr and Horák, Aleš and Kopeček, Ivan and Pala, Karel},
  date = {2016},
  pages = {249--258},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-45510-5_29},
  abstract = {This paper describes the compilation of a social media corpus with Facebook posts and WhatsApp chats. Authentic messages were voluntarily donated by Dutch youths between 12 and 23 years old. Social media nowadays constitute a fundamental part of youths’ private lives, constantly connecting them to friends and family via computer-mediated communication (CMC). The social networking site Facebook and mobile phone chat application WhatsApp are currently quite popular in the Netherlands. Several relevant issues concerning corpus compilation are discussed, including website creation, promotion, metadata collection, and intellectual property rights/ethical approval. The application that was created for scraping Facebook posts from users’ timelines, of course with their consent, can serve as an example for future data collection. The Facebook and WhatsApp messages are collected for a sociolinguistic study into Dutch youths’ written CMC, of which a preliminary analysis is presented, but also present a valuable data source for further research.},
  isbn = {978-3-319-45510-5},
  langid = {english}
}

@article{volkerTunedSendersSelfrevelation2021,
  title = {Tuned in on Senders’ Self-Revelation: {{Emojis}} and Emotional Intelligence Influence Interpretation of {{WhatsApp}} Messages},
  shorttitle = {Tuned in on Senders’ Self-Revelation},
  author = {Völker, Juliane and Mannheim, Carolin},
  date = {2021-01-01},
  journaltitle = {Computers in Human Behavior Reports},
  shortjournal = {Computers in Human Behavior Reports},
  volume = {3},
  pages = {100062},
  issn = {2451-9588},
  doi = {10.1016/j.chbr.2021.100062},
  url = {https://www.sciencedirect.com/science/article/pii/S2451958821000105},
  urldate = {2025-04-10},
  abstract = {Emojis function like nonverbal cues in digital communication, but how do they impact the meaning of a message? We tested experimentally (N~\hspace{0pt}=~\hspace{0pt}50) if the presence of emojis in WhatsApp messages influences their interpretation as either factual information, self-revelation of the sender, relationship information, or an appeal (“four-ears model”). Messages were most frequently interpretated as self-revelation, especially if they contained an emoji, whereas sole text messages were equally as frequently perceived as either self-revelation or factual information. The interpretation of messages with or without emojis interacted with whether their content was positive or negative. Additionally, recipient’s emotional intelligence both as an ability (cognitive measure) and trait (personality measure) was associated with interpreting self-revelation, but only in emoji messages. Emojis may thus provide the cues necessary to extract emotional information from text-based messages, to which emotionally intelligent recipients seem to be especially responsive.}
}

@article{wangELIZAChatGPTBrief2024,
  title = {From {{ELIZA}} to {{ChatGPT}}: {{A}} Brief History of Chatbots and Their Evolution},
  shorttitle = {From {{ELIZA}} to {{ChatGPT}}},
  author = {Wang, Kaicheng},
  date = {2024-02-21},
  journaltitle = {Applied and Computational Engineering},
  volume = {39},
  pages = {57--62},
  issn = {2755-273X},
  doi = {10.54254/2755-2721/39/20230579},
  url = {https://www.ewadirect.com/proceedings/ace/article/view/10185},
  urldate = {2025-03-27},
  abstract = {Over the years, chatbots have grown to be used in a variety of industries. From their humble beginnings to their current prominence, chatbots have come a long way. From the earliest chatbot ELIZA in the 1960s to today’s popular Chatgpt, chatbot language models, codes, and databases have improved greatly with the advancement of artificial intelligence technology.This paper introduces the development of chatbots through literature review and theoretical analysis. It also analyzes and summarizes the advantages and challenges of chatbots according to the current status of chatbot applications and social needs. Personalized interaction will be an important development direction for chatbots, because providing personalized responses through user data analysis can provide users with a personalized experience, thus increasing user engagement and satisfaction.},
  langid = {english}
}

@online{wangHistoryDevelopmentPrinciples2024,
  title = {History, {{Development}}, and {{Principles}} of {{Large Language Models-An Introductory Survey}}},
  author = {Wang, Zichong and Chu, Zhibo and Doan, Thang Viet and Ni, Shiwen and Yang, Min and Zhang, Wenbin},
  date = {2024-09-23},
  eprint = {2402.06853},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.06853},
  url = {http://arxiv.org/abs/2402.06853},
  urldate = {2025-03-19},
  abstract = {Language models serve as a cornerstone in natural language processing (NLP), utilizing mathematical methods to generalize language laws and knowledge for prediction and generation. Over extensive research spanning decades, language modeling has progressed from initial statistical language models (SLMs) to the contemporary landscape of large language models (LLMs). Notably, the swift evolution of LLMs has reached the ability to process, understand, and generate human-level text. Nevertheless, despite the significant advantages that LLMs offer in improving both work and personal lives, the limited understanding among general practitioners about the background and principles of these models hampers their full potential. Notably, most LLM reviews focus on specific aspects and utilize specialized language, posing a challenge for practitioners lacking relevant background knowledge. In light of this, this survey aims to present a comprehensible overview of LLMs to assist a broader audience. It strives to facilitate a comprehensive understanding by exploring the historical background of language models and tracing their evolution over time. The survey further investigates the factors influencing the development of LLMs, emphasizing key contributions. Additionally, it concentrates on elucidating the underlying principles of LLMs, equipping audiences with essential theoretical knowledge. The survey also highlights the limitations of existing work and points out promising future directions.},
  pubstate = {prepublished}
}

@article{wangUserBehaviorSimulation2025,
  title = {User {{Behavior Simulation}} with {{Large Language Model-based Agents}}},
  author = {Wang, Lei and Zhang, Jingsen and Yang, Hao and Chen, Zhi-Yuan and Tang, Jiakai and Zhang, Zeyu and Chen, Xu and Lin, Yankai and Sun, Hao and Song, Ruihua and Zhao, Xin and Xu, Jun and Dou, Zhicheng and Wang, Jun and Wen, Ji-Rong},
  date = {2025-01-28},
  journaltitle = {ACM Trans. Inf. Syst.},
  volume = {43},
  number = {2},
  pages = {55:1--55:37},
  issn = {1046-8188},
  doi = {10.1145/3708985},
  url = {https://dl.acm.org/doi/10.1145/3708985},
  urldate = {2025-04-10},
  abstract = {Simulating high quality user behavior data has always been a fundamental yet challenging problem in human-centered applications such as recommendation systems, social networks, among many others. The major difficulty of user behavior simulation originates from the intricate mechanism of human cognitive and decision processes. Recently, substantial evidence has suggested that by learning huge amounts of web knowledge, large language models (LLMs) can achieve human-like intelligence and generalization capabilities. Inspired by such capabilities, in this article, we take an initial step to study the potential of using LLMs for user behavior simulation in the recommendation domain. To make LLMs act like humans, we design profile, memory and action modules to equip them, building LLM-based agents to simulate real users. To enable interactions between different agents and observe their behavior patterns, we design a sandbox environment, where each agent can interact with the recommendation system, and different agents can converse with their friends via one-to-one chatting or one-to-many social broadcasting. In the experiments, we first demonstrate the believability of the agent-generated behaviors based on both subjective and objective evaluations. Then, to show the potential applications of our method, we simulate and study two social phenomena including (1) information cocoons and (2) user conformity behaviors. We find that controlling the personalization degree of recommendation algorithms and improving the heterogeneity of user social relations can be two effective strategies for alleviating the problem of information cocoon, and the conformity behaviors can be highly influenced by the amount of user social relations. To advance this direction, we have released our project at .}
}

@article{watkinsSteganographyMessagesHidden2001,
  title = {Steganography – {{Messages Hidden}} in {{Bits}}},
  author = {Watkins, Jonathan},
  date = {2001},
  journaltitle = {Multimedia Systems Coursework, Dept of Electronics and CS, University of Southampton, SO17 1BJ, UK},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=8c4c24eac97067ee16d8ecdc999cacb7f62c068c},
  abstract = {Steganography is the process of hiding one medium of communication (text, sound or image) within another. This paper will discuss the tools used to both hide and unhide (know as Steganalysis) information. A look at the history starting with Herodotus in ancient Greece describing secret messages written in wax on stone tablets, to world war two’s secret double meaning Nazi messages and British Intelligences invisible ink. Most recently the techniques have been accredited with Osama Bin Laden's Al-Qa’eda terrorist network. Not all of Steganography involves some kind of subterfuge, I will also cover the area of digital watermarking, a method to try to protect the copyright of image.},
  langid = {english}
}

@article{waynerMimicFunctions1992,
  title = {Mimic {{Functions}}},
  author = {Wayner, Peter},
  date = {1992-07-01},
  journaltitle = {Cryptologia},
  volume = {16},
  number = {3},
  pages = {193--214},
  publisher = {Taylor \& Francis},
  issn = {0161-1194},
  doi = {10.1080/0161-119291866883},
  url = {https://doi.org/10.1080/0161-119291866883},
  urldate = {2025-03-16},
  abstract = {A mimic function changes a file A so it assumes the statistical properties of another file B. That is, if p(t, A) is the probability of some substring t occurring in A, then a mimic function f, recodes A so that p(t, f(A)) approximates p(t, B) for all strings t of length less than some n. This paper describes the algorithm for computing mimic functions and compares the algorithm with its functional inverse, Huffman coding. The paper also provides a description of more robust and more general mimic functions which can be defined using context-free grammars and van Wijngaarden grammars.}
}

@online{weiHiddenPlainSight2024,
  title = {Hidden in {{Plain Sight}}: {{Exploring Chat History Tampering}} in {{Interactive Language Models}}},
  shorttitle = {Hidden in {{Plain Sight}}},
  author = {Wei, Cheng'an and Zhao, Yue and Gong, Yujia and Chen, Kai and Xiang, Lu and Zhu, Shenchen},
  date = {2024-09-06},
  eprint = {2405.20234},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.20234},
  url = {http://arxiv.org/abs/2405.20234},
  urldate = {2025-04-03},
  abstract = {Large Language Models (LLMs) such as ChatGPT and Llama have become prevalent in real-world applications, exhibiting impressive text generation performance. LLMs are fundamentally developed from a scenario where the input data remains static and unstructured. To behave interactively, LLM-based chat systems must integrate prior chat history as context into their inputs, following a pre-defined structure. However, LLMs cannot separate user inputs from context, enabling chat history tampering. This paper introduces a systematic methodology to inject user-supplied history into LLM conversations without any prior knowledge of the target model. The key is to utilize prompt templates that can well organize the messages to be injected, leading the target LLM to interpret them as genuine chat history. To automatically search for effective templates in a WebUI black-box setting, we propose the LLM-Guided Genetic Algorithm (LLMGA) that leverages an LLM to generate and iteratively optimize the templates. We apply the proposed method to popular real-world LLMs including ChatGPT and Llama-2/3. The results show that chat history tampering can enhance the malleability of the model's behavior over time and greatly influence the model output. For example, it can improve the success rate of disallowed response elicitation up to 97\% on ChatGPT. Our findings provide insights into the challenges associated with the real-world deployment of interactive LLMs.},
  pubstate = {prepublished}
}

@article{weiJailbrokenHowDoes2023,
  title = {Jailbroken: {{How Does LLM Safety Training Fail}}?},
  shorttitle = {Jailbroken},
  author = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {80079--80110},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/fd6613131889a4b656206c50a8bd7790-Abstract-Conference.html},
  urldate = {2025-03-12},
  langid = {english}
}

@article{weizenbaumELIZAComputerProgram1966,
  title = {{{ELIZA}}—a Computer Program for the Study of Natural Language Communication between Man and Machine},
  author = {Weizenbaum, Joseph},
  date = {1966-01-01},
  journaltitle = {Commun. ACM},
  volume = {9},
  number = {1},
  pages = {36--45},
  issn = {0001-0782},
  doi = {10.1145/365153.365168},
  url = {https://dl.acm.org/doi/10.1145/365153.365168},
  urldate = {2025-03-27}
}

@online{whiteModelOpennessFramework2024,
  title = {The {{Model Openness Framework}}: {{Promoting Completeness}} and {{Openness}} for {{Reproducibility}}, {{Transparency}}, and {{Usability}} in {{Artificial Intelligence}}},
  shorttitle = {The {{Model Openness Framework}}},
  author = {White, Matt and Haddad, Ibrahim and Osborne, Cailean and Liu, Xiao-Yang Yanglet and Abdelmonsef, Ahmed and Varghese, Sachin and Hors, Arnaud Le},
  date = {2024-10-18},
  eprint = {2403.13784},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.13784},
  url = {http://arxiv.org/abs/2403.13784},
  urldate = {2025-03-28},
  abstract = {Generative artificial intelligence (AI) offers numerous opportunities for research and innovation, but its commercialization has raised concerns about the transparency and safety of frontier AI models. Most models lack the necessary components for full understanding, auditing, and reproducibility, and some model producers use restrictive licenses whilst claiming that their models are "open source". To address these concerns, we introduce the Model Openness Framework (MOF), a three-tiered ranked classification system that rates machine learning models based on their completeness and openness, following open science principles. For each MOF class, we specify code, data, and documentation components of the model development lifecycle that must be released and under which open licenses. In addition, the Model Openness Tool (MOT) provides a user-friendly reference implementation to evaluate the openness and completeness of models against the MOF classification system. Together, the MOF and MOT provide timely practical guidance for (i) model producers to enhance the openness and completeness of their publicly-released models, and (ii) model consumers to identify open models and their constituent components that can be permissively used, studied, modified, and redistributed. Through the MOF, we seek to establish completeness and openness as core tenets of responsible AI research and development, and to promote best practices in the burgeoning open AI ecosystem.},
  pubstate = {prepublished}
}

@article{wilsonFundamentalCybersecurityConcepts2014,
  title = {Some {{Fundamental Cybersecurity Concepts}}},
  author = {Wilson, Kelce S. and Kiy, Müge Ayse},
  date = {2014},
  journaltitle = {IEEE Access},
  volume = {2},
  pages = {116--124},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2014.2305658},
  url = {https://ieeexplore.ieee.org/abstract/document/6737236},
  urldate = {2025-03-28},
  abstract = {The results of successful hacking attacks against commercially available cybersecurity protection tools that had been touted as secure are distilled into a set of concepts that are applicable to many protection planning scenarios. The concepts, which explain why trust in those systems was misplaced, provides a framework for both analyzing known exploits and also evaluating proposed protection systems for predicting likely potential vulnerabilities. The concepts are: 1) differentiating security threats into distinct classes; 2) a five layer model of computing systems; 3) a payload versus protection paradigm; and 4) the nine Ds of cybersecurity, which present practical defensive tactics in an easily remembered scheme. An eavesdropping risk, inherent in many smartphones and notebook computers, is described to motivate improved practices and demonstrate real-world application of the concepts to predicting new vulnerabilities. Additionally, the use of the nine Ds is demonstrated as analysis tool that permits ranking of the expected effectiveness of some potential countermeasures.},
  eventtitle = {{{IEEE Access}}}
}

@software{wolfTransformersStateoftheArtNatural2020,
  title = {Transformers: {{State-of-the-Art Natural Language Processing}}},
  shorttitle = {Transformers},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Perric and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  date = {2020-10},
  origdate = {2018-10-29T13:56:00Z},
  pages = {38--45},
  url = {https://www.aclweb.org/anthology/2020.emnlp-demos.6},
  urldate = {2025-03-29},
  abstract = {🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.},
  organization = {Association for Computational Linguistics}
}

@article{wongSocialMediaMay2016,
  entrysubtype = {newspaper},
  title = {Social Media May Have Been Blocked during {{Turkey}} Coup Attempt},
  author = {Wong, Julia Carrie},
  date = {2016-07-15T23:25:09},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2016/jul/15/turkey-blocking-social-facebook-twitter-youtube},
  urldate = {2025-03-24},
  abstract = {Reports emerge during attempted military coup of people struggling to access social media in a country described as a ‘bastion of internet censorship’},
  journalsubtitle = {World news},
  langid = {british}
}

@inproceedings{wuGenerativeTextSteganography2024,
  title = {Generative {{Text Steganography}} with {{Large Language Model}}},
  booktitle = {Proceedings of the 32nd {{ACM International Conference}} on {{Multimedia}}},
  author = {Wu, Jiaxuan and Wu, Zhengxian and Xue, Yiming and Wen, Juan and Peng, Wanli},
  date = {2024-10-28},
  eprint = {2404.10229},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {10345--10353},
  doi = {10.1145/3664647.3680562},
  url = {http://arxiv.org/abs/2404.10229},
  urldate = {2025-03-12},
  abstract = {Recent advances in large language models (LLMs) have blurred the boundary of high-quality text generation between humans and machines, which is favorable for generative text steganography. While, current advanced steganographic mapping is not suitable for LLMs since most users are restricted to accessing only the black-box API or user interface of the LLMs, thereby lacking access to the training vocabulary and its sampling probabilities. In this paper, we explore a black-box generative text steganographic method based on the user interfaces of large language models, which is called LLM-Stega. The main goal of LLM-Stega is that the secure covert communication between Alice (sender) and Bob (receiver) is conducted by using the user interfaces of LLMs. Specifically, We first construct a keyword set and design a new encrypted steganographic mapping to embed secret messages. Furthermore, to guarantee accurate extraction of secret messages and rich semantics of generated stego texts, an optimization mechanism based on reject sampling is proposed. Comprehensive experiments demonstrate that the proposed LLM-Stega outperforms current state-of-the-art methods.}
}

@article{wuPromptingSteganographyNew2024,
  title = {Prompting {{Steganography}}: {{A New Paradigm}}},
  shorttitle = {Prompting {{Steganography}}},
  author = {Wu, Hanzhou},
  date = {2024-01-21},
  journaltitle = {Electronic Imaging},
  volume = {36},
  pages = {1--11},
  publisher = {{Society for Imaging Science and Technology}},
  issn = {2470-1173},
  doi = {10.2352/EI.2024.36.4.MWSF-338},
  url = {https://library.imaging.org/ei/articles/36/4/MWSF-338},
  urldate = {2025-03-12},
  abstract = {Abstract Recent studies show that scaling pre-trained language models can lead to a significantly improved model capacity on downstream tasks, resulting in a new research direction called large language models (LLMs). A remarkable application of LLMs is ChatGPT, which is a powerful large language model capable of generating human-like text based on context and past conversations. It is demonstrated that LLMs have impressive skills in reasoning, especially when using prompting strategies. In this paper, we explore the possibility of applying LLMs to the field of steganography, which is referred to as the art of hiding secret data into an innocent cover for covert communication. Our purpose is not to combine an LLM into an already designed steganographic system to boost the performance, which follows the conventional framework of steganography. Instead, we expect that, through prompting, an LLM can realize steganography by itself, which is defined as prompting steganography and may be a new paradigm of steganography. We show that, by reasoning, an LLM can embed secret data into a cover, and extract secret data from a stego, with an error rate. This error rate, however, can be reduced by optimizing the prompt, which may shed light on further research.},
  langid = {english}
}

@article{wuUnveilingSecurityPrivacy2024,
  title = {Unveiling Security, Privacy, and Ethical Concerns of {{ChatGPT}}},
  author = {Wu, Xiaodong and Duan, Ran and Ni, Jianbing},
  date = {2024-03-01},
  journaltitle = {Journal of Information and Intelligence},
  shortjournal = {Journal of Information and Intelligence},
  volume = {2},
  number = {2},
  pages = {102--115},
  issn = {2949-7159},
  doi = {10.1016/j.jiixd.2023.10.007},
  url = {https://www.sciencedirect.com/science/article/pii/S2949715923000707},
  urldate = {2025-03-27},
  abstract = {This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.}
}

@article{xiangGenerativeLinguisticSteganography2022,
  title = {Generative {{Linguistic Steganography}}: {{A Comprehensive Review}}},
  shorttitle = {Generative {{Linguistic Steganography}}},
  author = {Xiang, Lingyun and Wang, Rong and Yang, Zhongliang and Liu, Yuling},
  date = {2022},
  journaltitle = {KSII Transactions on Internet and Information Systems (TIIS)},
  volume = {16},
  number = {3},
  pages = {986--1005},
  publisher = {Korean Society for Internet Information},
  issn = {1976-7277},
  doi = {10.3837/tiis.2022.03.013},
  url = {https://koreascience.kr/article/JAKO202211563864037.page},
  urldate = {2025-03-13},
  abstract = {Text steganography is one of the most imminent and promising research interests in the information security field. With the unprecedented success of the neural network and natural language processing (NLP), the last years have seen a surge of research on generative linguistic steganography (GLS). This paper provides a thorough and comprehensive review to summarize the existing key contributions, and creates a novel taxonomy for GLS according to NLP techniques and steganographic encoding algorithm, then summarizes the characteristics of generative linguistic steganographic methods properly to analyze the relationship and difference between each type of them. Meanwhile, this paper also comprehensively introduces and analyzes several evaluation metrics to evaluate the performance of GLS from diverse perspective. Finally, this paper concludes the future research work, which is more conducive to the follow-up research and innovation of researchers.},
  langid = {english}
}

@inproceedings{xingAssessingEfficacyInvisible2024,
  title = {Assessing the {{Efficacy}} of {{Invisible Watermarks}} in {{AI-Generated Medical Images}}},
  booktitle = {2024 {{IEEE International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  author = {Xing, Xiaodan and Zhou, Huiyu and Fang, Yingying and Yang, Guang},
  date = {2024-05},
  pages = {1--5},
  issn = {1945-8452},
  doi = {10.1109/ISBI56570.2024.10635746},
  url = {https://ieeexplore.ieee.org/abstract/document/10635746},
  urldate = {2025-03-31},
  abstract = {AI-generated medical images are gaining growing popularity due to their potential to address the data scarcity challenge in the real world. However, the issue of accurate identification of these synthetic images, particularly when they exhibit remarkable realism with their real copies, remains a concern. To mitigate this challenge, image generators such as DALLE and Imagen, have integrated digital watermarks aimed at facilitating the discernment of synthetic images’ authenticity. These watermarks are embedded within the image pixels and are invisible to the human eye while remains their detectability. Nevertheless, a comprehensive investigation into the potential impact of these invisible watermarks on the utility of synthetic medical images has been lacking. In this study, we propose the incorporation of invisible watermarks into synthetic medical images and seek to evaluate their efficacy in the context of downstream classification tasks. Our goal is to pave the way for discussions on the viability of such watermarks in boosting the detectability of synthetic medical images, fortifying ethical standards, and safeguarding against data pollution and potential scams.},
  eventtitle = {2024 {{IEEE International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})}
}

@online{xuGoldfishMemoryLongTerm2021,
  title = {Beyond {{Goldfish Memory}}: {{Long-Term Open-Domain Conversation}}},
  shorttitle = {Beyond {{Goldfish Memory}}},
  author = {Xu, Jing and Szlam, Arthur and Weston, Jason},
  date = {2021-07-15},
  eprint = {2107.07567},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2107.07567},
  url = {http://arxiv.org/abs/2107.07567},
  urldate = {2025-04-05},
  abstract = {Despite recent improvements in open-domain dialogue models, state of the art models are trained and evaluated on short conversations with little context. In contrast, the long-term conversation setting has hardly been studied. In this work we collect and release a human-human dataset consisting of multiple chat sessions whereby the speaking partners learn about each other's interests and discuss the things they have learnt from past sessions. We show how existing models trained on existing datasets perform poorly in this long-term conversation setting in both automatic and human evaluations, and we study long-context models that can perform much better. In particular, we find retrieval-augmented methods and methods with an ability to summarize and recall previous conversations outperform the standard encoder-decoder architectures currently considered state of the art.},
  pubstate = {prepublished}
}

@online{xuInvisMarkInvisibleRobust2024,
  title = {{{InvisMark}}: {{Invisible}} and {{Robust Watermarking}} for {{AI-generated Image Provenance}}},
  shorttitle = {{{InvisMark}}},
  author = {Xu, Rui and Hu, Mengya and Lei, Deren and Li, Yaxi and Lowe, David and Gorevski, Alex and Wang, Mingyu and Ching, Emily and Deng, Alex},
  date = {2024-11-19},
  eprint = {2411.07795},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.07795},
  url = {http://arxiv.org/abs/2411.07795},
  urldate = {2025-03-31},
  abstract = {The proliferation of AI-generated images has intensified the need for robust content authentication methods. We present InvisMark, a novel watermarking technique designed for high-resolution AI-generated images. Our approach leverages advanced neural network architectures and training strategies to embed imperceptible yet highly robust watermarks. InvisMark achieves state-of-the-art performance in imperceptibility (PSNR\$\textbackslash sim\$51, SSIM \$\textbackslash sim\$ 0.998) while maintaining over 97\textbackslash\% bit accuracy across various image manipulations. Notably, we demonstrate the successful encoding of 256-bit watermarks, significantly expanding payload capacity while preserving image quality. This enables the embedding of UUIDs with error correction codes, achieving near-perfect decoding success rates even under challenging image distortions. We also address potential vulnerabilities against advanced attacks and propose mitigation strategies. By combining high imperceptibility, extended payload capacity, and resilience to manipulations, InvisMark provides a robust foundation for ensuring media provenance in an era of increasingly sophisticated AI-generated content. Source code of this paper is available at: https://github.com/microsoft/InvisMark.},
  pubstate = {prepublished}
}

@article{yangLinguisticSteganalysisSocial2023,
  title = {Linguistic {{Steganalysis Toward Social Network}}},
  author = {Yang, Jinshuai and Yang, Zhongliang and Zou, Jiajun and Tu, Haoqin and Huang, Yongfeng},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {859--871},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3226909},
  url = {https://ieeexplore.ieee.org/abstract/document/9970400},
  urldate = {2025-03-13},
  abstract = {With the rapid development of the internet and social media, linguistic steganography can be easily abused in social networks to make considerable damage to varied aspects like personal privacy, network virus and national defense. Currently, considerable linguistic steganalysis methods are proposed to detect harmful steganographic carriers. However, almost all the existing methods fail in real social networks, since they are only devoted to the linguistic features that are extreme insufficient owing to the extreme sparsity and extreme fragmentation challenges of real social networks. In this paper, we attempt to fill the long-standing gap that the datasets and effective methods are absent for hunting steganographic texts in social network scenarios. Concretely, we construct a dataset called Stego-Sandbox to simulate the real social network scenarios, which contains texts and their relation. And we propose an effective linguistic steganalysis framework integrating linguistic features contained in texts and context features represented by these connections. Extensive experimental results demonstrate owing to the captured context features, our proposed framework can effectively compensate for shortcomings of these existing methods and tremendously improve their detection ability in real social network scenarios.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}}
}

@article{yangRNNStegaLinguisticSteganography2019,
  title = {{{RNN-Stega}}: {{Linguistic Steganography Based}} on {{Recurrent Neural Networks}}},
  shorttitle = {{{RNN-Stega}}},
  author = {Yang, Zhong-Liang and Guo, Xiao-Qing and Chen, Zi-Ming and Huang, Yong-Feng and Zhang, Yu-Jin},
  date = {2019-05},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {14},
  number = {5},
  pages = {1280--1295},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2018.2871746},
  url = {https://ieeexplore.ieee.org/document/8470163},
  urldate = {2025-01-26},
  abstract = {Linguistic steganography based on text carrier auto-generation technology is a current topic with great promise and challenges. Limited by the text automatic generation technology or the corresponding text coding methods, the quality of the steganographic text generated by previous methods is inferior, which makes its imperceptibility unsatisfactory. In this paper, we propose a linguistic steganography based on recurrent neural networks, which can automatically generate high-quality text covers on the basis of a secret bitstream that needs to be hidden. We trained our model with a large number of artificially generated samples and obtained a good estimate of the statistical language model. In the text generation process, we propose fixed-length coding and variable-length coding to encode words based on their conditional probability distribution. We designed several experiments to test the proposed model from the perspectives of information hiding efficiency, information imperceptibility, and information hidden capacity. The experimental results show that the proposed model outperforms all the previous related methods and achieves the state-of-the-art performance.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}}
}

@article{yangSeSyLinguisticSteganalysis2022,
  title = {{{SeSy}}: {{Linguistic Steganalysis Framework Integrating Semantic}} and {{Syntactic Features}}},
  shorttitle = {{{SeSy}}},
  author = {Yang, Jinshuai and Yang, Zhongliang and Zhang, Siyu and Tu, Haoqin and Huang, Yongfeng},
  date = {2022},
  journaltitle = {IEEE Signal Processing Letters},
  volume = {29},
  pages = {31--35},
  issn = {1558-2361},
  doi = {10.1109/LSP.2021.3122901},
  url = {https://ieeexplore.ieee.org/abstract/document/9591452},
  urldate = {2025-03-13},
  abstract = {With the rapid development of natural language processing technology and linguistic steganography, linguistic steganalysis gains considerable interest in recent years. Current advanced methods dominantly focus on statistical features in semantic view yet ignore syntax structure of text, which leads to limited performance to some newly statistically indistinguishable steganography algorithms. To fill this gap, in this paper, we propose a novel linguistic steganalysis framework named SeSy to integrate both semantic and syntactic features. Specifically, we propose to employ transformer-architecture language model as semantics extractor and leverage a graph attention network to retain syntactic features. Extensive experimental results show that owing to additional syntactic information, the SeSy framework effectively brings about remarkable improvement to current advanced linguistic steganalysis methods.},
  eventtitle = {{{IEEE Signal Processing Letters}}}
}

@inproceedings{yiExploitingLanguageModel2022,
  title = {Exploiting {{Language Model For Efficient Linguistic Steganalysis}}},
  booktitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Yi, Biao and Wu, Hanzhou and Feng, Guorui and Zhang, Xinpeng},
  date = {2022-05},
  pages = {3074--3078},
  issn = {2379-190X},
  doi = {10.1109/ICASSP43922.2022.9746219},
  url = {https://ieeexplore.ieee.org/abstract/document/9746219},
  urldate = {2025-03-13},
  abstract = {Recent advances in linguistic steganalysis have successively applied CNN, RNN, GNN and other efficient deep models for detecting secret information in generative texts. These methods tend to seek stronger feature extractors to achieve higher steganalysis effects. However, we have found through experiments that there actually exists significant difference between automatically generated stego texts and carrier texts in terms of the conditional probability distribution of individual words. Such kind of difference can be naturally captured by the language model used for generating stego texts. Through further experiments, we conclude that this ability can be transplanted to a text classifier by pre-training and fine-tuning to improve the detection performance. Motivated by this insight, we propose two methods for efficient linguistic steganalysis. One is to pre-train a language model based on RNN, and the other is to pre-train a sequence autoencoder. The results indicate that the two methods have different degrees of performance gain compared to the randomly initialized RNN, and the convergence speed is significantly accelerated. Moreover, our methods achieved the best performance compared to related works, while providing a solution for real-world scenario where there are more cover texts than stego texts.},
  eventtitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})}
}

@inproceedings{zamfirescu-pereiraWhyJohnnyCant2023,
  title = {Why {{Johnny Can}}’t {{Prompt}}: {{How Non-AI Experts Try}} (and {{Fail}}) to {{Design LLM Prompts}}},
  shorttitle = {Why {{Johnny Can}}’t {{Prompt}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
  date = {2023-04-19},
  series = {{{CHI}} '23},
  pages = {1--21},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3544548.3581388},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581388},
  urldate = {2025-04-03},
  abstract = {Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
  isbn = {978-1-4503-9421-5}
}

@online{zamirExcuseMeSir2024,
  title = {Excuse Me, Sir? {{Your}} Language Model Is Leaking (Information)},
  shorttitle = {Excuse Me, Sir?},
  author = {Zamir, Or},
  date = {2024-01-18},
  eprint = {2401.10360},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.10360},
  url = {http://arxiv.org/abs/2401.10360},
  urldate = {2025-03-12},
  abstract = {We introduce a cryptographic method to hide an arbitrary secret payload in the response of a Large Language Model (LLM). A secret key is required to extract the payload from the model's response, and without the key it is provably impossible to distinguish between the responses of the original LLM and the LLM that hides a payload. In particular, the quality of generated text is not affected by the payload. Our approach extends a recent result of Christ, Gunn and Zamir (2023) who introduced an undetectable watermarking scheme for LLMs.},
  pubstate = {prepublished},
  version = {1}
}

@online{zhangExtractingPromptsInverting2024,
  title = {Extracting {{Prompts}} by {{Inverting LLM Outputs}}},
  author = {Zhang, Collin and Morris, John X. and Shmatikov, Vitaly},
  date = {2024-10-08},
  eprint = {2405.15012},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.15012},
  url = {http://arxiv.org/abs/2405.15012},
  urldate = {2025-04-03},
  abstract = {We consider the problem of language model inversion: given outputs of a language model, we seek to extract the prompt that generated these outputs. We develop a new black-box method, output2prompt, that learns to extract prompts without access to the model's logits and without adversarial or jailbreaking queries. In contrast to previous work, output2prompt only needs outputs of normal user queries. To improve memory efficiency, output2prompt employs a new sparse encoding techique. We measure the efficacy of output2prompt on a variety of user and system prompts and demonstrate zero-shot transferability across different LLMs.},
  pubstate = {prepublished}
}

@online{zhangPersonalizingDialogueAgents2018,
  title = {Personalizing {{Dialogue Agents}}: {{I}} Have a Dog, Do You Have Pets Too?},
  shorttitle = {Personalizing {{Dialogue Agents}}},
  author = {Zhang, Saizheng and Dinan, Emily and Urbanek, Jack and Szlam, Arthur and Kiela, Douwe and Weston, Jason},
  date = {2018-09-25},
  eprint = {1801.07243},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1801.07243},
  url = {http://arxiv.org/abs/1801.07243},
  urldate = {2025-04-05},
  abstract = {Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i) condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.},
  pubstate = {prepublished},
  version = {5}
}

@article{zhaoInvisibleImageWatermarks2024,
  title = {Invisible {{Image Watermarks Are Provably Removable Using Generative AI}}},
  author = {Zhao, Xuandong and Zhang, Kexun and Su, Zihao and Vasan, Saastha and Grishchenko, Ilya and Kruegel, Christopher and Vigna, Giovanni and Wang, Yu-Xiang and Li, Lei},
  date = {2024-12-16},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {37},
  pages = {8643--8672},
  url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/10272bfd0371ef960ec557ed6c866058-Abstract-Conference.html},
  urldate = {2025-03-31},
  langid = {english}
}

@online{zhaoLinguaLinkedDistributedLarge2023,
  title = {{{LinguaLinked}}: {{A Distributed Large Language Model Inference System}} for {{Mobile Devices}}},
  shorttitle = {{{LinguaLinked}}},
  author = {Zhao, Junchen and Song, Yurun and Liu, Simeng and Harris, Ian G. and Jyothi, Sangeetha Abdu},
  date = {2023-12-01},
  eprint = {2312.00388},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2312.00388},
  url = {http://arxiv.org/abs/2312.00388},
  urldate = {2024-11-12},
  abstract = {Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of \$1.11\textbackslash times\$ to \$1.61\textbackslash times\$ in single-threaded settings, \$1.73\textbackslash times\$ to \$2.65\textbackslash times\$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of \$1.29\textbackslash times\$ to \$1.32\textbackslash times\$.},
  pubstate = {prepublished}
}

@online{zhaoSoKWatermarkingAIGenerated2024,
  title = {{{SoK}}: {{Watermarking}} for {{AI-Generated Content}}},
  shorttitle = {{{SoK}}},
  author = {Zhao, Xuandong and Gunn, Sam and Christ, Miranda and Fairoze, Jaiden and Fabrega, Andres and Carlini, Nicholas and Garg, Sanjam and Hong, Sanghyun and Nasr, Milad and Tramer, Florian and Jha, Somesh and Li, Lei and Wang, Yu-Xiang and Song, Dawn},
  date = {2024-12-19},
  eprint = {2411.18479},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.18479},
  url = {http://arxiv.org/abs/2411.18479},
  urldate = {2025-03-31},
  abstract = {As the outputs of generative AI (GenAI) techniques improve in quality, it becomes increasingly challenging to distinguish them from human-created content. Watermarking schemes are a promising approach to address the problem of distinguishing between AI and human-generated content. These schemes embed hidden signals within AI-generated content to enable reliable detection. While watermarking is not a silver bullet for addressing all risks associated with GenAI, it can play a crucial role in enhancing AI safety and trustworthiness by combating misinformation and deception. This paper presents a comprehensive overview of watermarking techniques for GenAI, beginning with the need for watermarking from historical and regulatory perspectives. We formalize the definitions and desired properties of watermarking schemes and examine the key objectives and threat models for existing approaches. Practical evaluation strategies are also explored, providing insights into the development of robust watermarking techniques capable of resisting various attacks. Additionally, we review recent representative works, highlight open challenges, and discuss potential directions for this emerging field. By offering a thorough understanding of watermarking in GenAI, this work aims to guide researchers in advancing watermarking methods and applications, and support policymakers in addressing the broader implications of GenAI.},
  pubstate = {prepublished}
}

@online{zhengLMSYSChat1MLargeScaleRealWorld2024,
  title = {{{LMSYS-Chat-1M}}: {{A Large-Scale Real-World LLM Conversation Dataset}}},
  shorttitle = {{{LMSYS-Chat-1M}}},
  author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Li, Tianle and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Li, Zhuohan and Lin, Zi and Xing, Eric P. and Gonzalez, Joseph E. and Stoica, Ion and Zhang, Hao},
  date = {2024-03-10},
  eprint = {2309.11998},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.11998},
  url = {http://arxiv.org/abs/2309.11998},
  urldate = {2025-04-05},
  abstract = {Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.},
  pubstate = {prepublished}
}

@inproceedings{zhouGoodbyeTextHello2017,
  title = {Goodbye {{Text}}, {{Hello Emoji}}: {{Mobile Communication}} on {{WeChat}} in {{China}}},
  shorttitle = {Goodbye {{Text}}, {{Hello Emoji}}},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zhou, Rui and Hentschel, Jasmine and Kumar, Neha},
  date = {2017-05-02},
  series = {{{CHI}} '17},
  pages = {748--759},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3025453.3025800},
  url = {https://dl.acm.org/doi/10.1145/3025453.3025800},
  urldate = {2025-04-04},
  abstract = {We present a qualitative study of mobile communication via WeChat in Southern China, focusing on the rapid proliferation of emoji and stickers and the lessening dependence on text. We use interview and observation data from 30 participants to investigate how rural, small town, and urban Chinese adults creatively and innovatively balance the use of emoji, stickers, and text in their mobile communication practices. We also discuss design implications of our research for the field of HCI, offering ways of leveraging the non-textual communication practices that we uncover, in scenarios where purely text-based communication may not suffice.},
  isbn = {978-1-4503-4655-9}
}

@article{zhouTalkingBotWall2023,
  title = {Talking to a Bot or a Wall? {{How}} Chatbots vs. Human Agents Affect Anticipated Communication Quality},
  shorttitle = {Talking to a Bot or a Wall?},
  author = {Zhou, Qi and Li, Bin and Han, Lei and Jou, Min},
  date = {2023-06-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {143},
  pages = {107674},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2023.107674},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563223000250},
  urldate = {2025-04-05},
  abstract = {Chatbots have been applied to computer-mediated communication to replace human agents due to their high efficiency and cost-effectiveness. However, their outcomes are not always desirable, and limited guidance exists on how chatbots impact users' perceptions of the communication process. Drawing on cue-filtered-out theories and multiple resource theory, this study investigated the impacts of the communicating agent (chatbot vs. human agent) on anticipated communication quality and the underlying mechanism. Two experimental studies revealed that users' anticipated communication quality was lower with chatbots than with human agents due to the serial mediating role of self-focused attention and user empathy. Moreover, moderation analyses found that a multiple-choice communication strategy for chatbots can enhance users' anticipated communication quality by impacting self-focused attention compared to an open-ended strategy. The findings contribute to the knowledge of the processes driving users’ anticipated communication quality toward chatbot applications and offer managerial implications for chatbots and communication strategies.}
}

@software{zieglerHarvardnlpNeuralSteganography2025,
  title = {Harvardnlp/{{NeuralSteganography}}},
  author = {Ziegler, Zachary M.},
  date = {2025-01-17T12:54:40Z},
  origdate = {2019-08-30T05:38:12Z},
  url = {https://github.com/harvardnlp/NeuralSteganography},
  urldate = {2025-03-11},
  abstract = {STEGASURAS: STEGanography via Arithmetic coding and Strong neURAl modelS},
  organization = {HNLP}
}

@online{zieglerNeuralLinguisticSteganography2019,
  title = {Neural {{Linguistic Steganography}}},
  author = {Ziegler, Zachary M. and Deng, Yuntian and Rush, Alexander M.},
  date = {2019-09-03},
  eprint = {1909.01496},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1909.01496},
  url = {http://arxiv.org/abs/1909.01496},
  urldate = {2024-10-30},
  abstract = {Whereas traditional cryptography encrypts a secret message into an unintelligible form, steganography conceals that communication is taking place by encoding a secret message into a cover signal. Language is a particularly pragmatic cover signal due to its benign occurrence and independence from any one medium. Traditionally, linguistic steganography systems encode secret messages in existing text via synonym substitution or word order rearrangements. Advances in neural language models enable previously impractical generation-based techniques. We propose a steganography technique based on arithmetic coding with large-scale neural language models. We find that our approach can generate realistic looking cover sentences as evaluated by humans, while at the same time preserving security by matching the cover message distribution with the language model distribution.},
  pubstate = {prepublished},
  version = {1}
}

@online{zieglerStegasuras2025,
  title = {Stegasuras},
  author = {Ziegler, Zachary M. and Deng, Yuntian and Rush, Alexander M.},
  date = {2025-03-11},
  url = {https://steganography.live/},
  urldate = {2025-03-11},
  abstract = {STEGanography via Arithmetic coding and Strong neURAl modelS},
  organization = {Stegasuras}
}
