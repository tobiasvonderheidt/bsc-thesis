% !TeX root = ../Thesis.tex

%*****************************************
\chapter{Related Work}\label{ch:relatedwork}
%*****************************************
\glsresetall % Resets all acronyms to not used

Steganography is often described as both the art and science of hiding information~\cite{bennettLinguisticSteganographySurvey2004}. As its forms are only limited by our creativity, an exhaustive discussion is not possible. Instead, we focus on some selected works. By progressing from simple to more sophisticated approaches, we ultimately answer the question: Why use \glspl{LLM} at all?

\section{Steganography without large language models}
\label{sec:steganographyWithoutLLMs}
As we implement an Android app to perform steganography in chat messages locally on smartphones, hardware resources are our strongest limitation. While \glspl{LLM} are a popular option to perform this kind of steganography~\cite{zieglerNeuralLinguisticSteganography2019}, running them is very resource-intensive. Therefore, we first consider some approaches without \glspl{LLM}.

\subsection{Mimicking}
\label{sec:mimicking}
Spammimic is a demonstration of text-based steganography without \glspl{LLM} from as early as 2001~\cite{spammimicSpammimic2000}. Secret messages are encoded into cover texts that look like spam e-mails. \cref{fig:spammimicSpamEmail} shows an example. This is done using context-free grammars and mimic functions~\cite{waynerMimicFunctions1992,bennettLinguisticSteganographySurvey2004}.

\begin{figure}
	\centering
	\captionsetup{width=\linewidth}
	\includegraphics[width=0.5\linewidth]{spammimic_spam_email.png}
	\caption[Spammimic]{Steganography in spam e-mails with Spammimic~\cite{spammimicSpammimic2000}. Only the secret message "hello world" was user input.}
	\label{fig:spammimicSpamEmail}
\end{figure}

This approach already fulfills some of the requirements we set ourselves in \cref{ch:introduction}. It generates plausible cover texts for a given topic with minimal computing resources. The topic can be chosen by exchanging the grammar~\cite{spammimicSpammimic2000}. Generating spam e-mails is particularly beneficial as it lowers an attacker's expectation of cover text quality. It allows us to hide our communication amongst other e-mail traffic, obfuscating when a secret communication is happening. We may even send our cover texts to any number of recipients that includes the intended one, to obfuscate who is communicating with whom. Both would increase an attacker's costs significantly~\cite{bennettLinguisticSteganographySurvey2004,petitcolasInformationHidingSurvey1999}.

But there are several drawbacks. Users would have to handle different grammars for different chat conversations. Creating grammars requires expert knowledge. This can't be expected from the average user. In contrast, \glspl{LLM} can be influenced by natural language commands. This can be expected from any layman user. Furthermore, encoding efficiency is low. Any secret message longer than a few words generates cover texts of implausible length, even for a spam e-mail.

\subsection{Substitution}
\label{sec:substitution}
When \gls{SMS} was prevalent, its character limits led users to abbreviate common terms (e.g. "u" for "you"). As shown in ~\cite{shirali-shahrezaTextSteganographySMS2007}, this can be leveraged to perform steganography. We define a dictionary of terms and their abbreviations and let the user write a chat message without any abbreviations. By either substituting terms with their abbreviations or not, we encode 1s and 0s.

This approach again fulfills some of the requirements we set ourselves in \cref{ch:introduction}. It uses minimal computing resources and gives the user great control over cover text quality. Semantically meaningful conversations are guaranteed as terms and their abbreviations are synonymous. A customizable dictionary is already built into the keyboards of most smartphones, so it is easily accessible for the average user.

But there still are several drawbacks. As many terms don't have an abbreviation in practice, encoding efficiency is low. This is aggravated when abbreviations are used for entire sentences instead of individual words (e.g. "ily" instead of "i luv u" for "i love you"). Abbreviations can be undesired for readability or even inappropriate in formal communication. Other substitution approaches (e.g. substituting synonym words) solve these issues only partially.

\section{Steganography with large language models}
\label{sec:steganographyWithLLMs}
While steganography approaches without \glspl{LLM} are already able to fulfill some of the requirements we set ourselves in \cref{ch:introduction}, they all suffer from low encoding efficiency. Therefore, we now consider steganography approaches with \glspl{LLM}. First, we restrict ourselves to high-level access via prompting. Then we investigate a low-level solution by manipulating token generation. This finally leads us to the Stegasuras project~\cite{zieglerNeuralLinguisticSteganography2019}, which this thesis is based on.

\subsection{High-level: Prompting}
\label{sec:highLevelPrompting}
With state-of-the-art \glspl{LLM} reaching hundreds of billions of parameters, they are able to perform advanced logic only by being prompted~\cite{hossainLLMProSAnalyzingLarge2025}. As demonstrated in~\cite{steinebachNaturalLanguageSteganography2024} with ChatGPT, we can leverage this to perform steganography. We define two disjoint sets of words, A and B. We prompt the \gls{LLM} to generate a text that contains words from A and B matching a certain pattern (e.g. BABBABABA). We interpret any occurrence of a word from A as 0, any from B as 1.

This approach is attractive because it doesn't require a low-level understanding of \glspl{LLM} to implement it. The topic of cover texts can be controlled via the words in sets A and B, which in turn can be generated via a prompt. Encoding efficiency can be controlled via the number of word sets to choose from. It may also be relatively efficient with computing resources, as the \gls{LLM} is only needed for encoding, not for decoding.

However, this approach conflicts with most of the requirements we set ourselves in \cref{ch:introduction}. As can easily be tested with tools like LM Studio, small \glspl{LLM} that are feasible to run locally on smartphones are not able to perform the encoding logic. We would have to rely on a service provider to host a large \gls{LLM} for us. Making core functionality of our app dependent on third parties increases attack surface significantly. Therefore, the simplicity of this approach is not worth it for us.

\subsection{Low-level: Manipulating token generation}
\label{sec:lowLevelManipulatingTokenGeneration}
Many modern frameworks exist to give us low-level access to \glspl{LLM}. As demonstrated in the Stegasuras project with PyTorch and GPT-2~\cite{zieglerNeuralLinguisticSteganography2019,zieglerHarvardnlpNeuralSteganography2025,zieglerStegasuras2025}, this can be leveraged to perform steganography. First, we convert a secret message from string to binary. Then, we encode it into a cover text by letting the \gls{LLM} sample tokens to complete a given context based on the secret message bits. \cref{fig:stegasuras} shows an example. Stegasuras implements UTF-8 conversion and Arithmetic compression for the first step and Arithmetic, Huffman and Bins coding for the second step.

\begin{figure}
	\captionsetup{width=\linewidth}

	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width=0.75\linewidth]{stegasuras_a.png}
		\caption{Inputs: A context to be completed and the secret message to be encoded.}
		\label{fig:stegasurasA}
	\end{subfigure}

	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width=0.75\linewidth]{stegasuras_b.png}
		\caption{Output: A cover text that completes the context while encoding the secret message.}
		\label{fig:stegasurasB}
	\end{subfigure}

	\caption[Stegasuras]{The web demo of Stegasuras~\cite{zieglerStegasuras2025}.}
	\label{fig:stegasuras}
\end{figure}

This approach is promising several strengths we haven't seen before. By gaining low-level access to the \gls{LLM}, we can implement a complex encoding logic. This increases encoding efficiency to multiple bits per token and allows us to use small \glspl{LLM} that are feasible to run locally on a smartphone.

However, the Stegasuras implementation also has some shortcomings we can improve upon. Being published in 2019, it is not state-of-the-art anymore. We can expect significant gains in cover text quality by just swapping out the \gls{LLM}~\cite{wuGenerativeTextSteganography2024}. Furthermore, there is an open edge case. If cover text generation ends as soon as all secret message bits are encoded, the last sentence of the cover text likely isn't finished. Stegasuras offers a partial solution by finishing it with greedy sampling during encoding~\cite{zieglerHarvardnlpNeuralSteganography2025}. But this isn't considered during decoding, so the recovered secret message is followed by noise. Stegasuras ignores this in its evaluation by cutting off unfinished last sentences of cover texts~\cite{zieglerNeuralLinguisticSteganography2019}, thereby corrupting the secret message encoded in them.

Solving this edge case is the first contribution we make. Beyond that, we port the implementation to the state-of-the-art llama.cpp framework~\cite{gerganovGgerganovLlamacpp2024}, which gives us access to a wide range of \glspl{LLM} to scale with available hardware. We implement an Android app to run all of this locally on a smartphone. We extend the functionality by creating chat conversations, allowing users to arbitrarily interleave cover texts and plain texts. We improve cover text quality by including emojis and exposing a system prompt, allowing users to influence \gls{LLM} behaviour on a lower level via a natural language command. This way, we are able to solve the real-world problem of protecting people's privacy against eavesdroppers with steganography.
